{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 28017,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0010707784559374665,
      "grad_norm": 66.9994888305664,
      "learning_rate": 4.999625227540422e-05,
      "loss": 11.4953,
      "step": 10
    },
    {
      "epoch": 0.002141556911874933,
      "grad_norm": NaN,
      "learning_rate": 4.9991433772352506e-05,
      "loss": 5.74,
      "step": 20
    },
    {
      "epoch": 0.0032123353678123997,
      "grad_norm": 7.618419647216797,
      "learning_rate": 4.9986615269300784e-05,
      "loss": 2.2217,
      "step": 30
    },
    {
      "epoch": 0.004283113823749866,
      "grad_norm": 4.314188480377197,
      "learning_rate": 4.99812613770211e-05,
      "loss": 1.2437,
      "step": 40
    },
    {
      "epoch": 0.005353892279687333,
      "grad_norm": 2.426856756210327,
      "learning_rate": 4.997590748474141e-05,
      "loss": 1.0172,
      "step": 50
    },
    {
      "epoch": 0.006424670735624799,
      "grad_norm": 0.8777441382408142,
      "learning_rate": 4.997055359246172e-05,
      "loss": 0.6363,
      "step": 60
    },
    {
      "epoch": 0.0074954491915622656,
      "grad_norm": 0.7947110533714294,
      "learning_rate": 4.996519970018204e-05,
      "loss": 0.5542,
      "step": 70
    },
    {
      "epoch": 0.008566227647499732,
      "grad_norm": 5.546529293060303,
      "learning_rate": 4.995984580790235e-05,
      "loss": 0.5313,
      "step": 80
    },
    {
      "epoch": 0.009637006103437198,
      "grad_norm": 0.5110136270523071,
      "learning_rate": 4.995449191562266e-05,
      "loss": 0.5265,
      "step": 90
    },
    {
      "epoch": 0.010707784559374666,
      "grad_norm": 0.463798850774765,
      "learning_rate": 4.994913802334297e-05,
      "loss": 0.4878,
      "step": 100
    },
    {
      "epoch": 0.011778563015312132,
      "grad_norm": 0.31797054409980774,
      "learning_rate": 4.994378413106329e-05,
      "loss": 0.4292,
      "step": 110
    },
    {
      "epoch": 0.012849341471249599,
      "grad_norm": 0.3339836597442627,
      "learning_rate": 4.9938430238783594e-05,
      "loss": 0.374,
      "step": 120
    },
    {
      "epoch": 0.013920119927187065,
      "grad_norm": 0.24108603596687317,
      "learning_rate": 4.993307634650391e-05,
      "loss": 0.4031,
      "step": 130
    },
    {
      "epoch": 0.014990898383124531,
      "grad_norm": 0.27526432275772095,
      "learning_rate": 4.992772245422422e-05,
      "loss": 0.3731,
      "step": 140
    },
    {
      "epoch": 0.016061676839061997,
      "grad_norm": 0.2422802895307541,
      "learning_rate": 4.992236856194454e-05,
      "loss": 0.3549,
      "step": 150
    },
    {
      "epoch": 0.017132455294999464,
      "grad_norm": 0.31950148940086365,
      "learning_rate": 4.9917014669664846e-05,
      "loss": 0.3852,
      "step": 160
    },
    {
      "epoch": 0.01820323375093693,
      "grad_norm": 0.3030194938182831,
      "learning_rate": 4.991166077738516e-05,
      "loss": 0.3855,
      "step": 170
    },
    {
      "epoch": 0.019274012206874396,
      "grad_norm": 0.851114809513092,
      "learning_rate": 4.9906306885105476e-05,
      "loss": 0.3264,
      "step": 180
    },
    {
      "epoch": 0.020344790662811866,
      "grad_norm": 0.38858118653297424,
      "learning_rate": 4.990095299282579e-05,
      "loss": 0.3673,
      "step": 190
    },
    {
      "epoch": 0.021415569118749332,
      "grad_norm": 0.246290922164917,
      "learning_rate": 4.98955991005461e-05,
      "loss": 0.3157,
      "step": 200
    },
    {
      "epoch": 0.0224863475746868,
      "grad_norm": 0.3244886100292206,
      "learning_rate": 4.989024520826641e-05,
      "loss": 0.3206,
      "step": 210
    },
    {
      "epoch": 0.023557126030624265,
      "grad_norm": 0.31550100445747375,
      "learning_rate": 4.988489131598673e-05,
      "loss": 0.3924,
      "step": 220
    },
    {
      "epoch": 0.02462790448656173,
      "grad_norm": 0.26225733757019043,
      "learning_rate": 4.987953742370704e-05,
      "loss": 0.3268,
      "step": 230
    },
    {
      "epoch": 0.025698682942499197,
      "grad_norm": 0.31844577193260193,
      "learning_rate": 4.987418353142735e-05,
      "loss": 0.3125,
      "step": 240
    },
    {
      "epoch": 0.026769461398436663,
      "grad_norm": 0.2428264021873474,
      "learning_rate": 4.986882963914766e-05,
      "loss": 0.3083,
      "step": 250
    },
    {
      "epoch": 0.02784023985437413,
      "grad_norm": 0.24144987761974335,
      "learning_rate": 4.9863475746867974e-05,
      "loss": 0.3498,
      "step": 260
    },
    {
      "epoch": 0.028911018310311596,
      "grad_norm": 0.2662716805934906,
      "learning_rate": 4.9858121854588285e-05,
      "loss": 0.3317,
      "step": 270
    },
    {
      "epoch": 0.029981796766249062,
      "grad_norm": 0.2063826322555542,
      "learning_rate": 4.9852767962308596e-05,
      "loss": 0.2782,
      "step": 280
    },
    {
      "epoch": 0.03105257522218653,
      "grad_norm": 0.5139782428741455,
      "learning_rate": 4.9847414070028915e-05,
      "loss": 0.345,
      "step": 290
    },
    {
      "epoch": 0.032123353678123995,
      "grad_norm": 0.2431519478559494,
      "learning_rate": 4.9842060177749226e-05,
      "loss": 0.3123,
      "step": 300
    },
    {
      "epoch": 0.033194132134061465,
      "grad_norm": 0.4038284420967102,
      "learning_rate": 4.983670628546954e-05,
      "loss": 0.3108,
      "step": 310
    },
    {
      "epoch": 0.03426491058999893,
      "grad_norm": 0.33070823550224304,
      "learning_rate": 4.983135239318985e-05,
      "loss": 0.2814,
      "step": 320
    },
    {
      "epoch": 0.0353356890459364,
      "grad_norm": 0.33502769470214844,
      "learning_rate": 4.982599850091017e-05,
      "loss": 0.3019,
      "step": 330
    },
    {
      "epoch": 0.03640646750187386,
      "grad_norm": 0.3016423285007477,
      "learning_rate": 4.982064460863048e-05,
      "loss": 0.2829,
      "step": 340
    },
    {
      "epoch": 0.03747724595781133,
      "grad_norm": 0.24777691066265106,
      "learning_rate": 4.981529071635079e-05,
      "loss": 0.2742,
      "step": 350
    },
    {
      "epoch": 0.03854802441374879,
      "grad_norm": 0.22095392644405365,
      "learning_rate": 4.98099368240711e-05,
      "loss": 0.2342,
      "step": 360
    },
    {
      "epoch": 0.03961880286968626,
      "grad_norm": 0.19906626641750336,
      "learning_rate": 4.980458293179141e-05,
      "loss": 0.2378,
      "step": 370
    },
    {
      "epoch": 0.04068958132562373,
      "grad_norm": 0.18230174481868744,
      "learning_rate": 4.979922903951173e-05,
      "loss": 0.2606,
      "step": 380
    },
    {
      "epoch": 0.041760359781561195,
      "grad_norm": 0.1487089991569519,
      "learning_rate": 4.9793875147232035e-05,
      "loss": 0.2431,
      "step": 390
    },
    {
      "epoch": 0.042831138237498664,
      "grad_norm": 0.29502519965171814,
      "learning_rate": 4.9788521254952354e-05,
      "loss": 0.2784,
      "step": 400
    },
    {
      "epoch": 0.04390191669343613,
      "grad_norm": 0.21152925491333008,
      "learning_rate": 4.9783167362672665e-05,
      "loss": 0.2442,
      "step": 410
    },
    {
      "epoch": 0.0449726951493736,
      "grad_norm": 4.475151538848877,
      "learning_rate": 4.9777813470392976e-05,
      "loss": 0.2695,
      "step": 420
    },
    {
      "epoch": 0.04604347360531106,
      "grad_norm": 0.32487744092941284,
      "learning_rate": 4.977245957811329e-05,
      "loss": 0.2807,
      "step": 430
    },
    {
      "epoch": 0.04711425206124853,
      "grad_norm": 0.7323249578475952,
      "learning_rate": 4.9767105685833606e-05,
      "loss": 0.3256,
      "step": 440
    },
    {
      "epoch": 0.04818503051718599,
      "grad_norm": 0.19078998267650604,
      "learning_rate": 4.976175179355392e-05,
      "loss": 0.2702,
      "step": 450
    },
    {
      "epoch": 0.04925580897312346,
      "grad_norm": 0.3357841372489929,
      "learning_rate": 4.975639790127423e-05,
      "loss": 0.2508,
      "step": 460
    },
    {
      "epoch": 0.050326587429060925,
      "grad_norm": 0.2877200245857239,
      "learning_rate": 4.975104400899454e-05,
      "loss": 0.2479,
      "step": 470
    },
    {
      "epoch": 0.051397365884998394,
      "grad_norm": 0.22613918781280518,
      "learning_rate": 4.974569011671485e-05,
      "loss": 0.2748,
      "step": 480
    },
    {
      "epoch": 0.05246814434093586,
      "grad_norm": 0.23102079331874847,
      "learning_rate": 4.974033622443517e-05,
      "loss": 0.2695,
      "step": 490
    },
    {
      "epoch": 0.05353892279687333,
      "grad_norm": 0.29657652974128723,
      "learning_rate": 4.9734982332155474e-05,
      "loss": 0.2222,
      "step": 500
    },
    {
      "epoch": 0.0546097012528108,
      "grad_norm": 0.236999049782753,
      "learning_rate": 4.972962843987579e-05,
      "loss": 0.2488,
      "step": 510
    },
    {
      "epoch": 0.05568047970874826,
      "grad_norm": 0.20568150281906128,
      "learning_rate": 4.9724274547596104e-05,
      "loss": 0.2506,
      "step": 520
    },
    {
      "epoch": 0.05675125816468573,
      "grad_norm": 0.23868681490421295,
      "learning_rate": 4.971892065531642e-05,
      "loss": 0.2497,
      "step": 530
    },
    {
      "epoch": 0.05782203662062319,
      "grad_norm": 0.1820514053106308,
      "learning_rate": 4.971356676303673e-05,
      "loss": 0.2488,
      "step": 540
    },
    {
      "epoch": 0.05889281507656066,
      "grad_norm": 0.29801854491233826,
      "learning_rate": 4.9708212870757045e-05,
      "loss": 0.2561,
      "step": 550
    },
    {
      "epoch": 0.059963593532498125,
      "grad_norm": 0.2304176241159439,
      "learning_rate": 4.9702858978477356e-05,
      "loss": 0.2271,
      "step": 560
    },
    {
      "epoch": 0.061034371988435594,
      "grad_norm": 0.22489245235919952,
      "learning_rate": 4.969750508619767e-05,
      "loss": 0.2414,
      "step": 570
    },
    {
      "epoch": 0.06210515044437306,
      "grad_norm": 0.21964186429977417,
      "learning_rate": 4.969215119391798e-05,
      "loss": 0.2519,
      "step": 580
    },
    {
      "epoch": 0.06317592890031053,
      "grad_norm": 0.23203028738498688,
      "learning_rate": 4.968679730163829e-05,
      "loss": 0.2333,
      "step": 590
    },
    {
      "epoch": 0.06424670735624799,
      "grad_norm": 0.2777824401855469,
      "learning_rate": 4.968144340935861e-05,
      "loss": 0.2291,
      "step": 600
    },
    {
      "epoch": 0.06531748581218545,
      "grad_norm": 0.21720299124717712,
      "learning_rate": 4.967608951707891e-05,
      "loss": 0.2243,
      "step": 610
    },
    {
      "epoch": 0.06638826426812293,
      "grad_norm": 0.32601603865623474,
      "learning_rate": 4.967073562479923e-05,
      "loss": 0.2206,
      "step": 620
    },
    {
      "epoch": 0.06745904272406039,
      "grad_norm": 0.20734462141990662,
      "learning_rate": 4.966538173251954e-05,
      "loss": 0.2304,
      "step": 630
    },
    {
      "epoch": 0.06852982117999785,
      "grad_norm": 0.17690198123455048,
      "learning_rate": 4.966002784023986e-05,
      "loss": 0.2143,
      "step": 640
    },
    {
      "epoch": 0.06960059963593533,
      "grad_norm": 0.3520008623600006,
      "learning_rate": 4.9654673947960166e-05,
      "loss": 0.2664,
      "step": 650
    },
    {
      "epoch": 0.0706713780918728,
      "grad_norm": 0.1424078345298767,
      "learning_rate": 4.9649320055680484e-05,
      "loss": 0.265,
      "step": 660
    },
    {
      "epoch": 0.07174215654781026,
      "grad_norm": 0.23857399821281433,
      "learning_rate": 4.9643966163400795e-05,
      "loss": 0.2282,
      "step": 670
    },
    {
      "epoch": 0.07281293500374772,
      "grad_norm": 0.20868350565433502,
      "learning_rate": 4.9638612271121107e-05,
      "loss": 0.2351,
      "step": 680
    },
    {
      "epoch": 0.0738837134596852,
      "grad_norm": 0.28584930300712585,
      "learning_rate": 4.963325837884142e-05,
      "loss": 0.2278,
      "step": 690
    },
    {
      "epoch": 0.07495449191562266,
      "grad_norm": 0.2617989182472229,
      "learning_rate": 4.962790448656173e-05,
      "loss": 0.2319,
      "step": 700
    },
    {
      "epoch": 0.07602527037156012,
      "grad_norm": 0.21043595671653748,
      "learning_rate": 4.962255059428205e-05,
      "loss": 0.2039,
      "step": 710
    },
    {
      "epoch": 0.07709604882749758,
      "grad_norm": 0.2022257000207901,
      "learning_rate": 4.961719670200235e-05,
      "loss": 0.2247,
      "step": 720
    },
    {
      "epoch": 0.07816682728343506,
      "grad_norm": 0.17848148941993713,
      "learning_rate": 4.961184280972267e-05,
      "loss": 0.214,
      "step": 730
    },
    {
      "epoch": 0.07923760573937252,
      "grad_norm": 0.3778696060180664,
      "learning_rate": 4.960648891744298e-05,
      "loss": 0.2197,
      "step": 740
    },
    {
      "epoch": 0.08030838419530999,
      "grad_norm": 0.24906592071056366,
      "learning_rate": 4.96011350251633e-05,
      "loss": 0.2124,
      "step": 750
    },
    {
      "epoch": 0.08137916265124746,
      "grad_norm": 0.23801292479038239,
      "learning_rate": 4.9595781132883605e-05,
      "loss": 0.2401,
      "step": 760
    },
    {
      "epoch": 0.08244994110718493,
      "grad_norm": 0.17359210550785065,
      "learning_rate": 4.959042724060392e-05,
      "loss": 0.1974,
      "step": 770
    },
    {
      "epoch": 0.08352071956312239,
      "grad_norm": 0.20731475949287415,
      "learning_rate": 4.9585073348324234e-05,
      "loss": 0.215,
      "step": 780
    },
    {
      "epoch": 0.08459149801905985,
      "grad_norm": 0.205315500497818,
      "learning_rate": 4.9579719456044546e-05,
      "loss": 0.2174,
      "step": 790
    },
    {
      "epoch": 0.08566227647499733,
      "grad_norm": 0.23850053548812866,
      "learning_rate": 4.957436556376486e-05,
      "loss": 0.2359,
      "step": 800
    },
    {
      "epoch": 0.08673305493093479,
      "grad_norm": 0.14440315961837769,
      "learning_rate": 4.956901167148517e-05,
      "loss": 0.2239,
      "step": 810
    },
    {
      "epoch": 0.08780383338687225,
      "grad_norm": 0.2628389000892639,
      "learning_rate": 4.9563657779205487e-05,
      "loss": 0.2441,
      "step": 820
    },
    {
      "epoch": 0.08887461184280972,
      "grad_norm": 0.23137003183364868,
      "learning_rate": 4.95583038869258e-05,
      "loss": 0.1976,
      "step": 830
    },
    {
      "epoch": 0.0899453902987472,
      "grad_norm": 0.1705503612756729,
      "learning_rate": 4.955294999464611e-05,
      "loss": 0.2316,
      "step": 840
    },
    {
      "epoch": 0.09101616875468466,
      "grad_norm": 0.3243993818759918,
      "learning_rate": 4.954759610236642e-05,
      "loss": 0.2092,
      "step": 850
    },
    {
      "epoch": 0.09208694721062212,
      "grad_norm": 0.1963430941104889,
      "learning_rate": 4.954224221008674e-05,
      "loss": 0.2253,
      "step": 860
    },
    {
      "epoch": 0.09315772566655958,
      "grad_norm": 0.22071769833564758,
      "learning_rate": 4.953688831780705e-05,
      "loss": 0.1972,
      "step": 870
    },
    {
      "epoch": 0.09422850412249706,
      "grad_norm": 0.2591249346733093,
      "learning_rate": 4.953153442552736e-05,
      "loss": 0.2195,
      "step": 880
    },
    {
      "epoch": 0.09529928257843452,
      "grad_norm": 0.14668509364128113,
      "learning_rate": 4.952618053324767e-05,
      "loss": 0.1963,
      "step": 890
    },
    {
      "epoch": 0.09637006103437198,
      "grad_norm": 0.18003971874713898,
      "learning_rate": 4.9520826640967985e-05,
      "loss": 0.1961,
      "step": 900
    },
    {
      "epoch": 0.09744083949030946,
      "grad_norm": 0.13645876944065094,
      "learning_rate": 4.9515472748688296e-05,
      "loss": 0.2317,
      "step": 910
    },
    {
      "epoch": 0.09851161794624692,
      "grad_norm": 0.21273377537727356,
      "learning_rate": 4.951011885640861e-05,
      "loss": 0.2067,
      "step": 920
    },
    {
      "epoch": 0.09958239640218439,
      "grad_norm": 0.18952268362045288,
      "learning_rate": 4.9504764964128925e-05,
      "loss": 0.2163,
      "step": 930
    },
    {
      "epoch": 0.10065317485812185,
      "grad_norm": 0.2177841067314148,
      "learning_rate": 4.949941107184924e-05,
      "loss": 0.1721,
      "step": 940
    },
    {
      "epoch": 0.10172395331405933,
      "grad_norm": 0.19453522562980652,
      "learning_rate": 4.949405717956955e-05,
      "loss": 0.1973,
      "step": 950
    },
    {
      "epoch": 0.10279473176999679,
      "grad_norm": 0.15041236579418182,
      "learning_rate": 4.948870328728986e-05,
      "loss": 0.1922,
      "step": 960
    },
    {
      "epoch": 0.10386551022593425,
      "grad_norm": 0.18183796107769012,
      "learning_rate": 4.948334939501018e-05,
      "loss": 0.2335,
      "step": 970
    },
    {
      "epoch": 0.10493628868187171,
      "grad_norm": 0.22330014407634735,
      "learning_rate": 4.947799550273049e-05,
      "loss": 0.2018,
      "step": 980
    },
    {
      "epoch": 0.10600706713780919,
      "grad_norm": 0.26659995317459106,
      "learning_rate": 4.94726416104508e-05,
      "loss": 0.1865,
      "step": 990
    },
    {
      "epoch": 0.10707784559374665,
      "grad_norm": 0.20812033116817474,
      "learning_rate": 4.946728771817111e-05,
      "loss": 0.197,
      "step": 1000
    },
    {
      "epoch": 0.10814862404968412,
      "grad_norm": 0.17693361639976501,
      "learning_rate": 4.9461933825891423e-05,
      "loss": 0.2213,
      "step": 1010
    },
    {
      "epoch": 0.1092194025056216,
      "grad_norm": 0.1865510642528534,
      "learning_rate": 4.945657993361174e-05,
      "loss": 0.193,
      "step": 1020
    },
    {
      "epoch": 0.11029018096155906,
      "grad_norm": 0.1776687204837799,
      "learning_rate": 4.9451226041332046e-05,
      "loss": 0.2182,
      "step": 1030
    },
    {
      "epoch": 0.11136095941749652,
      "grad_norm": 0.2235158383846283,
      "learning_rate": 4.9445872149052364e-05,
      "loss": 0.2125,
      "step": 1040
    },
    {
      "epoch": 0.11243173787343398,
      "grad_norm": 0.36274224519729614,
      "learning_rate": 4.9440518256772676e-05,
      "loss": 0.2266,
      "step": 1050
    },
    {
      "epoch": 0.11350251632937146,
      "grad_norm": 0.15550285577774048,
      "learning_rate": 4.943516436449299e-05,
      "loss": 0.2193,
      "step": 1060
    },
    {
      "epoch": 0.11457329478530892,
      "grad_norm": 0.15351824462413788,
      "learning_rate": 4.94298104722133e-05,
      "loss": 0.2294,
      "step": 1070
    },
    {
      "epoch": 0.11564407324124638,
      "grad_norm": 0.19608089327812195,
      "learning_rate": 4.942445657993362e-05,
      "loss": 0.1802,
      "step": 1080
    },
    {
      "epoch": 0.11671485169718385,
      "grad_norm": 0.20956102013587952,
      "learning_rate": 4.941910268765393e-05,
      "loss": 0.2117,
      "step": 1090
    },
    {
      "epoch": 0.11778563015312132,
      "grad_norm": 0.2295183688402176,
      "learning_rate": 4.941374879537424e-05,
      "loss": 0.1765,
      "step": 1100
    },
    {
      "epoch": 0.11885640860905879,
      "grad_norm": 0.27537232637405396,
      "learning_rate": 4.940839490309455e-05,
      "loss": 0.2145,
      "step": 1110
    },
    {
      "epoch": 0.11992718706499625,
      "grad_norm": 0.19903263449668884,
      "learning_rate": 4.940304101081486e-05,
      "loss": 0.1875,
      "step": 1120
    },
    {
      "epoch": 0.12099796552093373,
      "grad_norm": 0.21035468578338623,
      "learning_rate": 4.939768711853518e-05,
      "loss": 0.1857,
      "step": 1130
    },
    {
      "epoch": 0.12206874397687119,
      "grad_norm": 0.2912605106830597,
      "learning_rate": 4.9392333226255485e-05,
      "loss": 0.213,
      "step": 1140
    },
    {
      "epoch": 0.12313952243280865,
      "grad_norm": 0.26607176661491394,
      "learning_rate": 4.9386979333975803e-05,
      "loss": 0.2231,
      "step": 1150
    },
    {
      "epoch": 0.12421030088874611,
      "grad_norm": 0.17646779119968414,
      "learning_rate": 4.9381625441696115e-05,
      "loss": 0.1887,
      "step": 1160
    },
    {
      "epoch": 0.12528107934468358,
      "grad_norm": 0.16728194057941437,
      "learning_rate": 4.937627154941643e-05,
      "loss": 0.1884,
      "step": 1170
    },
    {
      "epoch": 0.12635185780062105,
      "grad_norm": 0.23616355657577515,
      "learning_rate": 4.937091765713674e-05,
      "loss": 0.2006,
      "step": 1180
    },
    {
      "epoch": 0.12742263625655853,
      "grad_norm": 0.21803973615169525,
      "learning_rate": 4.9365563764857056e-05,
      "loss": 0.1945,
      "step": 1190
    },
    {
      "epoch": 0.12849341471249598,
      "grad_norm": 0.4851001501083374,
      "learning_rate": 4.936020987257737e-05,
      "loss": 0.2022,
      "step": 1200
    },
    {
      "epoch": 0.12956419316843346,
      "grad_norm": 0.25224459171295166,
      "learning_rate": 4.935485598029768e-05,
      "loss": 0.2047,
      "step": 1210
    },
    {
      "epoch": 0.1306349716243709,
      "grad_norm": 0.2020677626132965,
      "learning_rate": 4.934950208801799e-05,
      "loss": 0.1869,
      "step": 1220
    },
    {
      "epoch": 0.13170575008030838,
      "grad_norm": 0.14788810908794403,
      "learning_rate": 4.93441481957383e-05,
      "loss": 0.1625,
      "step": 1230
    },
    {
      "epoch": 0.13277652853624586,
      "grad_norm": 0.26936593651771545,
      "learning_rate": 4.933879430345862e-05,
      "loss": 0.1882,
      "step": 1240
    },
    {
      "epoch": 0.1338473069921833,
      "grad_norm": 0.1929994523525238,
      "learning_rate": 4.9333440411178924e-05,
      "loss": 0.1915,
      "step": 1250
    },
    {
      "epoch": 0.13491808544812078,
      "grad_norm": 0.2205321192741394,
      "learning_rate": 4.932808651889924e-05,
      "loss": 0.1956,
      "step": 1260
    },
    {
      "epoch": 0.13598886390405826,
      "grad_norm": 0.19762243330478668,
      "learning_rate": 4.9322732626619554e-05,
      "loss": 0.1841,
      "step": 1270
    },
    {
      "epoch": 0.1370596423599957,
      "grad_norm": 0.16123007237911224,
      "learning_rate": 4.931737873433987e-05,
      "loss": 0.2091,
      "step": 1280
    },
    {
      "epoch": 0.13813042081593319,
      "grad_norm": 0.15819679200649261,
      "learning_rate": 4.9312024842060177e-05,
      "loss": 0.1899,
      "step": 1290
    },
    {
      "epoch": 0.13920119927187066,
      "grad_norm": 0.16997124254703522,
      "learning_rate": 4.9306670949780495e-05,
      "loss": 0.181,
      "step": 1300
    },
    {
      "epoch": 0.1402719777278081,
      "grad_norm": 0.12440340220928192,
      "learning_rate": 4.9301317057500806e-05,
      "loss": 0.1914,
      "step": 1310
    },
    {
      "epoch": 0.1413427561837456,
      "grad_norm": 0.1834373027086258,
      "learning_rate": 4.929596316522112e-05,
      "loss": 0.1871,
      "step": 1320
    },
    {
      "epoch": 0.14241353463968304,
      "grad_norm": 0.16921329498291016,
      "learning_rate": 4.929060927294143e-05,
      "loss": 0.1819,
      "step": 1330
    },
    {
      "epoch": 0.1434843130956205,
      "grad_norm": 0.24813967943191528,
      "learning_rate": 4.928525538066174e-05,
      "loss": 0.2011,
      "step": 1340
    },
    {
      "epoch": 0.144555091551558,
      "grad_norm": 0.2256767451763153,
      "learning_rate": 4.927990148838206e-05,
      "loss": 0.186,
      "step": 1350
    },
    {
      "epoch": 0.14562587000749544,
      "grad_norm": 0.4700678884983063,
      "learning_rate": 4.927454759610236e-05,
      "loss": 0.2145,
      "step": 1360
    },
    {
      "epoch": 0.14669664846343292,
      "grad_norm": 0.25235432386398315,
      "learning_rate": 4.926919370382268e-05,
      "loss": 0.1896,
      "step": 1370
    },
    {
      "epoch": 0.1477674269193704,
      "grad_norm": 0.3297761380672455,
      "learning_rate": 4.926383981154299e-05,
      "loss": 0.1856,
      "step": 1380
    },
    {
      "epoch": 0.14883820537530784,
      "grad_norm": 0.1754419356584549,
      "learning_rate": 4.925848591926331e-05,
      "loss": 0.1771,
      "step": 1390
    },
    {
      "epoch": 0.14990898383124532,
      "grad_norm": 0.18254335224628448,
      "learning_rate": 4.9253132026983616e-05,
      "loss": 0.1802,
      "step": 1400
    },
    {
      "epoch": 0.1509797622871828,
      "grad_norm": 0.15556377172470093,
      "learning_rate": 4.9247778134703934e-05,
      "loss": 0.1877,
      "step": 1410
    },
    {
      "epoch": 0.15205054074312024,
      "grad_norm": 0.13928300142288208,
      "learning_rate": 4.9242424242424245e-05,
      "loss": 0.171,
      "step": 1420
    },
    {
      "epoch": 0.15312131919905772,
      "grad_norm": 0.2505283057689667,
      "learning_rate": 4.9237070350144556e-05,
      "loss": 0.215,
      "step": 1430
    },
    {
      "epoch": 0.15419209765499517,
      "grad_norm": 0.27377569675445557,
      "learning_rate": 4.923171645786487e-05,
      "loss": 0.1967,
      "step": 1440
    },
    {
      "epoch": 0.15526287611093265,
      "grad_norm": 0.17500607669353485,
      "learning_rate": 4.922636256558518e-05,
      "loss": 0.1916,
      "step": 1450
    },
    {
      "epoch": 0.15633365456687012,
      "grad_norm": 0.21151913702487946,
      "learning_rate": 4.92210086733055e-05,
      "loss": 0.1869,
      "step": 1460
    },
    {
      "epoch": 0.15740443302280757,
      "grad_norm": 0.20585741102695465,
      "learning_rate": 4.921565478102581e-05,
      "loss": 0.1808,
      "step": 1470
    },
    {
      "epoch": 0.15847521147874505,
      "grad_norm": 0.22241954505443573,
      "learning_rate": 4.921030088874612e-05,
      "loss": 0.187,
      "step": 1480
    },
    {
      "epoch": 0.15954598993468252,
      "grad_norm": 0.3008115291595459,
      "learning_rate": 4.920494699646643e-05,
      "loss": 0.1913,
      "step": 1490
    },
    {
      "epoch": 0.16061676839061997,
      "grad_norm": 0.21068987250328064,
      "learning_rate": 4.919959310418675e-05,
      "loss": 0.175,
      "step": 1500
    },
    {
      "epoch": 0.16168754684655745,
      "grad_norm": 0.3136301338672638,
      "learning_rate": 4.9194239211907054e-05,
      "loss": 0.1872,
      "step": 1510
    },
    {
      "epoch": 0.16275832530249493,
      "grad_norm": 0.17424139380455017,
      "learning_rate": 4.918888531962737e-05,
      "loss": 0.165,
      "step": 1520
    },
    {
      "epoch": 0.16382910375843238,
      "grad_norm": 0.21527396142482758,
      "learning_rate": 4.9183531427347684e-05,
      "loss": 0.1682,
      "step": 1530
    },
    {
      "epoch": 0.16489988221436985,
      "grad_norm": 0.18030470609664917,
      "learning_rate": 4.9178177535067995e-05,
      "loss": 0.1859,
      "step": 1540
    },
    {
      "epoch": 0.1659706606703073,
      "grad_norm": 0.24725733697414398,
      "learning_rate": 4.917282364278831e-05,
      "loss": 0.1882,
      "step": 1550
    },
    {
      "epoch": 0.16704143912624478,
      "grad_norm": 0.15139003098011017,
      "learning_rate": 4.916746975050862e-05,
      "loss": 0.1981,
      "step": 1560
    },
    {
      "epoch": 0.16811221758218226,
      "grad_norm": 0.23052726686000824,
      "learning_rate": 4.9162115858228936e-05,
      "loss": 0.173,
      "step": 1570
    },
    {
      "epoch": 0.1691829960381197,
      "grad_norm": 0.30944445729255676,
      "learning_rate": 4.915676196594925e-05,
      "loss": 0.1786,
      "step": 1580
    },
    {
      "epoch": 0.17025377449405718,
      "grad_norm": 0.24338844418525696,
      "learning_rate": 4.915140807366956e-05,
      "loss": 0.2137,
      "step": 1590
    },
    {
      "epoch": 0.17132455294999466,
      "grad_norm": 0.2779216170310974,
      "learning_rate": 4.914605418138987e-05,
      "loss": 0.1856,
      "step": 1600
    },
    {
      "epoch": 0.1723953314059321,
      "grad_norm": 0.15910778939723969,
      "learning_rate": 4.914070028911019e-05,
      "loss": 0.1674,
      "step": 1610
    },
    {
      "epoch": 0.17346610986186958,
      "grad_norm": 0.17922401428222656,
      "learning_rate": 4.91353463968305e-05,
      "loss": 0.1618,
      "step": 1620
    },
    {
      "epoch": 0.17453688831780706,
      "grad_norm": 0.21368062496185303,
      "learning_rate": 4.912999250455081e-05,
      "loss": 0.1748,
      "step": 1630
    },
    {
      "epoch": 0.1756076667737445,
      "grad_norm": 0.21562545001506805,
      "learning_rate": 4.912463861227112e-05,
      "loss": 0.1856,
      "step": 1640
    },
    {
      "epoch": 0.17667844522968199,
      "grad_norm": 0.14670194685459137,
      "learning_rate": 4.9119284719991434e-05,
      "loss": 0.1563,
      "step": 1650
    },
    {
      "epoch": 0.17774922368561943,
      "grad_norm": 0.18425078690052032,
      "learning_rate": 4.9113930827711746e-05,
      "loss": 0.1579,
      "step": 1660
    },
    {
      "epoch": 0.1788200021415569,
      "grad_norm": 0.18940488994121552,
      "learning_rate": 4.910857693543206e-05,
      "loss": 0.1715,
      "step": 1670
    },
    {
      "epoch": 0.1798907805974944,
      "grad_norm": 0.2803070843219757,
      "learning_rate": 4.9103223043152375e-05,
      "loss": 0.1875,
      "step": 1680
    },
    {
      "epoch": 0.18096155905343184,
      "grad_norm": 0.2566150426864624,
      "learning_rate": 4.909786915087269e-05,
      "loss": 0.191,
      "step": 1690
    },
    {
      "epoch": 0.1820323375093693,
      "grad_norm": 0.17902733385562897,
      "learning_rate": 4.9092515258593e-05,
      "loss": 0.1753,
      "step": 1700
    },
    {
      "epoch": 0.1831031159653068,
      "grad_norm": 0.17112228274345398,
      "learning_rate": 4.908716136631331e-05,
      "loss": 0.1573,
      "step": 1710
    },
    {
      "epoch": 0.18417389442124424,
      "grad_norm": 0.21028268337249756,
      "learning_rate": 4.908180747403363e-05,
      "loss": 0.1821,
      "step": 1720
    },
    {
      "epoch": 0.18524467287718172,
      "grad_norm": 0.18453946709632874,
      "learning_rate": 4.907645358175394e-05,
      "loss": 0.1763,
      "step": 1730
    },
    {
      "epoch": 0.18631545133311916,
      "grad_norm": 0.13723266124725342,
      "learning_rate": 4.907109968947425e-05,
      "loss": 0.1725,
      "step": 1740
    },
    {
      "epoch": 0.18738622978905664,
      "grad_norm": 0.19222170114517212,
      "learning_rate": 4.906574579719456e-05,
      "loss": 0.1739,
      "step": 1750
    },
    {
      "epoch": 0.18845700824499412,
      "grad_norm": 0.23861218988895416,
      "learning_rate": 4.906039190491487e-05,
      "loss": 0.1685,
      "step": 1760
    },
    {
      "epoch": 0.18952778670093157,
      "grad_norm": 0.20433080196380615,
      "learning_rate": 4.905503801263519e-05,
      "loss": 0.1959,
      "step": 1770
    },
    {
      "epoch": 0.19059856515686904,
      "grad_norm": 0.21031801402568817,
      "learning_rate": 4.9049684120355496e-05,
      "loss": 0.1616,
      "step": 1780
    },
    {
      "epoch": 0.19166934361280652,
      "grad_norm": 0.26494190096855164,
      "learning_rate": 4.9044330228075814e-05,
      "loss": 0.1768,
      "step": 1790
    },
    {
      "epoch": 0.19274012206874397,
      "grad_norm": 0.21727988123893738,
      "learning_rate": 4.9038976335796126e-05,
      "loss": 0.1587,
      "step": 1800
    },
    {
      "epoch": 0.19381090052468145,
      "grad_norm": 0.1614905744791031,
      "learning_rate": 4.9033622443516444e-05,
      "loss": 0.1835,
      "step": 1810
    },
    {
      "epoch": 0.19488167898061892,
      "grad_norm": 0.18593871593475342,
      "learning_rate": 4.902826855123675e-05,
      "loss": 0.1757,
      "step": 1820
    },
    {
      "epoch": 0.19595245743655637,
      "grad_norm": 0.276655375957489,
      "learning_rate": 4.902291465895707e-05,
      "loss": 0.1758,
      "step": 1830
    },
    {
      "epoch": 0.19702323589249385,
      "grad_norm": 0.23493099212646484,
      "learning_rate": 4.901756076667738e-05,
      "loss": 0.1678,
      "step": 1840
    },
    {
      "epoch": 0.1980940143484313,
      "grad_norm": 0.17014910280704498,
      "learning_rate": 4.901220687439769e-05,
      "loss": 0.1413,
      "step": 1850
    },
    {
      "epoch": 0.19916479280436877,
      "grad_norm": 0.17982332408428192,
      "learning_rate": 4.9006852982118e-05,
      "loss": 0.2006,
      "step": 1860
    },
    {
      "epoch": 0.20023557126030625,
      "grad_norm": 0.24149398505687714,
      "learning_rate": 4.900149908983831e-05,
      "loss": 0.1851,
      "step": 1870
    },
    {
      "epoch": 0.2013063497162437,
      "grad_norm": 0.2641231417655945,
      "learning_rate": 4.899614519755863e-05,
      "loss": 0.1881,
      "step": 1880
    },
    {
      "epoch": 0.20237712817218118,
      "grad_norm": 0.15451474487781525,
      "learning_rate": 4.8990791305278935e-05,
      "loss": 0.1611,
      "step": 1890
    },
    {
      "epoch": 0.20344790662811865,
      "grad_norm": 0.1307578682899475,
      "learning_rate": 4.898543741299925e-05,
      "loss": 0.16,
      "step": 1900
    },
    {
      "epoch": 0.2045186850840561,
      "grad_norm": 0.1407829076051712,
      "learning_rate": 4.8980083520719565e-05,
      "loss": 0.1607,
      "step": 1910
    },
    {
      "epoch": 0.20558946353999358,
      "grad_norm": 0.18242177367210388,
      "learning_rate": 4.897472962843988e-05,
      "loss": 0.1752,
      "step": 1920
    },
    {
      "epoch": 0.20666024199593105,
      "grad_norm": 0.17590492963790894,
      "learning_rate": 4.896937573616019e-05,
      "loss": 0.1431,
      "step": 1930
    },
    {
      "epoch": 0.2077310204518685,
      "grad_norm": 0.16552209854125977,
      "learning_rate": 4.8964021843880506e-05,
      "loss": 0.157,
      "step": 1940
    },
    {
      "epoch": 0.20880179890780598,
      "grad_norm": 0.18718966841697693,
      "learning_rate": 4.895866795160082e-05,
      "loss": 0.1638,
      "step": 1950
    },
    {
      "epoch": 0.20987257736374343,
      "grad_norm": 0.19845952093601227,
      "learning_rate": 4.895331405932113e-05,
      "loss": 0.1697,
      "step": 1960
    },
    {
      "epoch": 0.2109433558196809,
      "grad_norm": 0.2024824023246765,
      "learning_rate": 4.894796016704144e-05,
      "loss": 0.1745,
      "step": 1970
    },
    {
      "epoch": 0.21201413427561838,
      "grad_norm": 0.2660502791404724,
      "learning_rate": 4.894260627476175e-05,
      "loss": 0.1777,
      "step": 1980
    },
    {
      "epoch": 0.21308491273155583,
      "grad_norm": 0.17634524405002594,
      "learning_rate": 4.893725238248207e-05,
      "loss": 0.1477,
      "step": 1990
    },
    {
      "epoch": 0.2141556911874933,
      "grad_norm": 0.26449400186538696,
      "learning_rate": 4.8931898490202374e-05,
      "loss": 0.1902,
      "step": 2000
    },
    {
      "epoch": 0.21522646964343078,
      "grad_norm": 0.24218933284282684,
      "learning_rate": 4.892654459792269e-05,
      "loss": 0.1783,
      "step": 2010
    },
    {
      "epoch": 0.21629724809936823,
      "grad_norm": 0.12517207860946655,
      "learning_rate": 4.8921190705643004e-05,
      "loss": 0.1664,
      "step": 2020
    },
    {
      "epoch": 0.2173680265553057,
      "grad_norm": 0.3055082857608795,
      "learning_rate": 4.891583681336332e-05,
      "loss": 0.1661,
      "step": 2030
    },
    {
      "epoch": 0.2184388050112432,
      "grad_norm": 0.20872648060321808,
      "learning_rate": 4.8910482921083626e-05,
      "loss": 0.1785,
      "step": 2040
    },
    {
      "epoch": 0.21950958346718064,
      "grad_norm": 0.186706081032753,
      "learning_rate": 4.8905129028803945e-05,
      "loss": 0.1833,
      "step": 2050
    },
    {
      "epoch": 0.2205803619231181,
      "grad_norm": 0.16930636763572693,
      "learning_rate": 4.8899775136524256e-05,
      "loss": 0.1776,
      "step": 2060
    },
    {
      "epoch": 0.22165114037905556,
      "grad_norm": 0.11389201134443283,
      "learning_rate": 4.889442124424457e-05,
      "loss": 0.1661,
      "step": 2070
    },
    {
      "epoch": 0.22272191883499304,
      "grad_norm": 0.2416815608739853,
      "learning_rate": 4.888906735196488e-05,
      "loss": 0.1908,
      "step": 2080
    },
    {
      "epoch": 0.22379269729093051,
      "grad_norm": 0.12755464017391205,
      "learning_rate": 4.888371345968519e-05,
      "loss": 0.1712,
      "step": 2090
    },
    {
      "epoch": 0.22486347574686796,
      "grad_norm": 0.17890821397304535,
      "learning_rate": 4.887835956740551e-05,
      "loss": 0.1748,
      "step": 2100
    },
    {
      "epoch": 0.22593425420280544,
      "grad_norm": 0.1298179030418396,
      "learning_rate": 4.887300567512582e-05,
      "loss": 0.1539,
      "step": 2110
    },
    {
      "epoch": 0.22700503265874292,
      "grad_norm": 0.16178657114505768,
      "learning_rate": 4.886765178284613e-05,
      "loss": 0.1629,
      "step": 2120
    },
    {
      "epoch": 0.22807581111468037,
      "grad_norm": 0.22778765857219696,
      "learning_rate": 4.886229789056644e-05,
      "loss": 0.1521,
      "step": 2130
    },
    {
      "epoch": 0.22914658957061784,
      "grad_norm": 0.2421306073665619,
      "learning_rate": 4.885694399828676e-05,
      "loss": 0.1612,
      "step": 2140
    },
    {
      "epoch": 0.23021736802655532,
      "grad_norm": 0.17011788487434387,
      "learning_rate": 4.8851590106007065e-05,
      "loss": 0.1823,
      "step": 2150
    },
    {
      "epoch": 0.23128814648249277,
      "grad_norm": 0.4192749857902527,
      "learning_rate": 4.8846236213727384e-05,
      "loss": 0.1751,
      "step": 2160
    },
    {
      "epoch": 0.23235892493843024,
      "grad_norm": 0.40395545959472656,
      "learning_rate": 4.8840882321447695e-05,
      "loss": 0.1945,
      "step": 2170
    },
    {
      "epoch": 0.2334297033943677,
      "grad_norm": 0.3517224192619324,
      "learning_rate": 4.8835528429168006e-05,
      "loss": 0.1627,
      "step": 2180
    },
    {
      "epoch": 0.23450048185030517,
      "grad_norm": 0.19286677241325378,
      "learning_rate": 4.883017453688832e-05,
      "loss": 0.1525,
      "step": 2190
    },
    {
      "epoch": 0.23557126030624265,
      "grad_norm": 0.12724071741104126,
      "learning_rate": 4.882482064460863e-05,
      "loss": 0.1635,
      "step": 2200
    },
    {
      "epoch": 0.2366420387621801,
      "grad_norm": 0.23827147483825684,
      "learning_rate": 4.881946675232895e-05,
      "loss": 0.171,
      "step": 2210
    },
    {
      "epoch": 0.23771281721811757,
      "grad_norm": 0.19549791514873505,
      "learning_rate": 4.881411286004926e-05,
      "loss": 0.1642,
      "step": 2220
    },
    {
      "epoch": 0.23878359567405505,
      "grad_norm": 0.1671837568283081,
      "learning_rate": 4.880875896776957e-05,
      "loss": 0.1923,
      "step": 2230
    },
    {
      "epoch": 0.2398543741299925,
      "grad_norm": 0.20191800594329834,
      "learning_rate": 4.880340507548988e-05,
      "loss": 0.1718,
      "step": 2240
    },
    {
      "epoch": 0.24092515258592997,
      "grad_norm": 0.2428014725446701,
      "learning_rate": 4.87980511832102e-05,
      "loss": 0.1858,
      "step": 2250
    },
    {
      "epoch": 0.24199593104186745,
      "grad_norm": 0.2973755896091461,
      "learning_rate": 4.879269729093051e-05,
      "loss": 0.2003,
      "step": 2260
    },
    {
      "epoch": 0.2430667094978049,
      "grad_norm": 0.15541386604309082,
      "learning_rate": 4.878734339865082e-05,
      "loss": 0.1623,
      "step": 2270
    },
    {
      "epoch": 0.24413748795374238,
      "grad_norm": 0.1766304224729538,
      "learning_rate": 4.8781989506371134e-05,
      "loss": 0.1534,
      "step": 2280
    },
    {
      "epoch": 0.24520826640967983,
      "grad_norm": 0.19912803173065186,
      "learning_rate": 4.8776635614091445e-05,
      "loss": 0.1503,
      "step": 2290
    },
    {
      "epoch": 0.2462790448656173,
      "grad_norm": 0.17831431329250336,
      "learning_rate": 4.877128172181176e-05,
      "loss": 0.1522,
      "step": 2300
    },
    {
      "epoch": 0.24734982332155478,
      "grad_norm": 0.2954845726490021,
      "learning_rate": 4.876592782953207e-05,
      "loss": 0.1613,
      "step": 2310
    },
    {
      "epoch": 0.24842060177749223,
      "grad_norm": 0.1686057448387146,
      "learning_rate": 4.8760573937252386e-05,
      "loss": 0.1561,
      "step": 2320
    },
    {
      "epoch": 0.2494913802334297,
      "grad_norm": 0.23915937542915344,
      "learning_rate": 4.87552200449727e-05,
      "loss": 0.1709,
      "step": 2330
    },
    {
      "epoch": 0.25056215868936715,
      "grad_norm": 0.23881801962852478,
      "learning_rate": 4.874986615269301e-05,
      "loss": 0.1768,
      "step": 2340
    },
    {
      "epoch": 0.25163293714530466,
      "grad_norm": 0.1881321668624878,
      "learning_rate": 4.874451226041332e-05,
      "loss": 0.1513,
      "step": 2350
    },
    {
      "epoch": 0.2527037156012421,
      "grad_norm": 0.1925119012594223,
      "learning_rate": 4.873915836813364e-05,
      "loss": 0.144,
      "step": 2360
    },
    {
      "epoch": 0.25377449405717956,
      "grad_norm": 0.24487607181072235,
      "learning_rate": 4.873380447585395e-05,
      "loss": 0.1661,
      "step": 2370
    },
    {
      "epoch": 0.25484527251311706,
      "grad_norm": 0.1548144370317459,
      "learning_rate": 4.872845058357426e-05,
      "loss": 0.1566,
      "step": 2380
    },
    {
      "epoch": 0.2559160509690545,
      "grad_norm": 0.2296452820301056,
      "learning_rate": 4.872309669129457e-05,
      "loss": 0.1935,
      "step": 2390
    },
    {
      "epoch": 0.25698682942499196,
      "grad_norm": 0.21447589993476868,
      "learning_rate": 4.8717742799014884e-05,
      "loss": 0.1457,
      "step": 2400
    },
    {
      "epoch": 0.25805760788092946,
      "grad_norm": 0.16023117303848267,
      "learning_rate": 4.87123889067352e-05,
      "loss": 0.1552,
      "step": 2410
    },
    {
      "epoch": 0.2591283863368669,
      "grad_norm": 0.286272257566452,
      "learning_rate": 4.870703501445551e-05,
      "loss": 0.1546,
      "step": 2420
    },
    {
      "epoch": 0.26019916479280436,
      "grad_norm": 0.16381072998046875,
      "learning_rate": 4.8701681122175825e-05,
      "loss": 0.18,
      "step": 2430
    },
    {
      "epoch": 0.2612699432487418,
      "grad_norm": 0.39267605543136597,
      "learning_rate": 4.869632722989614e-05,
      "loss": 0.1649,
      "step": 2440
    },
    {
      "epoch": 0.2623407217046793,
      "grad_norm": 0.2594432234764099,
      "learning_rate": 4.869097333761645e-05,
      "loss": 0.1576,
      "step": 2450
    },
    {
      "epoch": 0.26341150016061676,
      "grad_norm": 0.1835264265537262,
      "learning_rate": 4.868561944533676e-05,
      "loss": 0.1508,
      "step": 2460
    },
    {
      "epoch": 0.2644822786165542,
      "grad_norm": 0.18161652982234955,
      "learning_rate": 4.868026555305708e-05,
      "loss": 0.1662,
      "step": 2470
    },
    {
      "epoch": 0.2655530570724917,
      "grad_norm": 0.35315045714378357,
      "learning_rate": 4.867491166077739e-05,
      "loss": 0.1633,
      "step": 2480
    },
    {
      "epoch": 0.26662383552842917,
      "grad_norm": 0.18119093775749207,
      "learning_rate": 4.86695577684977e-05,
      "loss": 0.1387,
      "step": 2490
    },
    {
      "epoch": 0.2676946139843666,
      "grad_norm": 0.2394057810306549,
      "learning_rate": 4.866420387621801e-05,
      "loss": 0.1705,
      "step": 2500
    },
    {
      "epoch": 0.2687653924403041,
      "grad_norm": 0.17229585349559784,
      "learning_rate": 4.865884998393832e-05,
      "loss": 0.1688,
      "step": 2510
    },
    {
      "epoch": 0.26983617089624157,
      "grad_norm": 0.19950196146965027,
      "learning_rate": 4.865349609165864e-05,
      "loss": 0.1574,
      "step": 2520
    },
    {
      "epoch": 0.270906949352179,
      "grad_norm": 0.21412712335586548,
      "learning_rate": 4.8648142199378946e-05,
      "loss": 0.1359,
      "step": 2530
    },
    {
      "epoch": 0.2719777278081165,
      "grad_norm": 0.18519987165927887,
      "learning_rate": 4.8642788307099264e-05,
      "loss": 0.1485,
      "step": 2540
    },
    {
      "epoch": 0.27304850626405397,
      "grad_norm": 0.19655971229076385,
      "learning_rate": 4.8637434414819576e-05,
      "loss": 0.1655,
      "step": 2550
    },
    {
      "epoch": 0.2741192847199914,
      "grad_norm": 0.15657290816307068,
      "learning_rate": 4.8632080522539894e-05,
      "loss": 0.1582,
      "step": 2560
    },
    {
      "epoch": 0.2751900631759289,
      "grad_norm": 0.21062637865543365,
      "learning_rate": 4.86267266302602e-05,
      "loss": 0.1586,
      "step": 2570
    },
    {
      "epoch": 0.27626084163186637,
      "grad_norm": 0.18236613273620605,
      "learning_rate": 4.8621372737980517e-05,
      "loss": 0.1606,
      "step": 2580
    },
    {
      "epoch": 0.2773316200878038,
      "grad_norm": 0.16654729843139648,
      "learning_rate": 4.861601884570083e-05,
      "loss": 0.1555,
      "step": 2590
    },
    {
      "epoch": 0.2784023985437413,
      "grad_norm": 0.24552924931049347,
      "learning_rate": 4.861066495342114e-05,
      "loss": 0.1736,
      "step": 2600
    },
    {
      "epoch": 0.2794731769996788,
      "grad_norm": 0.18447375297546387,
      "learning_rate": 4.860531106114145e-05,
      "loss": 0.1647,
      "step": 2610
    },
    {
      "epoch": 0.2805439554556162,
      "grad_norm": 0.15656279027462006,
      "learning_rate": 4.859995716886176e-05,
      "loss": 0.1498,
      "step": 2620
    },
    {
      "epoch": 0.28161473391155367,
      "grad_norm": 0.1631057858467102,
      "learning_rate": 4.859460327658208e-05,
      "loss": 0.1667,
      "step": 2630
    },
    {
      "epoch": 0.2826855123674912,
      "grad_norm": 0.20735900104045868,
      "learning_rate": 4.8589249384302385e-05,
      "loss": 0.1725,
      "step": 2640
    },
    {
      "epoch": 0.2837562908234286,
      "grad_norm": 0.22140726447105408,
      "learning_rate": 4.85838954920227e-05,
      "loss": 0.1788,
      "step": 2650
    },
    {
      "epoch": 0.2848270692793661,
      "grad_norm": 0.1880957931280136,
      "learning_rate": 4.8578541599743015e-05,
      "loss": 0.1488,
      "step": 2660
    },
    {
      "epoch": 0.2858978477353036,
      "grad_norm": 0.18763534724712372,
      "learning_rate": 4.857318770746333e-05,
      "loss": 0.1827,
      "step": 2670
    },
    {
      "epoch": 0.286968626191241,
      "grad_norm": 0.19480758905410767,
      "learning_rate": 4.856783381518364e-05,
      "loss": 0.1521,
      "step": 2680
    },
    {
      "epoch": 0.2880394046471785,
      "grad_norm": 0.2245582789182663,
      "learning_rate": 4.8562479922903956e-05,
      "loss": 0.1703,
      "step": 2690
    },
    {
      "epoch": 0.289110183103116,
      "grad_norm": 0.15819591283798218,
      "learning_rate": 4.855712603062427e-05,
      "loss": 0.1519,
      "step": 2700
    },
    {
      "epoch": 0.29018096155905343,
      "grad_norm": 0.19559451937675476,
      "learning_rate": 4.855177213834458e-05,
      "loss": 0.1659,
      "step": 2710
    },
    {
      "epoch": 0.2912517400149909,
      "grad_norm": 0.24823759496212006,
      "learning_rate": 4.854641824606489e-05,
      "loss": 0.1447,
      "step": 2720
    },
    {
      "epoch": 0.2923225184709284,
      "grad_norm": 0.16672763228416443,
      "learning_rate": 4.85410643537852e-05,
      "loss": 0.1674,
      "step": 2730
    },
    {
      "epoch": 0.29339329692686583,
      "grad_norm": 0.2694936692714691,
      "learning_rate": 4.853571046150552e-05,
      "loss": 0.1722,
      "step": 2740
    },
    {
      "epoch": 0.2944640753828033,
      "grad_norm": 0.16878172755241394,
      "learning_rate": 4.853035656922583e-05,
      "loss": 0.1361,
      "step": 2750
    },
    {
      "epoch": 0.2955348538387408,
      "grad_norm": 0.25876742601394653,
      "learning_rate": 4.852500267694614e-05,
      "loss": 0.1533,
      "step": 2760
    },
    {
      "epoch": 0.29660563229467823,
      "grad_norm": 0.15831239521503448,
      "learning_rate": 4.8519648784666454e-05,
      "loss": 0.1339,
      "step": 2770
    },
    {
      "epoch": 0.2976764107506157,
      "grad_norm": 0.2136993408203125,
      "learning_rate": 4.851429489238677e-05,
      "loss": 0.1422,
      "step": 2780
    },
    {
      "epoch": 0.2987471892065532,
      "grad_norm": 0.14926019310951233,
      "learning_rate": 4.8508941000107076e-05,
      "loss": 0.1471,
      "step": 2790
    },
    {
      "epoch": 0.29981796766249064,
      "grad_norm": 0.17246977984905243,
      "learning_rate": 4.8503587107827394e-05,
      "loss": 0.1599,
      "step": 2800
    },
    {
      "epoch": 0.3008887461184281,
      "grad_norm": 0.19388410449028015,
      "learning_rate": 4.8498233215547706e-05,
      "loss": 0.1552,
      "step": 2810
    },
    {
      "epoch": 0.3019595245743656,
      "grad_norm": 0.1837635189294815,
      "learning_rate": 4.849287932326802e-05,
      "loss": 0.1497,
      "step": 2820
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 0.16616491973400116,
      "learning_rate": 4.848752543098833e-05,
      "loss": 0.1513,
      "step": 2830
    },
    {
      "epoch": 0.3041010814862405,
      "grad_norm": 0.216473788022995,
      "learning_rate": 4.848217153870864e-05,
      "loss": 0.1471,
      "step": 2840
    },
    {
      "epoch": 0.30517185994217794,
      "grad_norm": 0.21637669205665588,
      "learning_rate": 4.847681764642896e-05,
      "loss": 0.1506,
      "step": 2850
    },
    {
      "epoch": 0.30624263839811544,
      "grad_norm": 0.14449775218963623,
      "learning_rate": 4.847146375414927e-05,
      "loss": 0.1549,
      "step": 2860
    },
    {
      "epoch": 0.3073134168540529,
      "grad_norm": 0.23304736614227295,
      "learning_rate": 4.846610986186958e-05,
      "loss": 0.1573,
      "step": 2870
    },
    {
      "epoch": 0.30838419530999034,
      "grad_norm": 0.14818497002124786,
      "learning_rate": 4.846075596958989e-05,
      "loss": 0.1465,
      "step": 2880
    },
    {
      "epoch": 0.30945497376592784,
      "grad_norm": 0.25244730710983276,
      "learning_rate": 4.845540207731021e-05,
      "loss": 0.1576,
      "step": 2890
    },
    {
      "epoch": 0.3105257522218653,
      "grad_norm": 0.1898231953382492,
      "learning_rate": 4.845004818503052e-05,
      "loss": 0.1671,
      "step": 2900
    },
    {
      "epoch": 0.31159653067780274,
      "grad_norm": 0.18279127776622772,
      "learning_rate": 4.8444694292750833e-05,
      "loss": 0.1581,
      "step": 2910
    },
    {
      "epoch": 0.31266730913374025,
      "grad_norm": 0.25181469321250916,
      "learning_rate": 4.8439340400471145e-05,
      "loss": 0.1496,
      "step": 2920
    },
    {
      "epoch": 0.3137380875896777,
      "grad_norm": 0.1598006635904312,
      "learning_rate": 4.8433986508191456e-05,
      "loss": 0.1441,
      "step": 2930
    },
    {
      "epoch": 0.31480886604561514,
      "grad_norm": 0.1749616116285324,
      "learning_rate": 4.842863261591177e-05,
      "loss": 0.1564,
      "step": 2940
    },
    {
      "epoch": 0.31587964450155265,
      "grad_norm": 0.17092512547969818,
      "learning_rate": 4.842327872363208e-05,
      "loss": 0.161,
      "step": 2950
    },
    {
      "epoch": 0.3169504229574901,
      "grad_norm": 0.25807541608810425,
      "learning_rate": 4.84179248313524e-05,
      "loss": 0.1535,
      "step": 2960
    },
    {
      "epoch": 0.31802120141342755,
      "grad_norm": 0.20119254291057587,
      "learning_rate": 4.841257093907271e-05,
      "loss": 0.1469,
      "step": 2970
    },
    {
      "epoch": 0.31909197986936505,
      "grad_norm": 0.27577444911003113,
      "learning_rate": 4.840721704679302e-05,
      "loss": 0.1519,
      "step": 2980
    },
    {
      "epoch": 0.3201627583253025,
      "grad_norm": 0.1964644193649292,
      "learning_rate": 4.840186315451333e-05,
      "loss": 0.1406,
      "step": 2990
    },
    {
      "epoch": 0.32123353678123995,
      "grad_norm": 0.2138315588235855,
      "learning_rate": 4.839650926223365e-05,
      "loss": 0.1441,
      "step": 3000
    },
    {
      "epoch": 0.32230431523717745,
      "grad_norm": 0.19604334235191345,
      "learning_rate": 4.839115536995396e-05,
      "loss": 0.2062,
      "step": 3010
    },
    {
      "epoch": 0.3233750936931149,
      "grad_norm": 0.18162113428115845,
      "learning_rate": 4.838580147767427e-05,
      "loss": 0.1623,
      "step": 3020
    },
    {
      "epoch": 0.32444587214905235,
      "grad_norm": 0.10488094389438629,
      "learning_rate": 4.8380447585394584e-05,
      "loss": 0.1553,
      "step": 3030
    },
    {
      "epoch": 0.32551665060498985,
      "grad_norm": 0.172133207321167,
      "learning_rate": 4.8375093693114895e-05,
      "loss": 0.1484,
      "step": 3040
    },
    {
      "epoch": 0.3265874290609273,
      "grad_norm": 0.14887729287147522,
      "learning_rate": 4.836973980083521e-05,
      "loss": 0.1429,
      "step": 3050
    },
    {
      "epoch": 0.32765820751686475,
      "grad_norm": 0.21591146290302277,
      "learning_rate": 4.836438590855552e-05,
      "loss": 0.1768,
      "step": 3060
    },
    {
      "epoch": 0.3287289859728022,
      "grad_norm": 0.20904667675495148,
      "learning_rate": 4.8359032016275836e-05,
      "loss": 0.1528,
      "step": 3070
    },
    {
      "epoch": 0.3297997644287397,
      "grad_norm": 0.18627554178237915,
      "learning_rate": 4.835367812399615e-05,
      "loss": 0.1771,
      "step": 3080
    },
    {
      "epoch": 0.33087054288467715,
      "grad_norm": 0.1825820952653885,
      "learning_rate": 4.834832423171646e-05,
      "loss": 0.1466,
      "step": 3090
    },
    {
      "epoch": 0.3319413213406146,
      "grad_norm": 0.41517940163612366,
      "learning_rate": 4.834297033943677e-05,
      "loss": 0.1632,
      "step": 3100
    },
    {
      "epoch": 0.3330120997965521,
      "grad_norm": 0.21192406117916107,
      "learning_rate": 4.833761644715709e-05,
      "loss": 0.1415,
      "step": 3110
    },
    {
      "epoch": 0.33408287825248956,
      "grad_norm": 0.16895008087158203,
      "learning_rate": 4.83322625548774e-05,
      "loss": 0.1482,
      "step": 3120
    },
    {
      "epoch": 0.335153656708427,
      "grad_norm": 0.11415281891822815,
      "learning_rate": 4.832690866259771e-05,
      "loss": 0.1341,
      "step": 3130
    },
    {
      "epoch": 0.3362244351643645,
      "grad_norm": 0.20272867381572723,
      "learning_rate": 4.832155477031802e-05,
      "loss": 0.1664,
      "step": 3140
    },
    {
      "epoch": 0.33729521362030196,
      "grad_norm": 0.2346840649843216,
      "learning_rate": 4.8316200878038334e-05,
      "loss": 0.1507,
      "step": 3150
    },
    {
      "epoch": 0.3383659920762394,
      "grad_norm": 0.18764632940292358,
      "learning_rate": 4.831084698575865e-05,
      "loss": 0.1382,
      "step": 3160
    },
    {
      "epoch": 0.3394367705321769,
      "grad_norm": 0.24881191551685333,
      "learning_rate": 4.830549309347896e-05,
      "loss": 0.1581,
      "step": 3170
    },
    {
      "epoch": 0.34050754898811436,
      "grad_norm": 0.14984272420406342,
      "learning_rate": 4.8300139201199275e-05,
      "loss": 0.1376,
      "step": 3180
    },
    {
      "epoch": 0.3415783274440518,
      "grad_norm": 0.11522866785526276,
      "learning_rate": 4.8294785308919587e-05,
      "loss": 0.1347,
      "step": 3190
    },
    {
      "epoch": 0.3426491058999893,
      "grad_norm": 0.1866218000650406,
      "learning_rate": 4.8289431416639905e-05,
      "loss": 0.1454,
      "step": 3200
    },
    {
      "epoch": 0.34371988435592676,
      "grad_norm": 0.2625761032104492,
      "learning_rate": 4.828407752436021e-05,
      "loss": 0.1411,
      "step": 3210
    },
    {
      "epoch": 0.3447906628118642,
      "grad_norm": 0.18897053599357605,
      "learning_rate": 4.827872363208053e-05,
      "loss": 0.1428,
      "step": 3220
    },
    {
      "epoch": 0.3458614412678017,
      "grad_norm": 0.18715810775756836,
      "learning_rate": 4.827336973980084e-05,
      "loss": 0.1369,
      "step": 3230
    },
    {
      "epoch": 0.34693221972373917,
      "grad_norm": 0.15229135751724243,
      "learning_rate": 4.826801584752115e-05,
      "loss": 0.1522,
      "step": 3240
    },
    {
      "epoch": 0.3480029981796766,
      "grad_norm": 0.1383456289768219,
      "learning_rate": 4.826266195524146e-05,
      "loss": 0.1481,
      "step": 3250
    },
    {
      "epoch": 0.3490737766356141,
      "grad_norm": 0.23272007703781128,
      "learning_rate": 4.825730806296177e-05,
      "loss": 0.1517,
      "step": 3260
    },
    {
      "epoch": 0.35014455509155157,
      "grad_norm": 0.23888574540615082,
      "learning_rate": 4.825195417068209e-05,
      "loss": 0.1543,
      "step": 3270
    },
    {
      "epoch": 0.351215333547489,
      "grad_norm": 0.1715420037508011,
      "learning_rate": 4.8246600278402396e-05,
      "loss": 0.1473,
      "step": 3280
    },
    {
      "epoch": 0.35228611200342647,
      "grad_norm": 0.19227077066898346,
      "learning_rate": 4.8241246386122714e-05,
      "loss": 0.1458,
      "step": 3290
    },
    {
      "epoch": 0.35335689045936397,
      "grad_norm": 0.1921381652355194,
      "learning_rate": 4.8235892493843025e-05,
      "loss": 0.1495,
      "step": 3300
    },
    {
      "epoch": 0.3544276689153014,
      "grad_norm": 0.197117879986763,
      "learning_rate": 4.8230538601563344e-05,
      "loss": 0.1521,
      "step": 3310
    },
    {
      "epoch": 0.35549844737123887,
      "grad_norm": 0.24075248837471008,
      "learning_rate": 4.822518470928365e-05,
      "loss": 0.1516,
      "step": 3320
    },
    {
      "epoch": 0.3565692258271764,
      "grad_norm": 0.3035446107387543,
      "learning_rate": 4.8219830817003966e-05,
      "loss": 0.1543,
      "step": 3330
    },
    {
      "epoch": 0.3576400042831138,
      "grad_norm": 0.2685508131980896,
      "learning_rate": 4.821447692472428e-05,
      "loss": 0.1554,
      "step": 3340
    },
    {
      "epoch": 0.35871078273905127,
      "grad_norm": 0.7812888622283936,
      "learning_rate": 4.820912303244459e-05,
      "loss": 0.1394,
      "step": 3350
    },
    {
      "epoch": 0.3597815611949888,
      "grad_norm": 0.26806795597076416,
      "learning_rate": 4.82037691401649e-05,
      "loss": 0.1618,
      "step": 3360
    },
    {
      "epoch": 0.3608523396509262,
      "grad_norm": 0.14959487318992615,
      "learning_rate": 4.819841524788521e-05,
      "loss": 0.1572,
      "step": 3370
    },
    {
      "epoch": 0.3619231181068637,
      "grad_norm": 0.24507157504558563,
      "learning_rate": 4.819306135560553e-05,
      "loss": 0.1718,
      "step": 3380
    },
    {
      "epoch": 0.3629938965628012,
      "grad_norm": 0.2049155831336975,
      "learning_rate": 4.818770746332584e-05,
      "loss": 0.1519,
      "step": 3390
    },
    {
      "epoch": 0.3640646750187386,
      "grad_norm": 0.22254368662834167,
      "learning_rate": 4.818235357104615e-05,
      "loss": 0.1683,
      "step": 3400
    },
    {
      "epoch": 0.3651354534746761,
      "grad_norm": 0.1445188969373703,
      "learning_rate": 4.8176999678766464e-05,
      "loss": 0.1267,
      "step": 3410
    },
    {
      "epoch": 0.3662062319306136,
      "grad_norm": 0.3151285648345947,
      "learning_rate": 4.817164578648678e-05,
      "loss": 0.1568,
      "step": 3420
    },
    {
      "epoch": 0.36727701038655103,
      "grad_norm": 0.5569368600845337,
      "learning_rate": 4.816629189420709e-05,
      "loss": 0.156,
      "step": 3430
    },
    {
      "epoch": 0.3683477888424885,
      "grad_norm": 0.14941073954105377,
      "learning_rate": 4.8160938001927405e-05,
      "loss": 0.1278,
      "step": 3440
    },
    {
      "epoch": 0.369418567298426,
      "grad_norm": 0.3666149377822876,
      "learning_rate": 4.815558410964772e-05,
      "loss": 0.1348,
      "step": 3450
    },
    {
      "epoch": 0.37048934575436343,
      "grad_norm": 0.1878468245267868,
      "learning_rate": 4.815023021736803e-05,
      "loss": 0.1345,
      "step": 3460
    },
    {
      "epoch": 0.3715601242103009,
      "grad_norm": 0.19347308576107025,
      "learning_rate": 4.814487632508834e-05,
      "loss": 0.1369,
      "step": 3470
    },
    {
      "epoch": 0.37263090266623833,
      "grad_norm": 0.17221061885356903,
      "learning_rate": 4.813952243280865e-05,
      "loss": 0.1446,
      "step": 3480
    },
    {
      "epoch": 0.37370168112217583,
      "grad_norm": 0.18163621425628662,
      "learning_rate": 4.813416854052897e-05,
      "loss": 0.1434,
      "step": 3490
    },
    {
      "epoch": 0.3747724595781133,
      "grad_norm": 0.16650079190731049,
      "learning_rate": 4.812881464824928e-05,
      "loss": 0.1453,
      "step": 3500
    },
    {
      "epoch": 0.37584323803405073,
      "grad_norm": 0.1608285903930664,
      "learning_rate": 4.812346075596959e-05,
      "loss": 0.1472,
      "step": 3510
    },
    {
      "epoch": 0.37691401648998824,
      "grad_norm": 0.16849495470523834,
      "learning_rate": 4.8118106863689903e-05,
      "loss": 0.1436,
      "step": 3520
    },
    {
      "epoch": 0.3779847949459257,
      "grad_norm": 0.12362155318260193,
      "learning_rate": 4.811275297141022e-05,
      "loss": 0.1328,
      "step": 3530
    },
    {
      "epoch": 0.37905557340186313,
      "grad_norm": 0.20127423107624054,
      "learning_rate": 4.810739907913053e-05,
      "loss": 0.1531,
      "step": 3540
    },
    {
      "epoch": 0.38012635185780064,
      "grad_norm": 0.14692583680152893,
      "learning_rate": 4.8102045186850844e-05,
      "loss": 0.1298,
      "step": 3550
    },
    {
      "epoch": 0.3811971303137381,
      "grad_norm": 0.40173617005348206,
      "learning_rate": 4.8096691294571156e-05,
      "loss": 0.1373,
      "step": 3560
    },
    {
      "epoch": 0.38226790876967554,
      "grad_norm": 0.4163248836994171,
      "learning_rate": 4.809133740229147e-05,
      "loss": 0.1385,
      "step": 3570
    },
    {
      "epoch": 0.38333868722561304,
      "grad_norm": 0.14853714406490326,
      "learning_rate": 4.808598351001178e-05,
      "loss": 0.1529,
      "step": 3580
    },
    {
      "epoch": 0.3844094656815505,
      "grad_norm": 0.11638674885034561,
      "learning_rate": 4.808062961773209e-05,
      "loss": 0.1328,
      "step": 3590
    },
    {
      "epoch": 0.38548024413748794,
      "grad_norm": 0.13692286610603333,
      "learning_rate": 4.807527572545241e-05,
      "loss": 0.1303,
      "step": 3600
    },
    {
      "epoch": 0.38655102259342544,
      "grad_norm": 0.19880002737045288,
      "learning_rate": 4.806992183317272e-05,
      "loss": 0.1421,
      "step": 3610
    },
    {
      "epoch": 0.3876218010493629,
      "grad_norm": 0.19695430994033813,
      "learning_rate": 4.806456794089303e-05,
      "loss": 0.1372,
      "step": 3620
    },
    {
      "epoch": 0.38869257950530034,
      "grad_norm": 0.10909546911716461,
      "learning_rate": 4.805921404861334e-05,
      "loss": 0.1357,
      "step": 3630
    },
    {
      "epoch": 0.38976335796123784,
      "grad_norm": 0.4945143163204193,
      "learning_rate": 4.805386015633366e-05,
      "loss": 0.1468,
      "step": 3640
    },
    {
      "epoch": 0.3908341364171753,
      "grad_norm": 0.21996670961380005,
      "learning_rate": 4.804850626405397e-05,
      "loss": 0.1527,
      "step": 3650
    },
    {
      "epoch": 0.39190491487311274,
      "grad_norm": 0.5786020159721375,
      "learning_rate": 4.804315237177428e-05,
      "loss": 0.1398,
      "step": 3660
    },
    {
      "epoch": 0.39297569332905025,
      "grad_norm": 0.34130948781967163,
      "learning_rate": 4.8037798479494595e-05,
      "loss": 0.1539,
      "step": 3670
    },
    {
      "epoch": 0.3940464717849877,
      "grad_norm": 0.118926502764225,
      "learning_rate": 4.8032444587214906e-05,
      "loss": 0.1289,
      "step": 3680
    },
    {
      "epoch": 0.39511725024092514,
      "grad_norm": 0.20633290708065033,
      "learning_rate": 4.8027090694935224e-05,
      "loss": 0.1556,
      "step": 3690
    },
    {
      "epoch": 0.3961880286968626,
      "grad_norm": 0.20825515687465668,
      "learning_rate": 4.802173680265553e-05,
      "loss": 0.1444,
      "step": 3700
    },
    {
      "epoch": 0.3972588071528001,
      "grad_norm": 0.1829787939786911,
      "learning_rate": 4.801638291037585e-05,
      "loss": 0.143,
      "step": 3710
    },
    {
      "epoch": 0.39832958560873755,
      "grad_norm": 0.1495545506477356,
      "learning_rate": 4.801102901809616e-05,
      "loss": 0.1449,
      "step": 3720
    },
    {
      "epoch": 0.399400364064675,
      "grad_norm": 0.1543925702571869,
      "learning_rate": 4.800567512581647e-05,
      "loss": 0.1263,
      "step": 3730
    },
    {
      "epoch": 0.4004711425206125,
      "grad_norm": 0.20740659534931183,
      "learning_rate": 4.800032123353678e-05,
      "loss": 0.139,
      "step": 3740
    },
    {
      "epoch": 0.40154192097654995,
      "grad_norm": 0.1723191887140274,
      "learning_rate": 4.79949673412571e-05,
      "loss": 0.1469,
      "step": 3750
    },
    {
      "epoch": 0.4026126994324874,
      "grad_norm": 0.2730163037776947,
      "learning_rate": 4.798961344897741e-05,
      "loss": 0.1384,
      "step": 3760
    },
    {
      "epoch": 0.4036834778884249,
      "grad_norm": 0.36476457118988037,
      "learning_rate": 4.798425955669772e-05,
      "loss": 0.1374,
      "step": 3770
    },
    {
      "epoch": 0.40475425634436235,
      "grad_norm": 0.14328473806381226,
      "learning_rate": 4.7978905664418034e-05,
      "loss": 0.1399,
      "step": 3780
    },
    {
      "epoch": 0.4058250348002998,
      "grad_norm": 0.5888113379478455,
      "learning_rate": 4.7973551772138345e-05,
      "loss": 0.1463,
      "step": 3790
    },
    {
      "epoch": 0.4068958132562373,
      "grad_norm": 0.14520958065986633,
      "learning_rate": 4.796819787985866e-05,
      "loss": 0.1143,
      "step": 3800
    },
    {
      "epoch": 0.40796659171217475,
      "grad_norm": 0.18241308629512787,
      "learning_rate": 4.796284398757897e-05,
      "loss": 0.1629,
      "step": 3810
    },
    {
      "epoch": 0.4090373701681122,
      "grad_norm": 0.13209648430347443,
      "learning_rate": 4.7957490095299286e-05,
      "loss": 0.1307,
      "step": 3820
    },
    {
      "epoch": 0.4101081486240497,
      "grad_norm": 0.20704424381256104,
      "learning_rate": 4.79521362030196e-05,
      "loss": 0.1452,
      "step": 3830
    },
    {
      "epoch": 0.41117892707998716,
      "grad_norm": 0.2723501920700073,
      "learning_rate": 4.7946782310739916e-05,
      "loss": 0.1439,
      "step": 3840
    },
    {
      "epoch": 0.4122497055359246,
      "grad_norm": 0.19081565737724304,
      "learning_rate": 4.794142841846022e-05,
      "loss": 0.143,
      "step": 3850
    },
    {
      "epoch": 0.4133204839918621,
      "grad_norm": 0.13857989013195038,
      "learning_rate": 4.793607452618054e-05,
      "loss": 0.1331,
      "step": 3860
    },
    {
      "epoch": 0.41439126244779956,
      "grad_norm": 0.1671372801065445,
      "learning_rate": 4.793072063390085e-05,
      "loss": 0.1369,
      "step": 3870
    },
    {
      "epoch": 0.415462040903737,
      "grad_norm": 0.16384351253509521,
      "learning_rate": 4.792536674162116e-05,
      "loss": 0.1428,
      "step": 3880
    },
    {
      "epoch": 0.4165328193596745,
      "grad_norm": 0.21459108591079712,
      "learning_rate": 4.792001284934147e-05,
      "loss": 0.1354,
      "step": 3890
    },
    {
      "epoch": 0.41760359781561196,
      "grad_norm": 0.20992928743362427,
      "learning_rate": 4.7914658957061784e-05,
      "loss": 0.1349,
      "step": 3900
    },
    {
      "epoch": 0.4186743762715494,
      "grad_norm": 0.12441480159759521,
      "learning_rate": 4.79093050647821e-05,
      "loss": 0.1511,
      "step": 3910
    },
    {
      "epoch": 0.41974515472748686,
      "grad_norm": 0.21786783635616302,
      "learning_rate": 4.790395117250241e-05,
      "loss": 0.1481,
      "step": 3920
    },
    {
      "epoch": 0.42081593318342436,
      "grad_norm": 0.14700236916542053,
      "learning_rate": 4.7898597280222725e-05,
      "loss": 0.152,
      "step": 3930
    },
    {
      "epoch": 0.4218867116393618,
      "grad_norm": 0.17422722280025482,
      "learning_rate": 4.7893243387943036e-05,
      "loss": 0.1333,
      "step": 3940
    },
    {
      "epoch": 0.42295749009529926,
      "grad_norm": 0.167353555560112,
      "learning_rate": 4.7887889495663355e-05,
      "loss": 0.143,
      "step": 3950
    },
    {
      "epoch": 0.42402826855123676,
      "grad_norm": 0.22075395286083221,
      "learning_rate": 4.788253560338366e-05,
      "loss": 0.1544,
      "step": 3960
    },
    {
      "epoch": 0.4250990470071742,
      "grad_norm": 0.23730871081352234,
      "learning_rate": 4.787718171110398e-05,
      "loss": 0.1449,
      "step": 3970
    },
    {
      "epoch": 0.42616982546311166,
      "grad_norm": 0.18583816289901733,
      "learning_rate": 4.787182781882429e-05,
      "loss": 0.148,
      "step": 3980
    },
    {
      "epoch": 0.42724060391904917,
      "grad_norm": 0.2141389548778534,
      "learning_rate": 4.78664739265446e-05,
      "loss": 0.1279,
      "step": 3990
    },
    {
      "epoch": 0.4283113823749866,
      "grad_norm": 0.1820363998413086,
      "learning_rate": 4.786112003426491e-05,
      "loss": 0.1613,
      "step": 4000
    },
    {
      "epoch": 0.42938216083092406,
      "grad_norm": 0.26216158270835876,
      "learning_rate": 4.785576614198522e-05,
      "loss": 0.156,
      "step": 4010
    },
    {
      "epoch": 0.43045293928686157,
      "grad_norm": 0.1583825945854187,
      "learning_rate": 4.785041224970554e-05,
      "loss": 0.1281,
      "step": 4020
    },
    {
      "epoch": 0.431523717742799,
      "grad_norm": 0.19063200056552887,
      "learning_rate": 4.7845058357425846e-05,
      "loss": 0.1501,
      "step": 4030
    },
    {
      "epoch": 0.43259449619873647,
      "grad_norm": 0.28647810220718384,
      "learning_rate": 4.7839704465146164e-05,
      "loss": 0.1313,
      "step": 4040
    },
    {
      "epoch": 0.43366527465467397,
      "grad_norm": 0.1935541033744812,
      "learning_rate": 4.7834350572866475e-05,
      "loss": 0.1537,
      "step": 4050
    },
    {
      "epoch": 0.4347360531106114,
      "grad_norm": 0.5165702104568481,
      "learning_rate": 4.7828996680586794e-05,
      "loss": 0.1292,
      "step": 4060
    },
    {
      "epoch": 0.43580683156654887,
      "grad_norm": 0.14314410090446472,
      "learning_rate": 4.78236427883071e-05,
      "loss": 0.133,
      "step": 4070
    },
    {
      "epoch": 0.4368776100224864,
      "grad_norm": 0.12758104503154755,
      "learning_rate": 4.7818288896027416e-05,
      "loss": 0.1397,
      "step": 4080
    },
    {
      "epoch": 0.4379483884784238,
      "grad_norm": 0.15040145814418793,
      "learning_rate": 4.781293500374773e-05,
      "loss": 0.1458,
      "step": 4090
    },
    {
      "epoch": 0.43901916693436127,
      "grad_norm": 0.24312801659107208,
      "learning_rate": 4.780758111146804e-05,
      "loss": 0.1504,
      "step": 4100
    },
    {
      "epoch": 0.4400899453902987,
      "grad_norm": 0.14555059373378754,
      "learning_rate": 4.780222721918835e-05,
      "loss": 0.1344,
      "step": 4110
    },
    {
      "epoch": 0.4411607238462362,
      "grad_norm": 0.1598103642463684,
      "learning_rate": 4.779687332690866e-05,
      "loss": 0.1526,
      "step": 4120
    },
    {
      "epoch": 0.4422315023021737,
      "grad_norm": 0.14827103912830353,
      "learning_rate": 4.779151943462898e-05,
      "loss": 0.1546,
      "step": 4130
    },
    {
      "epoch": 0.4433022807581111,
      "grad_norm": 0.21433575451374054,
      "learning_rate": 4.778616554234929e-05,
      "loss": 0.1323,
      "step": 4140
    },
    {
      "epoch": 0.4443730592140486,
      "grad_norm": 0.13513590395450592,
      "learning_rate": 4.77808116500696e-05,
      "loss": 0.1411,
      "step": 4150
    },
    {
      "epoch": 0.4454438376699861,
      "grad_norm": 0.16275474429130554,
      "learning_rate": 4.7775457757789914e-05,
      "loss": 0.1388,
      "step": 4160
    },
    {
      "epoch": 0.4465146161259235,
      "grad_norm": 0.10638078302145004,
      "learning_rate": 4.777010386551023e-05,
      "loss": 0.1444,
      "step": 4170
    },
    {
      "epoch": 0.44758539458186103,
      "grad_norm": 0.23223483562469482,
      "learning_rate": 4.776474997323054e-05,
      "loss": 0.1308,
      "step": 4180
    },
    {
      "epoch": 0.4486561730377985,
      "grad_norm": 0.20232778787612915,
      "learning_rate": 4.7759396080950855e-05,
      "loss": 0.1366,
      "step": 4190
    },
    {
      "epoch": 0.4497269514937359,
      "grad_norm": 0.09969858080148697,
      "learning_rate": 4.775404218867117e-05,
      "loss": 0.1079,
      "step": 4200
    },
    {
      "epoch": 0.45079772994967343,
      "grad_norm": 0.1511114090681076,
      "learning_rate": 4.774868829639148e-05,
      "loss": 0.1377,
      "step": 4210
    },
    {
      "epoch": 0.4518685084056109,
      "grad_norm": 0.17791742086410522,
      "learning_rate": 4.774333440411179e-05,
      "loss": 0.139,
      "step": 4220
    },
    {
      "epoch": 0.45293928686154833,
      "grad_norm": 0.18622499704360962,
      "learning_rate": 4.77379805118321e-05,
      "loss": 0.1376,
      "step": 4230
    },
    {
      "epoch": 0.45401006531748583,
      "grad_norm": 0.2870626747608185,
      "learning_rate": 4.773262661955242e-05,
      "loss": 0.1755,
      "step": 4240
    },
    {
      "epoch": 0.4550808437734233,
      "grad_norm": 0.23939816653728485,
      "learning_rate": 4.772727272727273e-05,
      "loss": 0.126,
      "step": 4250
    },
    {
      "epoch": 0.45615162222936073,
      "grad_norm": 0.12820284068584442,
      "learning_rate": 4.772191883499304e-05,
      "loss": 0.1594,
      "step": 4260
    },
    {
      "epoch": 0.45722240068529824,
      "grad_norm": 0.20114943385124207,
      "learning_rate": 4.771656494271335e-05,
      "loss": 0.1417,
      "step": 4270
    },
    {
      "epoch": 0.4582931791412357,
      "grad_norm": 0.20344571769237518,
      "learning_rate": 4.771121105043367e-05,
      "loss": 0.1485,
      "step": 4280
    },
    {
      "epoch": 0.45936395759717313,
      "grad_norm": 0.22007985413074493,
      "learning_rate": 4.770585715815398e-05,
      "loss": 0.1483,
      "step": 4290
    },
    {
      "epoch": 0.46043473605311064,
      "grad_norm": 0.15652865171432495,
      "learning_rate": 4.7700503265874294e-05,
      "loss": 0.1389,
      "step": 4300
    },
    {
      "epoch": 0.4615055145090481,
      "grad_norm": 0.22295670211315155,
      "learning_rate": 4.7695149373594606e-05,
      "loss": 0.1295,
      "step": 4310
    },
    {
      "epoch": 0.46257629296498554,
      "grad_norm": 0.11707602441310883,
      "learning_rate": 4.768979548131492e-05,
      "loss": 0.1306,
      "step": 4320
    },
    {
      "epoch": 0.463647071420923,
      "grad_norm": 0.2632354497909546,
      "learning_rate": 4.7684441589035235e-05,
      "loss": 0.1381,
      "step": 4330
    },
    {
      "epoch": 0.4647178498768605,
      "grad_norm": 0.20694825053215027,
      "learning_rate": 4.767908769675554e-05,
      "loss": 0.1384,
      "step": 4340
    },
    {
      "epoch": 0.46578862833279794,
      "grad_norm": 0.1543104648590088,
      "learning_rate": 4.767373380447586e-05,
      "loss": 0.1282,
      "step": 4350
    },
    {
      "epoch": 0.4668594067887354,
      "grad_norm": 0.15347251296043396,
      "learning_rate": 4.766837991219617e-05,
      "loss": 0.1511,
      "step": 4360
    },
    {
      "epoch": 0.4679301852446729,
      "grad_norm": 0.17378295958042145,
      "learning_rate": 4.766302601991648e-05,
      "loss": 0.1367,
      "step": 4370
    },
    {
      "epoch": 0.46900096370061034,
      "grad_norm": 0.1220964714884758,
      "learning_rate": 4.765767212763679e-05,
      "loss": 0.1275,
      "step": 4380
    },
    {
      "epoch": 0.4700717421565478,
      "grad_norm": 0.19954128563404083,
      "learning_rate": 4.765231823535711e-05,
      "loss": 0.1405,
      "step": 4390
    },
    {
      "epoch": 0.4711425206124853,
      "grad_norm": 0.19368618726730347,
      "learning_rate": 4.764696434307742e-05,
      "loss": 0.147,
      "step": 4400
    },
    {
      "epoch": 0.47221329906842274,
      "grad_norm": 0.1941821426153183,
      "learning_rate": 4.764161045079773e-05,
      "loss": 0.1398,
      "step": 4410
    },
    {
      "epoch": 0.4732840775243602,
      "grad_norm": 0.2926008105278015,
      "learning_rate": 4.7636256558518045e-05,
      "loss": 0.1409,
      "step": 4420
    },
    {
      "epoch": 0.4743548559802977,
      "grad_norm": 0.1701270043849945,
      "learning_rate": 4.7630902666238356e-05,
      "loss": 0.1333,
      "step": 4430
    },
    {
      "epoch": 0.47542563443623514,
      "grad_norm": 0.19093844294548035,
      "learning_rate": 4.7625548773958674e-05,
      "loss": 0.1246,
      "step": 4440
    },
    {
      "epoch": 0.4764964128921726,
      "grad_norm": 0.16352707147598267,
      "learning_rate": 4.762019488167898e-05,
      "loss": 0.1441,
      "step": 4450
    },
    {
      "epoch": 0.4775671913481101,
      "grad_norm": 0.13298213481903076,
      "learning_rate": 4.76148409893993e-05,
      "loss": 0.1417,
      "step": 4460
    },
    {
      "epoch": 0.47863796980404755,
      "grad_norm": 0.1546713411808014,
      "learning_rate": 4.760948709711961e-05,
      "loss": 0.1571,
      "step": 4470
    },
    {
      "epoch": 0.479708748259985,
      "grad_norm": 0.19771122932434082,
      "learning_rate": 4.7604133204839927e-05,
      "loss": 0.2044,
      "step": 4480
    },
    {
      "epoch": 0.4807795267159225,
      "grad_norm": 0.19660980999469757,
      "learning_rate": 4.759877931256023e-05,
      "loss": 0.1604,
      "step": 4490
    },
    {
      "epoch": 0.48185030517185995,
      "grad_norm": 0.14726050198078156,
      "learning_rate": 4.759342542028055e-05,
      "loss": 0.1326,
      "step": 4500
    },
    {
      "epoch": 0.4829210836277974,
      "grad_norm": 0.27816468477249146,
      "learning_rate": 4.758807152800086e-05,
      "loss": 0.1448,
      "step": 4510
    },
    {
      "epoch": 0.4839918620837349,
      "grad_norm": 0.27727100253105164,
      "learning_rate": 4.758271763572117e-05,
      "loss": 0.1439,
      "step": 4520
    },
    {
      "epoch": 0.48506264053967235,
      "grad_norm": 0.155306875705719,
      "learning_rate": 4.7577363743441484e-05,
      "loss": 0.1316,
      "step": 4530
    },
    {
      "epoch": 0.4861334189956098,
      "grad_norm": 0.1563560962677002,
      "learning_rate": 4.7572009851161795e-05,
      "loss": 0.1273,
      "step": 4540
    },
    {
      "epoch": 0.48720419745154725,
      "grad_norm": 0.1424548476934433,
      "learning_rate": 4.756665595888211e-05,
      "loss": 0.1384,
      "step": 4550
    },
    {
      "epoch": 0.48827497590748475,
      "grad_norm": 0.16134411096572876,
      "learning_rate": 4.756130206660242e-05,
      "loss": 0.1739,
      "step": 4560
    },
    {
      "epoch": 0.4893457543634222,
      "grad_norm": 0.1403890699148178,
      "learning_rate": 4.7555948174322736e-05,
      "loss": 0.152,
      "step": 4570
    },
    {
      "epoch": 0.49041653281935965,
      "grad_norm": 0.4926012456417084,
      "learning_rate": 4.755059428204305e-05,
      "loss": 0.1174,
      "step": 4580
    },
    {
      "epoch": 0.49148731127529716,
      "grad_norm": 0.15708908438682556,
      "learning_rate": 4.7545240389763366e-05,
      "loss": 0.1424,
      "step": 4590
    },
    {
      "epoch": 0.4925580897312346,
      "grad_norm": 0.20179183781147003,
      "learning_rate": 4.753988649748367e-05,
      "loss": 0.1196,
      "step": 4600
    },
    {
      "epoch": 0.49362886818717205,
      "grad_norm": 0.15000472962856293,
      "learning_rate": 4.753453260520399e-05,
      "loss": 0.1296,
      "step": 4610
    },
    {
      "epoch": 0.49469964664310956,
      "grad_norm": 0.1531068980693817,
      "learning_rate": 4.75291787129243e-05,
      "loss": 0.111,
      "step": 4620
    },
    {
      "epoch": 0.495770425099047,
      "grad_norm": 0.08830998092889786,
      "learning_rate": 4.752382482064461e-05,
      "loss": 0.1385,
      "step": 4630
    },
    {
      "epoch": 0.49684120355498446,
      "grad_norm": 0.13441568613052368,
      "learning_rate": 4.751847092836492e-05,
      "loss": 0.1177,
      "step": 4640
    },
    {
      "epoch": 0.49791198201092196,
      "grad_norm": 0.17031824588775635,
      "learning_rate": 4.7513117036085234e-05,
      "loss": 0.1274,
      "step": 4650
    },
    {
      "epoch": 0.4989827604668594,
      "grad_norm": 0.20067168772220612,
      "learning_rate": 4.750776314380555e-05,
      "loss": 0.1327,
      "step": 4660
    },
    {
      "epoch": 0.5000535389227969,
      "grad_norm": 0.24143217504024506,
      "learning_rate": 4.750240925152586e-05,
      "loss": 0.1525,
      "step": 4670
    },
    {
      "epoch": 0.5011243173787343,
      "grad_norm": 0.25021153688430786,
      "learning_rate": 4.7497055359246175e-05,
      "loss": 0.1247,
      "step": 4680
    },
    {
      "epoch": 0.5021950958346718,
      "grad_norm": 0.262847900390625,
      "learning_rate": 4.7491701466966486e-05,
      "loss": 0.1489,
      "step": 4690
    },
    {
      "epoch": 0.5032658742906093,
      "grad_norm": 0.4699494242668152,
      "learning_rate": 4.7486347574686804e-05,
      "loss": 0.1306,
      "step": 4700
    },
    {
      "epoch": 0.5043366527465467,
      "grad_norm": 0.1541004776954651,
      "learning_rate": 4.748099368240711e-05,
      "loss": 0.1412,
      "step": 4710
    },
    {
      "epoch": 0.5054074312024842,
      "grad_norm": 0.18039485812187195,
      "learning_rate": 4.747563979012743e-05,
      "loss": 0.1377,
      "step": 4720
    },
    {
      "epoch": 0.5064782096584217,
      "grad_norm": 0.20787721872329712,
      "learning_rate": 4.747028589784774e-05,
      "loss": 0.1469,
      "step": 4730
    },
    {
      "epoch": 0.5075489881143591,
      "grad_norm": 0.1918482631444931,
      "learning_rate": 4.746493200556805e-05,
      "loss": 0.1284,
      "step": 4740
    },
    {
      "epoch": 0.5086197665702966,
      "grad_norm": 0.15641745924949646,
      "learning_rate": 4.745957811328836e-05,
      "loss": 0.1381,
      "step": 4750
    },
    {
      "epoch": 0.5096905450262341,
      "grad_norm": 0.13097050786018372,
      "learning_rate": 4.745422422100867e-05,
      "loss": 0.1247,
      "step": 4760
    },
    {
      "epoch": 0.5107613234821715,
      "grad_norm": 0.16231270134449005,
      "learning_rate": 4.744887032872899e-05,
      "loss": 0.1296,
      "step": 4770
    },
    {
      "epoch": 0.511832101938109,
      "grad_norm": 0.16274182498455048,
      "learning_rate": 4.74435164364493e-05,
      "loss": 0.1426,
      "step": 4780
    },
    {
      "epoch": 0.5129028803940465,
      "grad_norm": 0.18186545372009277,
      "learning_rate": 4.7438162544169614e-05,
      "loss": 0.1233,
      "step": 4790
    },
    {
      "epoch": 0.5139736588499839,
      "grad_norm": 0.21539385616779327,
      "learning_rate": 4.7432808651889925e-05,
      "loss": 0.1311,
      "step": 4800
    },
    {
      "epoch": 0.5150444373059214,
      "grad_norm": 0.14494292438030243,
      "learning_rate": 4.7427454759610243e-05,
      "loss": 0.1298,
      "step": 4810
    },
    {
      "epoch": 0.5161152157618589,
      "grad_norm": 0.22900468111038208,
      "learning_rate": 4.742210086733055e-05,
      "loss": 0.1171,
      "step": 4820
    },
    {
      "epoch": 0.5171859942177963,
      "grad_norm": 0.18322432041168213,
      "learning_rate": 4.7416746975050866e-05,
      "loss": 0.135,
      "step": 4830
    },
    {
      "epoch": 0.5182567726737338,
      "grad_norm": 0.1861189305782318,
      "learning_rate": 4.741139308277118e-05,
      "loss": 0.1359,
      "step": 4840
    },
    {
      "epoch": 0.5193275511296712,
      "grad_norm": 0.2323000282049179,
      "learning_rate": 4.740603919049149e-05,
      "loss": 0.1418,
      "step": 4850
    },
    {
      "epoch": 0.5203983295856087,
      "grad_norm": 0.1664283573627472,
      "learning_rate": 4.74006852982118e-05,
      "loss": 0.1492,
      "step": 4860
    },
    {
      "epoch": 0.5214691080415462,
      "grad_norm": 0.1347414255142212,
      "learning_rate": 4.739533140593211e-05,
      "loss": 0.1307,
      "step": 4870
    },
    {
      "epoch": 0.5225398864974836,
      "grad_norm": 0.12814097106456757,
      "learning_rate": 4.738997751365243e-05,
      "loss": 0.1251,
      "step": 4880
    },
    {
      "epoch": 0.5236106649534211,
      "grad_norm": 0.19165879487991333,
      "learning_rate": 4.738462362137274e-05,
      "loss": 0.1383,
      "step": 4890
    },
    {
      "epoch": 0.5246814434093586,
      "grad_norm": 0.13514220714569092,
      "learning_rate": 4.737926972909305e-05,
      "loss": 0.1491,
      "step": 4900
    },
    {
      "epoch": 0.525752221865296,
      "grad_norm": 0.18983833491802216,
      "learning_rate": 4.7373915836813364e-05,
      "loss": 0.1307,
      "step": 4910
    },
    {
      "epoch": 0.5268230003212335,
      "grad_norm": 0.19282273948192596,
      "learning_rate": 4.736856194453368e-05,
      "loss": 0.153,
      "step": 4920
    },
    {
      "epoch": 0.527893778777171,
      "grad_norm": 0.17998313903808594,
      "learning_rate": 4.7363208052253994e-05,
      "loss": 0.134,
      "step": 4930
    },
    {
      "epoch": 0.5289645572331084,
      "grad_norm": 0.18515466153621674,
      "learning_rate": 4.7357854159974305e-05,
      "loss": 0.1296,
      "step": 4940
    },
    {
      "epoch": 0.5300353356890459,
      "grad_norm": 0.2827453017234802,
      "learning_rate": 4.7352500267694617e-05,
      "loss": 0.1313,
      "step": 4950
    },
    {
      "epoch": 0.5311061141449834,
      "grad_norm": 0.17152075469493866,
      "learning_rate": 4.734714637541493e-05,
      "loss": 0.1218,
      "step": 4960
    },
    {
      "epoch": 0.5321768926009208,
      "grad_norm": 0.18860796093940735,
      "learning_rate": 4.734179248313524e-05,
      "loss": 0.1386,
      "step": 4970
    },
    {
      "epoch": 0.5332476710568583,
      "grad_norm": 0.19631339609622955,
      "learning_rate": 4.733643859085555e-05,
      "loss": 0.129,
      "step": 4980
    },
    {
      "epoch": 0.5343184495127958,
      "grad_norm": 0.191291943192482,
      "learning_rate": 4.733108469857587e-05,
      "loss": 0.1214,
      "step": 4990
    },
    {
      "epoch": 0.5353892279687332,
      "grad_norm": 0.8557539582252502,
      "learning_rate": 4.732573080629618e-05,
      "loss": 0.1399,
      "step": 5000
    },
    {
      "epoch": 0.5364600064246707,
      "grad_norm": 0.15745759010314941,
      "learning_rate": 4.732037691401649e-05,
      "loss": 0.1113,
      "step": 5010
    },
    {
      "epoch": 0.5375307848806082,
      "grad_norm": 0.16340112686157227,
      "learning_rate": 4.73150230217368e-05,
      "loss": 0.1429,
      "step": 5020
    },
    {
      "epoch": 0.5386015633365456,
      "grad_norm": 0.20424813032150269,
      "learning_rate": 4.730966912945712e-05,
      "loss": 0.1273,
      "step": 5030
    },
    {
      "epoch": 0.5396723417924831,
      "grad_norm": 0.2183976024389267,
      "learning_rate": 4.730431523717743e-05,
      "loss": 0.131,
      "step": 5040
    },
    {
      "epoch": 0.5407431202484206,
      "grad_norm": 0.1388075053691864,
      "learning_rate": 4.7298961344897744e-05,
      "loss": 0.1117,
      "step": 5050
    },
    {
      "epoch": 0.541813898704358,
      "grad_norm": 0.2297724485397339,
      "learning_rate": 4.7293607452618056e-05,
      "loss": 0.1379,
      "step": 5060
    },
    {
      "epoch": 0.5428846771602955,
      "grad_norm": 0.23850375413894653,
      "learning_rate": 4.728825356033837e-05,
      "loss": 0.1337,
      "step": 5070
    },
    {
      "epoch": 0.543955455616233,
      "grad_norm": 0.15592016279697418,
      "learning_rate": 4.7282899668058685e-05,
      "loss": 0.1331,
      "step": 5080
    },
    {
      "epoch": 0.5450262340721704,
      "grad_norm": 0.18976274132728577,
      "learning_rate": 4.727754577577899e-05,
      "loss": 0.1318,
      "step": 5090
    },
    {
      "epoch": 0.5460970125281079,
      "grad_norm": 0.24988311529159546,
      "learning_rate": 4.727219188349931e-05,
      "loss": 0.1236,
      "step": 5100
    },
    {
      "epoch": 0.5471677909840454,
      "grad_norm": 0.15651878714561462,
      "learning_rate": 4.726683799121962e-05,
      "loss": 0.1216,
      "step": 5110
    },
    {
      "epoch": 0.5482385694399828,
      "grad_norm": 0.18576928973197937,
      "learning_rate": 4.726148409893994e-05,
      "loss": 0.1146,
      "step": 5120
    },
    {
      "epoch": 0.5493093478959203,
      "grad_norm": 0.3540005087852478,
      "learning_rate": 4.725613020666024e-05,
      "loss": 0.1137,
      "step": 5130
    },
    {
      "epoch": 0.5503801263518578,
      "grad_norm": 0.15986941754817963,
      "learning_rate": 4.725077631438056e-05,
      "loss": 0.1304,
      "step": 5140
    },
    {
      "epoch": 0.5514509048077952,
      "grad_norm": 0.6322823762893677,
      "learning_rate": 4.724542242210087e-05,
      "loss": 0.1444,
      "step": 5150
    },
    {
      "epoch": 0.5525216832637327,
      "grad_norm": 0.2120504528284073,
      "learning_rate": 4.724006852982118e-05,
      "loss": 0.1267,
      "step": 5160
    },
    {
      "epoch": 0.5535924617196702,
      "grad_norm": 0.12203016877174377,
      "learning_rate": 4.7234714637541494e-05,
      "loss": 0.1141,
      "step": 5170
    },
    {
      "epoch": 0.5546632401756076,
      "grad_norm": 0.13886819779872894,
      "learning_rate": 4.7229360745261806e-05,
      "loss": 0.1133,
      "step": 5180
    },
    {
      "epoch": 0.5557340186315451,
      "grad_norm": 0.13384181261062622,
      "learning_rate": 4.7224006852982124e-05,
      "loss": 0.1355,
      "step": 5190
    },
    {
      "epoch": 0.5568047970874827,
      "grad_norm": 0.21385031938552856,
      "learning_rate": 4.721865296070243e-05,
      "loss": 0.131,
      "step": 5200
    },
    {
      "epoch": 0.55787557554342,
      "grad_norm": 0.1375730186700821,
      "learning_rate": 4.721329906842275e-05,
      "loss": 0.1507,
      "step": 5210
    },
    {
      "epoch": 0.5589463539993575,
      "grad_norm": 0.17940255999565125,
      "learning_rate": 4.720794517614306e-05,
      "loss": 0.1399,
      "step": 5220
    },
    {
      "epoch": 0.560017132455295,
      "grad_norm": 0.26722994446754456,
      "learning_rate": 4.7202591283863376e-05,
      "loss": 0.1414,
      "step": 5230
    },
    {
      "epoch": 0.5610879109112324,
      "grad_norm": 0.1456994265317917,
      "learning_rate": 4.719723739158368e-05,
      "loss": 0.1183,
      "step": 5240
    },
    {
      "epoch": 0.56215868936717,
      "grad_norm": 0.23731696605682373,
      "learning_rate": 4.7191883499304e-05,
      "loss": 0.1199,
      "step": 5250
    },
    {
      "epoch": 0.5632294678231073,
      "grad_norm": 0.2832699418067932,
      "learning_rate": 4.718652960702431e-05,
      "loss": 0.1363,
      "step": 5260
    },
    {
      "epoch": 0.5643002462790448,
      "grad_norm": 0.14944352209568024,
      "learning_rate": 4.718117571474462e-05,
      "loss": 0.1241,
      "step": 5270
    },
    {
      "epoch": 0.5653710247349824,
      "grad_norm": 0.16742345690727234,
      "learning_rate": 4.7175821822464933e-05,
      "loss": 0.111,
      "step": 5280
    },
    {
      "epoch": 0.5664418031909197,
      "grad_norm": 0.17496950924396515,
      "learning_rate": 4.7170467930185245e-05,
      "loss": 0.134,
      "step": 5290
    },
    {
      "epoch": 0.5675125816468573,
      "grad_norm": 0.1846102476119995,
      "learning_rate": 4.716511403790556e-05,
      "loss": 0.1263,
      "step": 5300
    },
    {
      "epoch": 0.5685833601027948,
      "grad_norm": 0.24357670545578003,
      "learning_rate": 4.715976014562587e-05,
      "loss": 0.1248,
      "step": 5310
    },
    {
      "epoch": 0.5696541385587321,
      "grad_norm": 0.11939974874258041,
      "learning_rate": 4.7154406253346186e-05,
      "loss": 0.1393,
      "step": 5320
    },
    {
      "epoch": 0.5707249170146697,
      "grad_norm": 0.23643793165683746,
      "learning_rate": 4.71490523610665e-05,
      "loss": 0.1234,
      "step": 5330
    },
    {
      "epoch": 0.5717956954706072,
      "grad_norm": 0.12133566290140152,
      "learning_rate": 4.7143698468786815e-05,
      "loss": 0.1329,
      "step": 5340
    },
    {
      "epoch": 0.5728664739265446,
      "grad_norm": 0.19466334581375122,
      "learning_rate": 4.713834457650712e-05,
      "loss": 0.1312,
      "step": 5350
    },
    {
      "epoch": 0.573937252382482,
      "grad_norm": 0.1257767677307129,
      "learning_rate": 4.713299068422744e-05,
      "loss": 0.1248,
      "step": 5360
    },
    {
      "epoch": 0.5750080308384196,
      "grad_norm": 0.22552348673343658,
      "learning_rate": 4.712763679194775e-05,
      "loss": 0.1173,
      "step": 5370
    },
    {
      "epoch": 0.576078809294357,
      "grad_norm": 0.23384588956832886,
      "learning_rate": 4.712228289966806e-05,
      "loss": 0.1283,
      "step": 5380
    },
    {
      "epoch": 0.5771495877502945,
      "grad_norm": 0.36304807662963867,
      "learning_rate": 4.711692900738837e-05,
      "loss": 0.1461,
      "step": 5390
    },
    {
      "epoch": 0.578220366206232,
      "grad_norm": 0.16768306493759155,
      "learning_rate": 4.7111575115108684e-05,
      "loss": 0.1223,
      "step": 5400
    },
    {
      "epoch": 0.5792911446621694,
      "grad_norm": 0.1508106291294098,
      "learning_rate": 4.7106221222829e-05,
      "loss": 0.1241,
      "step": 5410
    },
    {
      "epoch": 0.5803619231181069,
      "grad_norm": 0.10026272386312485,
      "learning_rate": 4.710086733054931e-05,
      "loss": 0.134,
      "step": 5420
    },
    {
      "epoch": 0.5814327015740444,
      "grad_norm": 0.11523010581731796,
      "learning_rate": 4.7095513438269625e-05,
      "loss": 0.1234,
      "step": 5430
    },
    {
      "epoch": 0.5825034800299818,
      "grad_norm": 0.24031947553157806,
      "learning_rate": 4.7090159545989936e-05,
      "loss": 0.1307,
      "step": 5440
    },
    {
      "epoch": 0.5835742584859193,
      "grad_norm": 0.3019450604915619,
      "learning_rate": 4.7084805653710254e-05,
      "loss": 0.1342,
      "step": 5450
    },
    {
      "epoch": 0.5846450369418568,
      "grad_norm": 0.18880966305732727,
      "learning_rate": 4.707945176143056e-05,
      "loss": 0.117,
      "step": 5460
    },
    {
      "epoch": 0.5857158153977942,
      "grad_norm": 0.24398116767406464,
      "learning_rate": 4.707409786915088e-05,
      "loss": 0.1315,
      "step": 5470
    },
    {
      "epoch": 0.5867865938537317,
      "grad_norm": 0.3818712830543518,
      "learning_rate": 4.706874397687119e-05,
      "loss": 0.1293,
      "step": 5480
    },
    {
      "epoch": 0.5878573723096692,
      "grad_norm": 0.18825845420360565,
      "learning_rate": 4.70633900845915e-05,
      "loss": 0.1345,
      "step": 5490
    },
    {
      "epoch": 0.5889281507656066,
      "grad_norm": 0.2087685614824295,
      "learning_rate": 4.705803619231181e-05,
      "loss": 0.1192,
      "step": 5500
    },
    {
      "epoch": 0.5899989292215441,
      "grad_norm": 0.12432543188333511,
      "learning_rate": 4.705268230003212e-05,
      "loss": 0.124,
      "step": 5510
    },
    {
      "epoch": 0.5910697076774816,
      "grad_norm": 0.21156169474124908,
      "learning_rate": 4.704732840775244e-05,
      "loss": 0.1147,
      "step": 5520
    },
    {
      "epoch": 0.592140486133419,
      "grad_norm": 0.19265739619731903,
      "learning_rate": 4.704197451547275e-05,
      "loss": 0.1313,
      "step": 5530
    },
    {
      "epoch": 0.5932112645893565,
      "grad_norm": 0.22050851583480835,
      "learning_rate": 4.7036620623193064e-05,
      "loss": 0.1478,
      "step": 5540
    },
    {
      "epoch": 0.594282043045294,
      "grad_norm": 0.13957969844341278,
      "learning_rate": 4.7031266730913375e-05,
      "loss": 0.1277,
      "step": 5550
    },
    {
      "epoch": 0.5953528215012314,
      "grad_norm": 0.3066866099834442,
      "learning_rate": 4.702591283863369e-05,
      "loss": 0.145,
      "step": 5560
    },
    {
      "epoch": 0.5964235999571689,
      "grad_norm": 0.14454206824302673,
      "learning_rate": 4.7020558946354005e-05,
      "loss": 0.1335,
      "step": 5570
    },
    {
      "epoch": 0.5974943784131064,
      "grad_norm": 0.18862850964069366,
      "learning_rate": 4.7015205054074316e-05,
      "loss": 0.1321,
      "step": 5580
    },
    {
      "epoch": 0.5985651568690438,
      "grad_norm": 0.20768804848194122,
      "learning_rate": 4.700985116179463e-05,
      "loss": 0.1293,
      "step": 5590
    },
    {
      "epoch": 0.5996359353249813,
      "grad_norm": 0.22343789041042328,
      "learning_rate": 4.700449726951494e-05,
      "loss": 0.1335,
      "step": 5600
    },
    {
      "epoch": 0.6007067137809188,
      "grad_norm": 0.1760244071483612,
      "learning_rate": 4.699914337723525e-05,
      "loss": 0.1279,
      "step": 5610
    },
    {
      "epoch": 0.6017774922368562,
      "grad_norm": 0.19566218554973602,
      "learning_rate": 4.699378948495556e-05,
      "loss": 0.1268,
      "step": 5620
    },
    {
      "epoch": 0.6028482706927937,
      "grad_norm": 0.20514443516731262,
      "learning_rate": 4.698843559267588e-05,
      "loss": 0.1353,
      "step": 5630
    },
    {
      "epoch": 0.6039190491487312,
      "grad_norm": 0.14884734153747559,
      "learning_rate": 4.698308170039619e-05,
      "loss": 0.1245,
      "step": 5640
    },
    {
      "epoch": 0.6049898276046686,
      "grad_norm": 0.23325392603874207,
      "learning_rate": 4.69777278081165e-05,
      "loss": 0.1444,
      "step": 5650
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 0.1887105405330658,
      "learning_rate": 4.6972373915836814e-05,
      "loss": 0.1352,
      "step": 5660
    },
    {
      "epoch": 0.6071313845165436,
      "grad_norm": 0.19604374468326569,
      "learning_rate": 4.696702002355713e-05,
      "loss": 0.1332,
      "step": 5670
    },
    {
      "epoch": 0.608202162972481,
      "grad_norm": 0.18007002770900726,
      "learning_rate": 4.6961666131277444e-05,
      "loss": 0.1373,
      "step": 5680
    },
    {
      "epoch": 0.6092729414284185,
      "grad_norm": 0.15643031895160675,
      "learning_rate": 4.695631223899775e-05,
      "loss": 0.1241,
      "step": 5690
    },
    {
      "epoch": 0.6103437198843559,
      "grad_norm": 0.15827438235282898,
      "learning_rate": 4.6950958346718066e-05,
      "loss": 0.1574,
      "step": 5700
    },
    {
      "epoch": 0.6114144983402934,
      "grad_norm": 0.1542881280183792,
      "learning_rate": 4.694560445443838e-05,
      "loss": 0.1229,
      "step": 5710
    },
    {
      "epoch": 0.6124852767962309,
      "grad_norm": 0.22227437794208527,
      "learning_rate": 4.6940250562158696e-05,
      "loss": 0.1367,
      "step": 5720
    },
    {
      "epoch": 0.6135560552521683,
      "grad_norm": 0.14722903072834015,
      "learning_rate": 4.6934896669879e-05,
      "loss": 0.1421,
      "step": 5730
    },
    {
      "epoch": 0.6146268337081058,
      "grad_norm": 0.2290026992559433,
      "learning_rate": 4.692954277759932e-05,
      "loss": 0.1587,
      "step": 5740
    },
    {
      "epoch": 0.6156976121640433,
      "grad_norm": 0.19954368472099304,
      "learning_rate": 4.692418888531963e-05,
      "loss": 0.1229,
      "step": 5750
    },
    {
      "epoch": 0.6167683906199807,
      "grad_norm": 0.2671971023082733,
      "learning_rate": 4.691883499303994e-05,
      "loss": 0.1516,
      "step": 5760
    },
    {
      "epoch": 0.6178391690759182,
      "grad_norm": 0.24589870870113373,
      "learning_rate": 4.691348110076025e-05,
      "loss": 0.1352,
      "step": 5770
    },
    {
      "epoch": 0.6189099475318557,
      "grad_norm": 0.2007148563861847,
      "learning_rate": 4.690812720848057e-05,
      "loss": 0.13,
      "step": 5780
    },
    {
      "epoch": 0.6199807259877931,
      "grad_norm": 0.13316506147384644,
      "learning_rate": 4.690277331620088e-05,
      "loss": 0.1134,
      "step": 5790
    },
    {
      "epoch": 0.6210515044437306,
      "grad_norm": 0.1328023374080658,
      "learning_rate": 4.689741942392119e-05,
      "loss": 0.1206,
      "step": 5800
    },
    {
      "epoch": 0.6221222828996681,
      "grad_norm": 0.1920696496963501,
      "learning_rate": 4.6892065531641505e-05,
      "loss": 0.1272,
      "step": 5810
    },
    {
      "epoch": 0.6231930613556055,
      "grad_norm": 0.1593875288963318,
      "learning_rate": 4.688671163936182e-05,
      "loss": 0.1146,
      "step": 5820
    },
    {
      "epoch": 0.624263839811543,
      "grad_norm": 0.13691648840904236,
      "learning_rate": 4.6881357747082135e-05,
      "loss": 0.1344,
      "step": 5830
    },
    {
      "epoch": 0.6253346182674805,
      "grad_norm": 0.11322510242462158,
      "learning_rate": 4.687600385480244e-05,
      "loss": 0.1075,
      "step": 5840
    },
    {
      "epoch": 0.6264053967234179,
      "grad_norm": 0.1872422695159912,
      "learning_rate": 4.687064996252276e-05,
      "loss": 0.1322,
      "step": 5850
    },
    {
      "epoch": 0.6274761751793554,
      "grad_norm": 0.18143846094608307,
      "learning_rate": 4.686529607024307e-05,
      "loss": 0.1406,
      "step": 5860
    },
    {
      "epoch": 0.6285469536352929,
      "grad_norm": 0.19823794066905975,
      "learning_rate": 4.685994217796339e-05,
      "loss": 0.1259,
      "step": 5870
    },
    {
      "epoch": 0.6296177320912303,
      "grad_norm": 0.1999744176864624,
      "learning_rate": 4.685458828568369e-05,
      "loss": 0.124,
      "step": 5880
    },
    {
      "epoch": 0.6306885105471678,
      "grad_norm": 0.17089655995368958,
      "learning_rate": 4.6849234393404003e-05,
      "loss": 0.1135,
      "step": 5890
    },
    {
      "epoch": 0.6317592890031053,
      "grad_norm": 0.15947555005550385,
      "learning_rate": 4.684388050112432e-05,
      "loss": 0.1263,
      "step": 5900
    },
    {
      "epoch": 0.6328300674590427,
      "grad_norm": 0.17126154899597168,
      "learning_rate": 4.683852660884463e-05,
      "loss": 0.1315,
      "step": 5910
    },
    {
      "epoch": 0.6339008459149802,
      "grad_norm": 0.2501867413520813,
      "learning_rate": 4.6833172716564944e-05,
      "loss": 0.1279,
      "step": 5920
    },
    {
      "epoch": 0.6349716243709177,
      "grad_norm": 0.3225952088832855,
      "learning_rate": 4.6827818824285256e-05,
      "loss": 0.1274,
      "step": 5930
    },
    {
      "epoch": 0.6360424028268551,
      "grad_norm": 0.1593649834394455,
      "learning_rate": 4.6822464932005574e-05,
      "loss": 0.1321,
      "step": 5940
    },
    {
      "epoch": 0.6371131812827926,
      "grad_norm": 0.15040533244609833,
      "learning_rate": 4.681711103972588e-05,
      "loss": 0.1259,
      "step": 5950
    },
    {
      "epoch": 0.6381839597387301,
      "grad_norm": 0.2190089225769043,
      "learning_rate": 4.68117571474462e-05,
      "loss": 0.1353,
      "step": 5960
    },
    {
      "epoch": 0.6392547381946675,
      "grad_norm": 0.1820523887872696,
      "learning_rate": 4.680640325516651e-05,
      "loss": 0.1227,
      "step": 5970
    },
    {
      "epoch": 0.640325516650605,
      "grad_norm": 0.13717049360275269,
      "learning_rate": 4.6801049362886826e-05,
      "loss": 0.1235,
      "step": 5980
    },
    {
      "epoch": 0.6413962951065425,
      "grad_norm": 0.15004590153694153,
      "learning_rate": 4.679569547060713e-05,
      "loss": 0.1153,
      "step": 5990
    },
    {
      "epoch": 0.6424670735624799,
      "grad_norm": 0.2599000930786133,
      "learning_rate": 4.679034157832744e-05,
      "loss": 0.1369,
      "step": 6000
    },
    {
      "epoch": 0.6435378520184174,
      "grad_norm": 0.2401784509420395,
      "learning_rate": 4.678498768604776e-05,
      "loss": 0.142,
      "step": 6010
    },
    {
      "epoch": 0.6446086304743549,
      "grad_norm": 0.2802169620990753,
      "learning_rate": 4.677963379376807e-05,
      "loss": 0.146,
      "step": 6020
    },
    {
      "epoch": 0.6456794089302923,
      "grad_norm": 0.21254944801330566,
      "learning_rate": 4.677427990148838e-05,
      "loss": 0.1262,
      "step": 6030
    },
    {
      "epoch": 0.6467501873862298,
      "grad_norm": 0.14360730350017548,
      "learning_rate": 4.6768926009208695e-05,
      "loss": 0.1174,
      "step": 6040
    },
    {
      "epoch": 0.6478209658421673,
      "grad_norm": 0.16826897859573364,
      "learning_rate": 4.676357211692901e-05,
      "loss": 0.1239,
      "step": 6050
    },
    {
      "epoch": 0.6488917442981047,
      "grad_norm": 0.1863725781440735,
      "learning_rate": 4.6758218224649324e-05,
      "loss": 0.1011,
      "step": 6060
    },
    {
      "epoch": 0.6499625227540422,
      "grad_norm": 0.18304035067558289,
      "learning_rate": 4.6752864332369636e-05,
      "loss": 0.1296,
      "step": 6070
    },
    {
      "epoch": 0.6510333012099797,
      "grad_norm": 0.1343982070684433,
      "learning_rate": 4.674751044008995e-05,
      "loss": 0.1149,
      "step": 6080
    },
    {
      "epoch": 0.6521040796659171,
      "grad_norm": 0.1284073442220688,
      "learning_rate": 4.674215654781026e-05,
      "loss": 0.1173,
      "step": 6090
    },
    {
      "epoch": 0.6531748581218546,
      "grad_norm": 0.159525528550148,
      "learning_rate": 4.673680265553057e-05,
      "loss": 0.1222,
      "step": 6100
    },
    {
      "epoch": 0.654245636577792,
      "grad_norm": 0.14673447608947754,
      "learning_rate": 4.673144876325088e-05,
      "loss": 0.1336,
      "step": 6110
    },
    {
      "epoch": 0.6553164150337295,
      "grad_norm": 0.17642612755298615,
      "learning_rate": 4.67260948709712e-05,
      "loss": 0.1279,
      "step": 6120
    },
    {
      "epoch": 0.656387193489667,
      "grad_norm": 0.10515566915273666,
      "learning_rate": 4.672074097869151e-05,
      "loss": 0.1147,
      "step": 6130
    },
    {
      "epoch": 0.6574579719456044,
      "grad_norm": 0.19195495545864105,
      "learning_rate": 4.671538708641182e-05,
      "loss": 0.1298,
      "step": 6140
    },
    {
      "epoch": 0.6585287504015419,
      "grad_norm": 0.16797946393489838,
      "learning_rate": 4.6710033194132134e-05,
      "loss": 0.1289,
      "step": 6150
    },
    {
      "epoch": 0.6595995288574794,
      "grad_norm": 0.24371209740638733,
      "learning_rate": 4.670467930185245e-05,
      "loss": 0.1239,
      "step": 6160
    },
    {
      "epoch": 0.6606703073134168,
      "grad_norm": 0.15877923369407654,
      "learning_rate": 4.669932540957276e-05,
      "loss": 0.1146,
      "step": 6170
    },
    {
      "epoch": 0.6617410857693543,
      "grad_norm": 0.23382523655891418,
      "learning_rate": 4.6693971517293075e-05,
      "loss": 0.1275,
      "step": 6180
    },
    {
      "epoch": 0.6628118642252918,
      "grad_norm": 0.12681911885738373,
      "learning_rate": 4.6688617625013386e-05,
      "loss": 0.1298,
      "step": 6190
    },
    {
      "epoch": 0.6638826426812292,
      "grad_norm": 0.14875274896621704,
      "learning_rate": 4.66832637327337e-05,
      "loss": 0.115,
      "step": 6200
    },
    {
      "epoch": 0.6649534211371667,
      "grad_norm": 0.23414364457130432,
      "learning_rate": 4.6677909840454016e-05,
      "loss": 0.137,
      "step": 6210
    },
    {
      "epoch": 0.6660241995931042,
      "grad_norm": 0.18047429621219635,
      "learning_rate": 4.667255594817432e-05,
      "loss": 0.1119,
      "step": 6220
    },
    {
      "epoch": 0.6670949780490416,
      "grad_norm": 0.13655495643615723,
      "learning_rate": 4.666720205589464e-05,
      "loss": 0.1133,
      "step": 6230
    },
    {
      "epoch": 0.6681657565049791,
      "grad_norm": 0.12276260554790497,
      "learning_rate": 4.666184816361495e-05,
      "loss": 0.1105,
      "step": 6240
    },
    {
      "epoch": 0.6692365349609166,
      "grad_norm": 0.17077390849590302,
      "learning_rate": 4.665649427133526e-05,
      "loss": 0.1259,
      "step": 6250
    },
    {
      "epoch": 0.670307313416854,
      "grad_norm": 0.1592601090669632,
      "learning_rate": 4.665114037905557e-05,
      "loss": 0.1167,
      "step": 6260
    },
    {
      "epoch": 0.6713780918727915,
      "grad_norm": 0.1420639455318451,
      "learning_rate": 4.664578648677589e-05,
      "loss": 0.1296,
      "step": 6270
    },
    {
      "epoch": 0.672448870328729,
      "grad_norm": 0.14612817764282227,
      "learning_rate": 4.66404325944962e-05,
      "loss": 0.1103,
      "step": 6280
    },
    {
      "epoch": 0.6735196487846664,
      "grad_norm": 0.19978798925876617,
      "learning_rate": 4.6635078702216514e-05,
      "loss": 0.146,
      "step": 6290
    },
    {
      "epoch": 0.6745904272406039,
      "grad_norm": 0.4034678339958191,
      "learning_rate": 4.6629724809936825e-05,
      "loss": 0.122,
      "step": 6300
    },
    {
      "epoch": 0.6756612056965414,
      "grad_norm": 0.12736308574676514,
      "learning_rate": 4.6624370917657136e-05,
      "loss": 0.1121,
      "step": 6310
    },
    {
      "epoch": 0.6767319841524788,
      "grad_norm": 0.13403858244419098,
      "learning_rate": 4.6619017025377455e-05,
      "loss": 0.121,
      "step": 6320
    },
    {
      "epoch": 0.6778027626084163,
      "grad_norm": 0.16081497073173523,
      "learning_rate": 4.661366313309776e-05,
      "loss": 0.1224,
      "step": 6330
    },
    {
      "epoch": 0.6788735410643538,
      "grad_norm": 0.1419428139925003,
      "learning_rate": 4.660830924081808e-05,
      "loss": 0.1154,
      "step": 6340
    },
    {
      "epoch": 0.6799443195202912,
      "grad_norm": 0.11532789468765259,
      "learning_rate": 4.660295534853839e-05,
      "loss": 0.12,
      "step": 6350
    },
    {
      "epoch": 0.6810150979762287,
      "grad_norm": 0.20696419477462769,
      "learning_rate": 4.659760145625871e-05,
      "loss": 0.1201,
      "step": 6360
    },
    {
      "epoch": 0.6820858764321662,
      "grad_norm": 0.2009909600019455,
      "learning_rate": 4.659224756397901e-05,
      "loss": 0.1272,
      "step": 6370
    },
    {
      "epoch": 0.6831566548881036,
      "grad_norm": 0.19954454898834229,
      "learning_rate": 4.658689367169933e-05,
      "loss": 0.1315,
      "step": 6380
    },
    {
      "epoch": 0.6842274333440411,
      "grad_norm": 0.1578710824251175,
      "learning_rate": 4.658153977941964e-05,
      "loss": 0.1055,
      "step": 6390
    },
    {
      "epoch": 0.6852982117999786,
      "grad_norm": 0.1696411371231079,
      "learning_rate": 4.657618588713995e-05,
      "loss": 0.1329,
      "step": 6400
    },
    {
      "epoch": 0.686368990255916,
      "grad_norm": 0.17967982590198517,
      "learning_rate": 4.6570831994860264e-05,
      "loss": 0.1348,
      "step": 6410
    },
    {
      "epoch": 0.6874397687118535,
      "grad_norm": 0.26694974303245544,
      "learning_rate": 4.6565478102580575e-05,
      "loss": 0.1111,
      "step": 6420
    },
    {
      "epoch": 0.688510547167791,
      "grad_norm": 0.16762757301330566,
      "learning_rate": 4.6560124210300894e-05,
      "loss": 0.1249,
      "step": 6430
    },
    {
      "epoch": 0.6895813256237284,
      "grad_norm": 0.17328734695911407,
      "learning_rate": 4.65547703180212e-05,
      "loss": 0.1242,
      "step": 6440
    },
    {
      "epoch": 0.6906521040796659,
      "grad_norm": 0.22383148968219757,
      "learning_rate": 4.6549416425741516e-05,
      "loss": 0.1349,
      "step": 6450
    },
    {
      "epoch": 0.6917228825356034,
      "grad_norm": 0.2534015476703644,
      "learning_rate": 4.654406253346183e-05,
      "loss": 0.1197,
      "step": 6460
    },
    {
      "epoch": 0.6927936609915408,
      "grad_norm": 0.19549155235290527,
      "learning_rate": 4.6538708641182146e-05,
      "loss": 0.1437,
      "step": 6470
    },
    {
      "epoch": 0.6938644394474783,
      "grad_norm": 0.12550996243953705,
      "learning_rate": 4.653335474890245e-05,
      "loss": 0.1134,
      "step": 6480
    },
    {
      "epoch": 0.6949352179034158,
      "grad_norm": 0.307343453168869,
      "learning_rate": 4.652800085662277e-05,
      "loss": 0.1367,
      "step": 6490
    },
    {
      "epoch": 0.6960059963593532,
      "grad_norm": 0.17377814650535583,
      "learning_rate": 4.652264696434308e-05,
      "loss": 0.1245,
      "step": 6500
    },
    {
      "epoch": 0.6970767748152907,
      "grad_norm": 0.13226591050624847,
      "learning_rate": 4.651729307206339e-05,
      "loss": 0.1148,
      "step": 6510
    },
    {
      "epoch": 0.6981475532712282,
      "grad_norm": 0.13955391943454742,
      "learning_rate": 4.65119391797837e-05,
      "loss": 0.1173,
      "step": 6520
    },
    {
      "epoch": 0.6992183317271656,
      "grad_norm": 0.18830527365207672,
      "learning_rate": 4.6506585287504014e-05,
      "loss": 0.1479,
      "step": 6530
    },
    {
      "epoch": 0.7002891101831031,
      "grad_norm": 0.14255093038082123,
      "learning_rate": 4.650123139522433e-05,
      "loss": 0.1134,
      "step": 6540
    },
    {
      "epoch": 0.7013598886390405,
      "grad_norm": 0.29567787051200867,
      "learning_rate": 4.649587750294464e-05,
      "loss": 0.1272,
      "step": 6550
    },
    {
      "epoch": 0.702430667094978,
      "grad_norm": 0.12887315452098846,
      "learning_rate": 4.6490523610664955e-05,
      "loss": 0.1335,
      "step": 6560
    },
    {
      "epoch": 0.7035014455509155,
      "grad_norm": 0.15172435343265533,
      "learning_rate": 4.648516971838527e-05,
      "loss": 0.1236,
      "step": 6570
    },
    {
      "epoch": 0.7045722240068529,
      "grad_norm": 0.16198919713497162,
      "learning_rate": 4.6479815826105585e-05,
      "loss": 0.1232,
      "step": 6580
    },
    {
      "epoch": 0.7056430024627904,
      "grad_norm": 0.15400493144989014,
      "learning_rate": 4.647446193382589e-05,
      "loss": 0.1367,
      "step": 6590
    },
    {
      "epoch": 0.7067137809187279,
      "grad_norm": 0.2340320646762848,
      "learning_rate": 4.646910804154621e-05,
      "loss": 0.1181,
      "step": 6600
    },
    {
      "epoch": 0.7077845593746653,
      "grad_norm": 0.16095489263534546,
      "learning_rate": 4.646375414926652e-05,
      "loss": 0.117,
      "step": 6610
    },
    {
      "epoch": 0.7088553378306028,
      "grad_norm": 0.21287104487419128,
      "learning_rate": 4.645840025698683e-05,
      "loss": 0.1278,
      "step": 6620
    },
    {
      "epoch": 0.7099261162865403,
      "grad_norm": 0.15993037819862366,
      "learning_rate": 4.645304636470714e-05,
      "loss": 0.1034,
      "step": 6630
    },
    {
      "epoch": 0.7109968947424777,
      "grad_norm": 0.15334182977676392,
      "learning_rate": 4.644769247242745e-05,
      "loss": 0.1154,
      "step": 6640
    },
    {
      "epoch": 0.7120676731984152,
      "grad_norm": 0.1514158397912979,
      "learning_rate": 4.644233858014777e-05,
      "loss": 0.1131,
      "step": 6650
    },
    {
      "epoch": 0.7131384516543527,
      "grad_norm": 0.1423925757408142,
      "learning_rate": 4.643698468786808e-05,
      "loss": 0.1153,
      "step": 6660
    },
    {
      "epoch": 0.7142092301102901,
      "grad_norm": 0.13385798037052155,
      "learning_rate": 4.6431630795588394e-05,
      "loss": 0.1354,
      "step": 6670
    },
    {
      "epoch": 0.7152800085662276,
      "grad_norm": 0.16545900702476501,
      "learning_rate": 4.6426276903308706e-05,
      "loss": 0.1095,
      "step": 6680
    },
    {
      "epoch": 0.7163507870221651,
      "grad_norm": 0.17360343039035797,
      "learning_rate": 4.6420923011029024e-05,
      "loss": 0.1133,
      "step": 6690
    },
    {
      "epoch": 0.7174215654781025,
      "grad_norm": 0.22803272306919098,
      "learning_rate": 4.641556911874933e-05,
      "loss": 0.1105,
      "step": 6700
    },
    {
      "epoch": 0.71849234393404,
      "grad_norm": 0.24614183604717255,
      "learning_rate": 4.641021522646965e-05,
      "loss": 0.1144,
      "step": 6710
    },
    {
      "epoch": 0.7195631223899775,
      "grad_norm": 0.2655350863933563,
      "learning_rate": 4.640486133418996e-05,
      "loss": 0.1251,
      "step": 6720
    },
    {
      "epoch": 0.7206339008459149,
      "grad_norm": 0.1139695942401886,
      "learning_rate": 4.639950744191027e-05,
      "loss": 0.1163,
      "step": 6730
    },
    {
      "epoch": 0.7217046793018524,
      "grad_norm": 0.13950859010219574,
      "learning_rate": 4.639415354963058e-05,
      "loss": 0.1225,
      "step": 6740
    },
    {
      "epoch": 0.72277545775779,
      "grad_norm": 0.19576668739318848,
      "learning_rate": 4.638879965735089e-05,
      "loss": 0.1096,
      "step": 6750
    },
    {
      "epoch": 0.7238462362137273,
      "grad_norm": 0.19546280801296234,
      "learning_rate": 4.638344576507121e-05,
      "loss": 0.1086,
      "step": 6760
    },
    {
      "epoch": 0.7249170146696648,
      "grad_norm": 0.5368584394454956,
      "learning_rate": 4.637809187279152e-05,
      "loss": 0.1102,
      "step": 6770
    },
    {
      "epoch": 0.7259877931256024,
      "grad_norm": 0.21704453229904175,
      "learning_rate": 4.637273798051183e-05,
      "loss": 0.1268,
      "step": 6780
    },
    {
      "epoch": 0.7270585715815397,
      "grad_norm": 0.14516641199588776,
      "learning_rate": 4.6367384088232145e-05,
      "loss": 0.1188,
      "step": 6790
    },
    {
      "epoch": 0.7281293500374773,
      "grad_norm": 0.1709989458322525,
      "learning_rate": 4.636203019595246e-05,
      "loss": 0.108,
      "step": 6800
    },
    {
      "epoch": 0.7292001284934148,
      "grad_norm": 0.14781047403812408,
      "learning_rate": 4.6356676303672774e-05,
      "loss": 0.1201,
      "step": 6810
    },
    {
      "epoch": 0.7302709069493521,
      "grad_norm": 1.2559748888015747,
      "learning_rate": 4.6351322411393086e-05,
      "loss": 0.1371,
      "step": 6820
    },
    {
      "epoch": 0.7313416854052897,
      "grad_norm": 0.13686439394950867,
      "learning_rate": 4.63459685191134e-05,
      "loss": 0.1303,
      "step": 6830
    },
    {
      "epoch": 0.7324124638612272,
      "grad_norm": 0.12458499521017075,
      "learning_rate": 4.634061462683371e-05,
      "loss": 0.1051,
      "step": 6840
    },
    {
      "epoch": 0.7334832423171646,
      "grad_norm": 0.14805953204631805,
      "learning_rate": 4.6335260734554027e-05,
      "loss": 0.1118,
      "step": 6850
    },
    {
      "epoch": 0.7345540207731021,
      "grad_norm": 0.1911933571100235,
      "learning_rate": 4.632990684227433e-05,
      "loss": 0.1235,
      "step": 6860
    },
    {
      "epoch": 0.7356247992290396,
      "grad_norm": 0.1598597764968872,
      "learning_rate": 4.632455294999465e-05,
      "loss": 0.1067,
      "step": 6870
    },
    {
      "epoch": 0.736695577684977,
      "grad_norm": 0.14604033529758453,
      "learning_rate": 4.631919905771496e-05,
      "loss": 0.1059,
      "step": 6880
    },
    {
      "epoch": 0.7377663561409145,
      "grad_norm": 0.13192741572856903,
      "learning_rate": 4.631384516543527e-05,
      "loss": 0.1268,
      "step": 6890
    },
    {
      "epoch": 0.738837134596852,
      "grad_norm": 0.11387085169553757,
      "learning_rate": 4.6308491273155584e-05,
      "loss": 0.1118,
      "step": 6900
    },
    {
      "epoch": 0.7399079130527894,
      "grad_norm": 0.17462515830993652,
      "learning_rate": 4.63031373808759e-05,
      "loss": 0.1073,
      "step": 6910
    },
    {
      "epoch": 0.7409786915087269,
      "grad_norm": 0.3194374442100525,
      "learning_rate": 4.629778348859621e-05,
      "loss": 0.1245,
      "step": 6920
    },
    {
      "epoch": 0.7420494699646644,
      "grad_norm": 0.14378733932971954,
      "learning_rate": 4.6292429596316525e-05,
      "loss": 0.129,
      "step": 6930
    },
    {
      "epoch": 0.7431202484206018,
      "grad_norm": 0.16344454884529114,
      "learning_rate": 4.6287075704036836e-05,
      "loss": 0.1194,
      "step": 6940
    },
    {
      "epoch": 0.7441910268765393,
      "grad_norm": 0.20031480491161346,
      "learning_rate": 4.628172181175715e-05,
      "loss": 0.1226,
      "step": 6950
    },
    {
      "epoch": 0.7452618053324767,
      "grad_norm": 0.12359633296728134,
      "learning_rate": 4.6276367919477466e-05,
      "loss": 0.1379,
      "step": 6960
    },
    {
      "epoch": 0.7463325837884142,
      "grad_norm": 0.13125202059745789,
      "learning_rate": 4.627101402719777e-05,
      "loss": 0.1241,
      "step": 6970
    },
    {
      "epoch": 0.7474033622443517,
      "grad_norm": 0.20228396356105804,
      "learning_rate": 4.626566013491809e-05,
      "loss": 0.1372,
      "step": 6980
    },
    {
      "epoch": 0.7484741407002891,
      "grad_norm": 0.19725775718688965,
      "learning_rate": 4.62603062426384e-05,
      "loss": 0.1082,
      "step": 6990
    },
    {
      "epoch": 0.7495449191562266,
      "grad_norm": 0.133664071559906,
      "learning_rate": 4.625495235035872e-05,
      "loss": 0.1224,
      "step": 7000
    },
    {
      "epoch": 0.7506156976121641,
      "grad_norm": 0.2503953278064728,
      "learning_rate": 4.624959845807902e-05,
      "loss": 0.1174,
      "step": 7010
    },
    {
      "epoch": 0.7516864760681015,
      "grad_norm": 0.13449423015117645,
      "learning_rate": 4.624424456579934e-05,
      "loss": 0.1277,
      "step": 7020
    },
    {
      "epoch": 0.752757254524039,
      "grad_norm": 0.21727557480335236,
      "learning_rate": 4.623889067351965e-05,
      "loss": 0.1214,
      "step": 7030
    },
    {
      "epoch": 0.7538280329799765,
      "grad_norm": 0.1803528070449829,
      "learning_rate": 4.6233536781239963e-05,
      "loss": 0.1118,
      "step": 7040
    },
    {
      "epoch": 0.7548988114359139,
      "grad_norm": 0.1381625533103943,
      "learning_rate": 4.6228182888960275e-05,
      "loss": 0.1165,
      "step": 7050
    },
    {
      "epoch": 0.7559695898918514,
      "grad_norm": 0.16515839099884033,
      "learning_rate": 4.6222828996680586e-05,
      "loss": 0.1276,
      "step": 7060
    },
    {
      "epoch": 0.7570403683477889,
      "grad_norm": 0.1721477210521698,
      "learning_rate": 4.6217475104400904e-05,
      "loss": 0.1049,
      "step": 7070
    },
    {
      "epoch": 0.7581111468037263,
      "grad_norm": 0.2249370813369751,
      "learning_rate": 4.621212121212121e-05,
      "loss": 0.1447,
      "step": 7080
    },
    {
      "epoch": 0.7591819252596638,
      "grad_norm": 0.14386822283267975,
      "learning_rate": 4.620676731984153e-05,
      "loss": 0.1212,
      "step": 7090
    },
    {
      "epoch": 0.7602527037156013,
      "grad_norm": 0.27286404371261597,
      "learning_rate": 4.620141342756184e-05,
      "loss": 0.1207,
      "step": 7100
    },
    {
      "epoch": 0.7613234821715387,
      "grad_norm": 0.12222956120967865,
      "learning_rate": 4.619605953528216e-05,
      "loss": 0.1102,
      "step": 7110
    },
    {
      "epoch": 0.7623942606274762,
      "grad_norm": 0.20780958235263824,
      "learning_rate": 4.619070564300246e-05,
      "loss": 0.1173,
      "step": 7120
    },
    {
      "epoch": 0.7634650390834137,
      "grad_norm": 0.19694732129573822,
      "learning_rate": 4.618535175072278e-05,
      "loss": 0.1035,
      "step": 7130
    },
    {
      "epoch": 0.7645358175393511,
      "grad_norm": 0.14351503551006317,
      "learning_rate": 4.617999785844309e-05,
      "loss": 0.1295,
      "step": 7140
    },
    {
      "epoch": 0.7656065959952886,
      "grad_norm": 0.15431901812553406,
      "learning_rate": 4.61746439661634e-05,
      "loss": 0.1219,
      "step": 7150
    },
    {
      "epoch": 0.7666773744512261,
      "grad_norm": 0.22990255057811737,
      "learning_rate": 4.6169290073883714e-05,
      "loss": 0.1164,
      "step": 7160
    },
    {
      "epoch": 0.7677481529071635,
      "grad_norm": 0.184825599193573,
      "learning_rate": 4.6163936181604025e-05,
      "loss": 0.1179,
      "step": 7170
    },
    {
      "epoch": 0.768818931363101,
      "grad_norm": 0.09163078665733337,
      "learning_rate": 4.6158582289324343e-05,
      "loss": 0.1095,
      "step": 7180
    },
    {
      "epoch": 0.7698897098190385,
      "grad_norm": 0.13600140810012817,
      "learning_rate": 4.615322839704465e-05,
      "loss": 0.1172,
      "step": 7190
    },
    {
      "epoch": 0.7709604882749759,
      "grad_norm": 0.31536543369293213,
      "learning_rate": 4.6147874504764966e-05,
      "loss": 0.1298,
      "step": 7200
    },
    {
      "epoch": 0.7720312667309134,
      "grad_norm": 0.14798787236213684,
      "learning_rate": 4.614252061248528e-05,
      "loss": 0.1398,
      "step": 7210
    },
    {
      "epoch": 0.7731020451868509,
      "grad_norm": 0.25367864966392517,
      "learning_rate": 4.6137166720205596e-05,
      "loss": 0.1201,
      "step": 7220
    },
    {
      "epoch": 0.7741728236427883,
      "grad_norm": 0.9350070357322693,
      "learning_rate": 4.61318128279259e-05,
      "loss": 0.1211,
      "step": 7230
    },
    {
      "epoch": 0.7752436020987258,
      "grad_norm": 0.1362900584936142,
      "learning_rate": 4.612645893564622e-05,
      "loss": 0.1037,
      "step": 7240
    },
    {
      "epoch": 0.7763143805546633,
      "grad_norm": 0.24562306702136993,
      "learning_rate": 4.612110504336653e-05,
      "loss": 0.1225,
      "step": 7250
    },
    {
      "epoch": 0.7773851590106007,
      "grad_norm": 0.28806084394454956,
      "learning_rate": 4.611575115108684e-05,
      "loss": 0.132,
      "step": 7260
    },
    {
      "epoch": 0.7784559374665382,
      "grad_norm": 0.20316565036773682,
      "learning_rate": 4.611039725880715e-05,
      "loss": 0.1191,
      "step": 7270
    },
    {
      "epoch": 0.7795267159224757,
      "grad_norm": 0.14433962106704712,
      "learning_rate": 4.6105043366527464e-05,
      "loss": 0.1304,
      "step": 7280
    },
    {
      "epoch": 0.7805974943784131,
      "grad_norm": 0.17694483697414398,
      "learning_rate": 4.609968947424778e-05,
      "loss": 0.129,
      "step": 7290
    },
    {
      "epoch": 0.7816682728343506,
      "grad_norm": 0.17038209736347198,
      "learning_rate": 4.6094335581968094e-05,
      "loss": 0.1225,
      "step": 7300
    },
    {
      "epoch": 0.7827390512902881,
      "grad_norm": 0.21367089450359344,
      "learning_rate": 4.6088981689688405e-05,
      "loss": 0.1248,
      "step": 7310
    },
    {
      "epoch": 0.7838098297462255,
      "grad_norm": 0.272329717874527,
      "learning_rate": 4.6083627797408717e-05,
      "loss": 0.1192,
      "step": 7320
    },
    {
      "epoch": 0.784880608202163,
      "grad_norm": 0.20282064378261566,
      "learning_rate": 4.6078273905129035e-05,
      "loss": 0.1058,
      "step": 7330
    },
    {
      "epoch": 0.7859513866581005,
      "grad_norm": 0.14389020204544067,
      "learning_rate": 4.607292001284934e-05,
      "loss": 0.1143,
      "step": 7340
    },
    {
      "epoch": 0.7870221651140379,
      "grad_norm": 0.13442742824554443,
      "learning_rate": 4.606756612056966e-05,
      "loss": 0.1241,
      "step": 7350
    },
    {
      "epoch": 0.7880929435699754,
      "grad_norm": 0.1354391872882843,
      "learning_rate": 4.606221222828997e-05,
      "loss": 0.1286,
      "step": 7360
    },
    {
      "epoch": 0.7891637220259128,
      "grad_norm": 0.19573158025741577,
      "learning_rate": 4.605685833601028e-05,
      "loss": 0.1258,
      "step": 7370
    },
    {
      "epoch": 0.7902345004818503,
      "grad_norm": 0.21998360753059387,
      "learning_rate": 4.605150444373059e-05,
      "loss": 0.1256,
      "step": 7380
    },
    {
      "epoch": 0.7913052789377878,
      "grad_norm": 0.1650821715593338,
      "learning_rate": 4.60461505514509e-05,
      "loss": 0.1358,
      "step": 7390
    },
    {
      "epoch": 0.7923760573937252,
      "grad_norm": 0.5235579609870911,
      "learning_rate": 4.604079665917122e-05,
      "loss": 0.1516,
      "step": 7400
    },
    {
      "epoch": 0.7934468358496627,
      "grad_norm": 0.1546725481748581,
      "learning_rate": 4.603544276689153e-05,
      "loss": 0.1123,
      "step": 7410
    },
    {
      "epoch": 0.7945176143056002,
      "grad_norm": 0.2985212504863739,
      "learning_rate": 4.6030088874611844e-05,
      "loss": 0.1408,
      "step": 7420
    },
    {
      "epoch": 0.7955883927615376,
      "grad_norm": 0.16675099730491638,
      "learning_rate": 4.6024734982332156e-05,
      "loss": 0.1208,
      "step": 7430
    },
    {
      "epoch": 0.7966591712174751,
      "grad_norm": 0.1560676544904709,
      "learning_rate": 4.6019381090052474e-05,
      "loss": 0.1224,
      "step": 7440
    },
    {
      "epoch": 0.7977299496734126,
      "grad_norm": 0.12590286135673523,
      "learning_rate": 4.6014027197772785e-05,
      "loss": 0.1304,
      "step": 7450
    },
    {
      "epoch": 0.79880072812935,
      "grad_norm": 0.15943960845470428,
      "learning_rate": 4.6008673305493097e-05,
      "loss": 0.1081,
      "step": 7460
    },
    {
      "epoch": 0.7998715065852875,
      "grad_norm": 0.20296579599380493,
      "learning_rate": 4.600331941321341e-05,
      "loss": 0.1298,
      "step": 7470
    },
    {
      "epoch": 0.800942285041225,
      "grad_norm": 0.1884743869304657,
      "learning_rate": 4.599796552093372e-05,
      "loss": 0.0969,
      "step": 7480
    },
    {
      "epoch": 0.8020130634971624,
      "grad_norm": 0.16579924523830414,
      "learning_rate": 4.599261162865403e-05,
      "loss": 0.124,
      "step": 7490
    },
    {
      "epoch": 0.8030838419530999,
      "grad_norm": 0.17911629378795624,
      "learning_rate": 4.598725773637434e-05,
      "loss": 0.1219,
      "step": 7500
    },
    {
      "epoch": 0.8041546204090374,
      "grad_norm": 0.24434594810009003,
      "learning_rate": 4.598190384409466e-05,
      "loss": 0.1158,
      "step": 7510
    },
    {
      "epoch": 0.8052253988649748,
      "grad_norm": 0.17641299962997437,
      "learning_rate": 4.597654995181497e-05,
      "loss": 0.0997,
      "step": 7520
    },
    {
      "epoch": 0.8062961773209123,
      "grad_norm": 0.19737185537815094,
      "learning_rate": 4.597119605953528e-05,
      "loss": 0.0996,
      "step": 7530
    },
    {
      "epoch": 0.8073669557768498,
      "grad_norm": 0.18276746571063995,
      "learning_rate": 4.5965842167255594e-05,
      "loss": 0.121,
      "step": 7540
    },
    {
      "epoch": 0.8084377342327872,
      "grad_norm": 0.15059535205364227,
      "learning_rate": 4.596048827497591e-05,
      "loss": 0.1101,
      "step": 7550
    },
    {
      "epoch": 0.8095085126887247,
      "grad_norm": 0.1742713898420334,
      "learning_rate": 4.5955134382696224e-05,
      "loss": 0.1313,
      "step": 7560
    },
    {
      "epoch": 0.8105792911446622,
      "grad_norm": 0.18261496722698212,
      "learning_rate": 4.5949780490416535e-05,
      "loss": 0.121,
      "step": 7570
    },
    {
      "epoch": 0.8116500696005996,
      "grad_norm": 0.22182658314704895,
      "learning_rate": 4.594442659813685e-05,
      "loss": 0.137,
      "step": 7580
    },
    {
      "epoch": 0.8127208480565371,
      "grad_norm": 0.22370123863220215,
      "learning_rate": 4.593907270585716e-05,
      "loss": 0.1072,
      "step": 7590
    },
    {
      "epoch": 0.8137916265124746,
      "grad_norm": 0.12981706857681274,
      "learning_rate": 4.5933718813577476e-05,
      "loss": 0.1292,
      "step": 7600
    },
    {
      "epoch": 0.814862404968412,
      "grad_norm": 0.2702500820159912,
      "learning_rate": 4.592836492129778e-05,
      "loss": 0.1281,
      "step": 7610
    },
    {
      "epoch": 0.8159331834243495,
      "grad_norm": 0.3093525171279907,
      "learning_rate": 4.59230110290181e-05,
      "loss": 0.1021,
      "step": 7620
    },
    {
      "epoch": 0.817003961880287,
      "grad_norm": 0.2039419412612915,
      "learning_rate": 4.591765713673841e-05,
      "loss": 0.1126,
      "step": 7630
    },
    {
      "epoch": 0.8180747403362244,
      "grad_norm": 0.21432611346244812,
      "learning_rate": 4.591230324445873e-05,
      "loss": 0.1287,
      "step": 7640
    },
    {
      "epoch": 0.8191455187921619,
      "grad_norm": 0.15259742736816406,
      "learning_rate": 4.5906949352179033e-05,
      "loss": 0.1201,
      "step": 7650
    },
    {
      "epoch": 0.8202162972480994,
      "grad_norm": 0.15774603188037872,
      "learning_rate": 4.590159545989935e-05,
      "loss": 0.1223,
      "step": 7660
    },
    {
      "epoch": 0.8212870757040368,
      "grad_norm": 0.27014249563217163,
      "learning_rate": 4.589624156761966e-05,
      "loss": 0.1257,
      "step": 7670
    },
    {
      "epoch": 0.8223578541599743,
      "grad_norm": 0.1920347958803177,
      "learning_rate": 4.5890887675339974e-05,
      "loss": 0.116,
      "step": 7680
    },
    {
      "epoch": 0.8234286326159118,
      "grad_norm": 0.29663488268852234,
      "learning_rate": 4.5885533783060286e-05,
      "loss": 0.1221,
      "step": 7690
    },
    {
      "epoch": 0.8244994110718492,
      "grad_norm": 0.1778009980916977,
      "learning_rate": 4.58801798907806e-05,
      "loss": 0.1276,
      "step": 7700
    },
    {
      "epoch": 0.8255701895277867,
      "grad_norm": 0.21547597646713257,
      "learning_rate": 4.5874825998500915e-05,
      "loss": 0.1489,
      "step": 7710
    },
    {
      "epoch": 0.8266409679837242,
      "grad_norm": 0.16083484888076782,
      "learning_rate": 4.586947210622122e-05,
      "loss": 0.1244,
      "step": 7720
    },
    {
      "epoch": 0.8277117464396616,
      "grad_norm": 0.18084712326526642,
      "learning_rate": 4.586411821394154e-05,
      "loss": 0.1252,
      "step": 7730
    },
    {
      "epoch": 0.8287825248955991,
      "grad_norm": 0.15910625457763672,
      "learning_rate": 4.585876432166185e-05,
      "loss": 0.1224,
      "step": 7740
    },
    {
      "epoch": 0.8298533033515366,
      "grad_norm": 0.24085529148578644,
      "learning_rate": 4.585341042938217e-05,
      "loss": 0.1186,
      "step": 7750
    },
    {
      "epoch": 0.830924081807474,
      "grad_norm": 0.17556969821453094,
      "learning_rate": 4.584805653710247e-05,
      "loss": 0.1148,
      "step": 7760
    },
    {
      "epoch": 0.8319948602634115,
      "grad_norm": 0.204464390873909,
      "learning_rate": 4.584270264482279e-05,
      "loss": 0.126,
      "step": 7770
    },
    {
      "epoch": 0.833065638719349,
      "grad_norm": 0.15063796937465668,
      "learning_rate": 4.58373487525431e-05,
      "loss": 0.1256,
      "step": 7780
    },
    {
      "epoch": 0.8341364171752864,
      "grad_norm": 0.13294260203838348,
      "learning_rate": 4.583199486026341e-05,
      "loss": 0.1261,
      "step": 7790
    },
    {
      "epoch": 0.8352071956312239,
      "grad_norm": 0.21389205753803253,
      "learning_rate": 4.5826640967983725e-05,
      "loss": 0.1283,
      "step": 7800
    },
    {
      "epoch": 0.8362779740871613,
      "grad_norm": 0.14055398106575012,
      "learning_rate": 4.5821287075704036e-05,
      "loss": 0.1234,
      "step": 7810
    },
    {
      "epoch": 0.8373487525430988,
      "grad_norm": 1.1510857343673706,
      "learning_rate": 4.5815933183424354e-05,
      "loss": 0.1283,
      "step": 7820
    },
    {
      "epoch": 0.8384195309990363,
      "grad_norm": 0.1673966646194458,
      "learning_rate": 4.581057929114466e-05,
      "loss": 0.0937,
      "step": 7830
    },
    {
      "epoch": 0.8394903094549737,
      "grad_norm": 0.17517443001270294,
      "learning_rate": 4.580522539886498e-05,
      "loss": 0.1067,
      "step": 7840
    },
    {
      "epoch": 0.8405610879109112,
      "grad_norm": 0.16506215929985046,
      "learning_rate": 4.579987150658529e-05,
      "loss": 0.1144,
      "step": 7850
    },
    {
      "epoch": 0.8416318663668487,
      "grad_norm": 0.15599851310253143,
      "learning_rate": 4.579451761430561e-05,
      "loss": 0.1186,
      "step": 7860
    },
    {
      "epoch": 0.8427026448227861,
      "grad_norm": 0.3267514407634735,
      "learning_rate": 4.578916372202591e-05,
      "loss": 0.1093,
      "step": 7870
    },
    {
      "epoch": 0.8437734232787236,
      "grad_norm": 0.1525837630033493,
      "learning_rate": 4.578380982974623e-05,
      "loss": 0.112,
      "step": 7880
    },
    {
      "epoch": 0.8448442017346611,
      "grad_norm": 0.17465655505657196,
      "learning_rate": 4.577845593746654e-05,
      "loss": 0.1222,
      "step": 7890
    },
    {
      "epoch": 0.8459149801905985,
      "grad_norm": 0.14065411686897278,
      "learning_rate": 4.577310204518685e-05,
      "loss": 0.1125,
      "step": 7900
    },
    {
      "epoch": 0.846985758646536,
      "grad_norm": 0.1689133644104004,
      "learning_rate": 4.5767748152907164e-05,
      "loss": 0.1172,
      "step": 7910
    },
    {
      "epoch": 0.8480565371024735,
      "grad_norm": 0.21220152080059052,
      "learning_rate": 4.5762394260627475e-05,
      "loss": 0.1167,
      "step": 7920
    },
    {
      "epoch": 0.8491273155584109,
      "grad_norm": 0.20131422579288483,
      "learning_rate": 4.575704036834779e-05,
      "loss": 0.1097,
      "step": 7930
    },
    {
      "epoch": 0.8501980940143484,
      "grad_norm": 0.20346419513225555,
      "learning_rate": 4.5751686476068105e-05,
      "loss": 0.1344,
      "step": 7940
    },
    {
      "epoch": 0.8512688724702859,
      "grad_norm": 0.25131332874298096,
      "learning_rate": 4.5746332583788416e-05,
      "loss": 0.1269,
      "step": 7950
    },
    {
      "epoch": 0.8523396509262233,
      "grad_norm": 0.19534863531589508,
      "learning_rate": 4.574097869150873e-05,
      "loss": 0.1251,
      "step": 7960
    },
    {
      "epoch": 0.8534104293821608,
      "grad_norm": 1.2346630096435547,
      "learning_rate": 4.5735624799229046e-05,
      "loss": 0.1225,
      "step": 7970
    },
    {
      "epoch": 0.8544812078380983,
      "grad_norm": 0.15727387368679047,
      "learning_rate": 4.573027090694935e-05,
      "loss": 0.1134,
      "step": 7980
    },
    {
      "epoch": 0.8555519862940357,
      "grad_norm": 0.13386298716068268,
      "learning_rate": 4.572491701466967e-05,
      "loss": 0.1133,
      "step": 7990
    },
    {
      "epoch": 0.8566227647499732,
      "grad_norm": 0.15317769348621368,
      "learning_rate": 4.571956312238998e-05,
      "loss": 0.1237,
      "step": 8000
    },
    {
      "epoch": 0.8576935432059107,
      "grad_norm": 0.18101245164871216,
      "learning_rate": 4.571420923011029e-05,
      "loss": 0.1074,
      "step": 8010
    },
    {
      "epoch": 0.8587643216618481,
      "grad_norm": 0.1967460811138153,
      "learning_rate": 4.57088553378306e-05,
      "loss": 0.1263,
      "step": 8020
    },
    {
      "epoch": 0.8598351001177856,
      "grad_norm": 0.12024148553609848,
      "learning_rate": 4.5703501445550914e-05,
      "loss": 0.1086,
      "step": 8030
    },
    {
      "epoch": 0.8609058785737231,
      "grad_norm": 0.1546332687139511,
      "learning_rate": 4.569814755327123e-05,
      "loss": 0.1203,
      "step": 8040
    },
    {
      "epoch": 0.8619766570296605,
      "grad_norm": 0.11453968286514282,
      "learning_rate": 4.5692793660991544e-05,
      "loss": 0.1052,
      "step": 8050
    },
    {
      "epoch": 0.863047435485598,
      "grad_norm": 0.1503734439611435,
      "learning_rate": 4.5687439768711855e-05,
      "loss": 0.1142,
      "step": 8060
    },
    {
      "epoch": 0.8641182139415355,
      "grad_norm": 0.24630016088485718,
      "learning_rate": 4.5682085876432166e-05,
      "loss": 0.1093,
      "step": 8070
    },
    {
      "epoch": 0.8651889923974729,
      "grad_norm": 0.15077240765094757,
      "learning_rate": 4.5676731984152485e-05,
      "loss": 0.1133,
      "step": 8080
    },
    {
      "epoch": 0.8662597708534104,
      "grad_norm": 0.19160519540309906,
      "learning_rate": 4.5671378091872796e-05,
      "loss": 0.1023,
      "step": 8090
    },
    {
      "epoch": 0.8673305493093479,
      "grad_norm": 0.20221887528896332,
      "learning_rate": 4.566602419959311e-05,
      "loss": 0.1425,
      "step": 8100
    },
    {
      "epoch": 0.8684013277652853,
      "grad_norm": 0.1947299838066101,
      "learning_rate": 4.566067030731342e-05,
      "loss": 0.1128,
      "step": 8110
    },
    {
      "epoch": 0.8694721062212228,
      "grad_norm": 0.14385439455509186,
      "learning_rate": 4.565531641503373e-05,
      "loss": 0.1263,
      "step": 8120
    },
    {
      "epoch": 0.8705428846771603,
      "grad_norm": 0.14660485088825226,
      "learning_rate": 4.564996252275404e-05,
      "loss": 0.1161,
      "step": 8130
    },
    {
      "epoch": 0.8716136631330977,
      "grad_norm": 0.11470581591129303,
      "learning_rate": 4.564460863047435e-05,
      "loss": 0.1101,
      "step": 8140
    },
    {
      "epoch": 0.8726844415890352,
      "grad_norm": 0.11006028205156326,
      "learning_rate": 4.563925473819467e-05,
      "loss": 0.106,
      "step": 8150
    },
    {
      "epoch": 0.8737552200449727,
      "grad_norm": 0.16449782252311707,
      "learning_rate": 4.563390084591498e-05,
      "loss": 0.1155,
      "step": 8160
    },
    {
      "epoch": 0.8748259985009101,
      "grad_norm": 0.20564477145671844,
      "learning_rate": 4.5628546953635294e-05,
      "loss": 0.1157,
      "step": 8170
    },
    {
      "epoch": 0.8758967769568476,
      "grad_norm": 0.11978797614574432,
      "learning_rate": 4.5623193061355605e-05,
      "loss": 0.1259,
      "step": 8180
    },
    {
      "epoch": 0.8769675554127851,
      "grad_norm": 0.16904549300670624,
      "learning_rate": 4.5617839169075924e-05,
      "loss": 0.1015,
      "step": 8190
    },
    {
      "epoch": 0.8780383338687225,
      "grad_norm": 0.1243538036942482,
      "learning_rate": 4.5612485276796235e-05,
      "loss": 0.1012,
      "step": 8200
    },
    {
      "epoch": 0.87910911232466,
      "grad_norm": 0.19060002267360687,
      "learning_rate": 4.5607131384516546e-05,
      "loss": 0.1061,
      "step": 8210
    },
    {
      "epoch": 0.8801798907805974,
      "grad_norm": 0.144151508808136,
      "learning_rate": 4.560177749223686e-05,
      "loss": 0.1193,
      "step": 8220
    },
    {
      "epoch": 0.881250669236535,
      "grad_norm": 0.18606628477573395,
      "learning_rate": 4.559642359995717e-05,
      "loss": 0.119,
      "step": 8230
    },
    {
      "epoch": 0.8823214476924724,
      "grad_norm": 0.1613742560148239,
      "learning_rate": 4.559106970767749e-05,
      "loss": 0.1217,
      "step": 8240
    },
    {
      "epoch": 0.8833922261484098,
      "grad_norm": 0.15019536018371582,
      "learning_rate": 4.558571581539779e-05,
      "loss": 0.1046,
      "step": 8250
    },
    {
      "epoch": 0.8844630046043473,
      "grad_norm": 0.206448495388031,
      "learning_rate": 4.558036192311811e-05,
      "loss": 0.1102,
      "step": 8260
    },
    {
      "epoch": 0.8855337830602849,
      "grad_norm": 0.18459442257881165,
      "learning_rate": 4.557500803083842e-05,
      "loss": 0.1078,
      "step": 8270
    },
    {
      "epoch": 0.8866045615162222,
      "grad_norm": 0.19523519277572632,
      "learning_rate": 4.556965413855873e-05,
      "loss": 0.1182,
      "step": 8280
    },
    {
      "epoch": 0.8876753399721597,
      "grad_norm": 0.2389851212501526,
      "learning_rate": 4.5564300246279044e-05,
      "loss": 0.1265,
      "step": 8290
    },
    {
      "epoch": 0.8887461184280973,
      "grad_norm": 0.14461055397987366,
      "learning_rate": 4.555894635399936e-05,
      "loss": 0.1089,
      "step": 8300
    },
    {
      "epoch": 0.8898168968840346,
      "grad_norm": 0.15999144315719604,
      "learning_rate": 4.5553592461719674e-05,
      "loss": 0.1257,
      "step": 8310
    },
    {
      "epoch": 0.8908876753399722,
      "grad_norm": 0.2380635142326355,
      "learning_rate": 4.5548238569439985e-05,
      "loss": 0.1095,
      "step": 8320
    },
    {
      "epoch": 0.8919584537959097,
      "grad_norm": 0.15802615880966187,
      "learning_rate": 4.55428846771603e-05,
      "loss": 0.1132,
      "step": 8330
    },
    {
      "epoch": 0.893029232251847,
      "grad_norm": 0.23804689943790436,
      "learning_rate": 4.553753078488061e-05,
      "loss": 0.1211,
      "step": 8340
    },
    {
      "epoch": 0.8941000107077846,
      "grad_norm": 0.09106717258691788,
      "learning_rate": 4.5532176892600926e-05,
      "loss": 0.1209,
      "step": 8350
    },
    {
      "epoch": 0.8951707891637221,
      "grad_norm": 0.2747526466846466,
      "learning_rate": 4.552682300032123e-05,
      "loss": 0.1171,
      "step": 8360
    },
    {
      "epoch": 0.8962415676196595,
      "grad_norm": 0.19962017238140106,
      "learning_rate": 4.552146910804155e-05,
      "loss": 0.1255,
      "step": 8370
    },
    {
      "epoch": 0.897312346075597,
      "grad_norm": 0.2155900001525879,
      "learning_rate": 4.551611521576186e-05,
      "loss": 0.1054,
      "step": 8380
    },
    {
      "epoch": 0.8983831245315345,
      "grad_norm": 0.1564779281616211,
      "learning_rate": 4.551076132348218e-05,
      "loss": 0.1286,
      "step": 8390
    },
    {
      "epoch": 0.8994539029874719,
      "grad_norm": 0.22829695045948029,
      "learning_rate": 4.550540743120248e-05,
      "loss": 0.1036,
      "step": 8400
    },
    {
      "epoch": 0.9005246814434094,
      "grad_norm": 0.2102915495634079,
      "learning_rate": 4.55000535389228e-05,
      "loss": 0.1241,
      "step": 8410
    },
    {
      "epoch": 0.9015954598993469,
      "grad_norm": 0.14463083446025848,
      "learning_rate": 4.549469964664311e-05,
      "loss": 0.1141,
      "step": 8420
    },
    {
      "epoch": 0.9026662383552843,
      "grad_norm": 0.169950932264328,
      "learning_rate": 4.5489345754363424e-05,
      "loss": 0.1167,
      "step": 8430
    },
    {
      "epoch": 0.9037370168112218,
      "grad_norm": 0.16142329573631287,
      "learning_rate": 4.5483991862083736e-05,
      "loss": 0.1179,
      "step": 8440
    },
    {
      "epoch": 0.9048077952671593,
      "grad_norm": 0.13164830207824707,
      "learning_rate": 4.547863796980405e-05,
      "loss": 0.1123,
      "step": 8450
    },
    {
      "epoch": 0.9058785737230967,
      "grad_norm": 0.21358712017536163,
      "learning_rate": 4.5473284077524365e-05,
      "loss": 0.1047,
      "step": 8460
    },
    {
      "epoch": 0.9069493521790342,
      "grad_norm": 0.1437821090221405,
      "learning_rate": 4.546793018524467e-05,
      "loss": 0.1134,
      "step": 8470
    },
    {
      "epoch": 0.9080201306349717,
      "grad_norm": 0.24279183149337769,
      "learning_rate": 4.546257629296499e-05,
      "loss": 0.1327,
      "step": 8480
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.20288807153701782,
      "learning_rate": 4.54572224006853e-05,
      "loss": 0.1226,
      "step": 8490
    },
    {
      "epoch": 0.9101616875468466,
      "grad_norm": 0.19057391583919525,
      "learning_rate": 4.545186850840562e-05,
      "loss": 0.1144,
      "step": 8500
    },
    {
      "epoch": 0.9112324660027841,
      "grad_norm": 0.19536635279655457,
      "learning_rate": 4.544651461612592e-05,
      "loss": 0.1221,
      "step": 8510
    },
    {
      "epoch": 0.9123032444587215,
      "grad_norm": 0.1339339166879654,
      "learning_rate": 4.544116072384624e-05,
      "loss": 0.1206,
      "step": 8520
    },
    {
      "epoch": 0.913374022914659,
      "grad_norm": 0.6644772291183472,
      "learning_rate": 4.543580683156655e-05,
      "loss": 0.127,
      "step": 8530
    },
    {
      "epoch": 0.9144448013705965,
      "grad_norm": 0.2221360206604004,
      "learning_rate": 4.543045293928686e-05,
      "loss": 0.1122,
      "step": 8540
    },
    {
      "epoch": 0.9155155798265339,
      "grad_norm": 0.20323924720287323,
      "learning_rate": 4.5425099047007175e-05,
      "loss": 0.1089,
      "step": 8550
    },
    {
      "epoch": 0.9165863582824714,
      "grad_norm": 0.15623153746128082,
      "learning_rate": 4.5419745154727486e-05,
      "loss": 0.1204,
      "step": 8560
    },
    {
      "epoch": 0.9176571367384089,
      "grad_norm": 0.15739355981349945,
      "learning_rate": 4.5414391262447804e-05,
      "loss": 0.1253,
      "step": 8570
    },
    {
      "epoch": 0.9187279151943463,
      "grad_norm": 0.1609705090522766,
      "learning_rate": 4.5409037370168116e-05,
      "loss": 0.1185,
      "step": 8580
    },
    {
      "epoch": 0.9197986936502838,
      "grad_norm": 0.11447038501501083,
      "learning_rate": 4.540368347788843e-05,
      "loss": 0.1134,
      "step": 8590
    },
    {
      "epoch": 0.9208694721062213,
      "grad_norm": 0.6608713269233704,
      "learning_rate": 4.539832958560874e-05,
      "loss": 0.0936,
      "step": 8600
    },
    {
      "epoch": 0.9219402505621587,
      "grad_norm": 0.3093360960483551,
      "learning_rate": 4.539297569332906e-05,
      "loss": 0.1252,
      "step": 8610
    },
    {
      "epoch": 0.9230110290180962,
      "grad_norm": 0.16560709476470947,
      "learning_rate": 4.538762180104936e-05,
      "loss": 0.1041,
      "step": 8620
    },
    {
      "epoch": 0.9240818074740336,
      "grad_norm": 0.1917511522769928,
      "learning_rate": 4.538226790876968e-05,
      "loss": 0.1207,
      "step": 8630
    },
    {
      "epoch": 0.9251525859299711,
      "grad_norm": 0.15927192568778992,
      "learning_rate": 4.537691401648999e-05,
      "loss": 0.1046,
      "step": 8640
    },
    {
      "epoch": 0.9262233643859086,
      "grad_norm": 0.6536536812782288,
      "learning_rate": 4.53715601242103e-05,
      "loss": 0.1285,
      "step": 8650
    },
    {
      "epoch": 0.927294142841846,
      "grad_norm": 0.1893158107995987,
      "learning_rate": 4.5366206231930614e-05,
      "loss": 0.1421,
      "step": 8660
    },
    {
      "epoch": 0.9283649212977835,
      "grad_norm": 0.13847202062606812,
      "learning_rate": 4.5360852339650925e-05,
      "loss": 0.1068,
      "step": 8670
    },
    {
      "epoch": 0.929435699753721,
      "grad_norm": 0.14577607810497284,
      "learning_rate": 4.535549844737124e-05,
      "loss": 0.1138,
      "step": 8680
    },
    {
      "epoch": 0.9305064782096584,
      "grad_norm": 0.13739743828773499,
      "learning_rate": 4.5350144555091555e-05,
      "loss": 0.1021,
      "step": 8690
    },
    {
      "epoch": 0.9315772566655959,
      "grad_norm": 0.21018362045288086,
      "learning_rate": 4.5344790662811866e-05,
      "loss": 0.1158,
      "step": 8700
    },
    {
      "epoch": 0.9326480351215334,
      "grad_norm": 0.34805357456207275,
      "learning_rate": 4.533943677053218e-05,
      "loss": 0.1239,
      "step": 8710
    },
    {
      "epoch": 0.9337188135774708,
      "grad_norm": 0.15298211574554443,
      "learning_rate": 4.5334082878252496e-05,
      "loss": 0.0999,
      "step": 8720
    },
    {
      "epoch": 0.9347895920334083,
      "grad_norm": 0.1252986192703247,
      "learning_rate": 4.532872898597281e-05,
      "loss": 0.1202,
      "step": 8730
    },
    {
      "epoch": 0.9358603704893458,
      "grad_norm": 0.15252617001533508,
      "learning_rate": 4.532337509369312e-05,
      "loss": 0.1044,
      "step": 8740
    },
    {
      "epoch": 0.9369311489452832,
      "grad_norm": 0.2287357598543167,
      "learning_rate": 4.531802120141343e-05,
      "loss": 0.1158,
      "step": 8750
    },
    {
      "epoch": 0.9380019274012207,
      "grad_norm": 0.20458419620990753,
      "learning_rate": 4.531266730913374e-05,
      "loss": 0.1029,
      "step": 8760
    },
    {
      "epoch": 0.9390727058571582,
      "grad_norm": 0.11333898454904556,
      "learning_rate": 4.530731341685405e-05,
      "loss": 0.1013,
      "step": 8770
    },
    {
      "epoch": 0.9401434843130956,
      "grad_norm": 0.21424366533756256,
      "learning_rate": 4.5301959524574364e-05,
      "loss": 0.1106,
      "step": 8780
    },
    {
      "epoch": 0.9412142627690331,
      "grad_norm": 0.18549121916294098,
      "learning_rate": 4.529660563229468e-05,
      "loss": 0.1105,
      "step": 8790
    },
    {
      "epoch": 0.9422850412249706,
      "grad_norm": 0.11733882129192352,
      "learning_rate": 4.5291251740014994e-05,
      "loss": 0.104,
      "step": 8800
    },
    {
      "epoch": 0.943355819680908,
      "grad_norm": 0.21929949522018433,
      "learning_rate": 4.5285897847735305e-05,
      "loss": 0.1174,
      "step": 8810
    },
    {
      "epoch": 0.9444265981368455,
      "grad_norm": 0.1452602595090866,
      "learning_rate": 4.5280543955455616e-05,
      "loss": 0.1088,
      "step": 8820
    },
    {
      "epoch": 0.945497376592783,
      "grad_norm": 0.15318433940410614,
      "learning_rate": 4.5275190063175935e-05,
      "loss": 0.1145,
      "step": 8830
    },
    {
      "epoch": 0.9465681550487204,
      "grad_norm": 0.2526857256889343,
      "learning_rate": 4.5269836170896246e-05,
      "loss": 0.1127,
      "step": 8840
    },
    {
      "epoch": 0.9476389335046579,
      "grad_norm": 0.16333214938640594,
      "learning_rate": 4.526448227861656e-05,
      "loss": 0.1133,
      "step": 8850
    },
    {
      "epoch": 0.9487097119605954,
      "grad_norm": 0.1726233959197998,
      "learning_rate": 4.525912838633687e-05,
      "loss": 0.1331,
      "step": 8860
    },
    {
      "epoch": 0.9497804904165328,
      "grad_norm": 0.12936227023601532,
      "learning_rate": 4.525377449405718e-05,
      "loss": 0.1085,
      "step": 8870
    },
    {
      "epoch": 0.9508512688724703,
      "grad_norm": 0.16860246658325195,
      "learning_rate": 4.52484206017775e-05,
      "loss": 0.1234,
      "step": 8880
    },
    {
      "epoch": 0.9519220473284078,
      "grad_norm": 0.15017038583755493,
      "learning_rate": 4.52430667094978e-05,
      "loss": 0.1127,
      "step": 8890
    },
    {
      "epoch": 0.9529928257843452,
      "grad_norm": 0.11264584958553314,
      "learning_rate": 4.523771281721812e-05,
      "loss": 0.1134,
      "step": 8900
    },
    {
      "epoch": 0.9540636042402827,
      "grad_norm": 0.18150007724761963,
      "learning_rate": 4.523235892493843e-05,
      "loss": 0.1132,
      "step": 8910
    },
    {
      "epoch": 0.9551343826962202,
      "grad_norm": 0.20432430505752563,
      "learning_rate": 4.5227005032658744e-05,
      "loss": 0.125,
      "step": 8920
    },
    {
      "epoch": 0.9562051611521576,
      "grad_norm": 0.1478664129972458,
      "learning_rate": 4.5221651140379055e-05,
      "loss": 0.1207,
      "step": 8930
    },
    {
      "epoch": 0.9572759396080951,
      "grad_norm": 0.14869938790798187,
      "learning_rate": 4.5216297248099373e-05,
      "loss": 0.1164,
      "step": 8940
    },
    {
      "epoch": 0.9583467180640326,
      "grad_norm": 0.18329539895057678,
      "learning_rate": 4.5210943355819685e-05,
      "loss": 0.1161,
      "step": 8950
    },
    {
      "epoch": 0.95941749651997,
      "grad_norm": 0.17453108727931976,
      "learning_rate": 4.5205589463539996e-05,
      "loss": 0.1148,
      "step": 8960
    },
    {
      "epoch": 0.9604882749759075,
      "grad_norm": 0.1497269570827484,
      "learning_rate": 4.520023557126031e-05,
      "loss": 0.1148,
      "step": 8970
    },
    {
      "epoch": 0.961559053431845,
      "grad_norm": 0.2495776116847992,
      "learning_rate": 4.519488167898062e-05,
      "loss": 0.1155,
      "step": 8980
    },
    {
      "epoch": 0.9626298318877824,
      "grad_norm": 0.13667917251586914,
      "learning_rate": 4.518952778670094e-05,
      "loss": 0.1099,
      "step": 8990
    },
    {
      "epoch": 0.9637006103437199,
      "grad_norm": 0.17387016117572784,
      "learning_rate": 4.518417389442124e-05,
      "loss": 0.11,
      "step": 9000
    },
    {
      "epoch": 0.9647713887996574,
      "grad_norm": 0.31140920519828796,
      "learning_rate": 4.517882000214156e-05,
      "loss": 0.1218,
      "step": 9010
    },
    {
      "epoch": 0.9658421672555948,
      "grad_norm": 0.37794584035873413,
      "learning_rate": 4.517346610986187e-05,
      "loss": 0.1063,
      "step": 9020
    },
    {
      "epoch": 0.9669129457115323,
      "grad_norm": 0.5135964751243591,
      "learning_rate": 4.516811221758219e-05,
      "loss": 0.1086,
      "step": 9030
    },
    {
      "epoch": 0.9679837241674698,
      "grad_norm": 0.14093106985092163,
      "learning_rate": 4.5162758325302494e-05,
      "loss": 0.1148,
      "step": 9040
    },
    {
      "epoch": 0.9690545026234072,
      "grad_norm": 0.2789715826511383,
      "learning_rate": 4.515740443302281e-05,
      "loss": 0.1255,
      "step": 9050
    },
    {
      "epoch": 0.9701252810793447,
      "grad_norm": 0.12944982945919037,
      "learning_rate": 4.5152050540743124e-05,
      "loss": 0.113,
      "step": 9060
    },
    {
      "epoch": 0.9711960595352821,
      "grad_norm": 0.24093316495418549,
      "learning_rate": 4.5146696648463435e-05,
      "loss": 0.1115,
      "step": 9070
    },
    {
      "epoch": 0.9722668379912196,
      "grad_norm": 0.18862999975681305,
      "learning_rate": 4.514134275618375e-05,
      "loss": 0.1212,
      "step": 9080
    },
    {
      "epoch": 0.9733376164471571,
      "grad_norm": 0.1788669377565384,
      "learning_rate": 4.513598886390406e-05,
      "loss": 0.097,
      "step": 9090
    },
    {
      "epoch": 0.9744083949030945,
      "grad_norm": 0.25152096152305603,
      "learning_rate": 4.5130634971624376e-05,
      "loss": 0.103,
      "step": 9100
    },
    {
      "epoch": 0.975479173359032,
      "grad_norm": 0.19282731413841248,
      "learning_rate": 4.512528107934468e-05,
      "loss": 0.1155,
      "step": 9110
    },
    {
      "epoch": 0.9765499518149695,
      "grad_norm": 0.23824673891067505,
      "learning_rate": 4.5119927187065e-05,
      "loss": 0.1031,
      "step": 9120
    },
    {
      "epoch": 0.9776207302709069,
      "grad_norm": 0.18602965772151947,
      "learning_rate": 4.511457329478531e-05,
      "loss": 0.1217,
      "step": 9130
    },
    {
      "epoch": 0.9786915087268444,
      "grad_norm": 0.1990974396467209,
      "learning_rate": 4.510921940250563e-05,
      "loss": 0.11,
      "step": 9140
    },
    {
      "epoch": 0.9797622871827819,
      "grad_norm": 0.14840276539325714,
      "learning_rate": 4.510386551022593e-05,
      "loss": 0.11,
      "step": 9150
    },
    {
      "epoch": 0.9808330656387193,
      "grad_norm": 0.17196393013000488,
      "learning_rate": 4.509851161794625e-05,
      "loss": 0.1142,
      "step": 9160
    },
    {
      "epoch": 0.9819038440946568,
      "grad_norm": 0.20569603145122528,
      "learning_rate": 4.509315772566656e-05,
      "loss": 0.1126,
      "step": 9170
    },
    {
      "epoch": 0.9829746225505943,
      "grad_norm": 0.1454896777868271,
      "learning_rate": 4.5087803833386874e-05,
      "loss": 0.1207,
      "step": 9180
    },
    {
      "epoch": 0.9840454010065317,
      "grad_norm": 0.14220425486564636,
      "learning_rate": 4.5082449941107186e-05,
      "loss": 0.1269,
      "step": 9190
    },
    {
      "epoch": 0.9851161794624692,
      "grad_norm": 0.13239158689975739,
      "learning_rate": 4.50770960488275e-05,
      "loss": 0.1102,
      "step": 9200
    },
    {
      "epoch": 0.9861869579184067,
      "grad_norm": 0.14470764994621277,
      "learning_rate": 4.5071742156547815e-05,
      "loss": 0.1169,
      "step": 9210
    },
    {
      "epoch": 0.9872577363743441,
      "grad_norm": 0.13762320578098297,
      "learning_rate": 4.506638826426812e-05,
      "loss": 0.1216,
      "step": 9220
    },
    {
      "epoch": 0.9883285148302816,
      "grad_norm": 0.3365268111228943,
      "learning_rate": 4.506103437198844e-05,
      "loss": 0.1297,
      "step": 9230
    },
    {
      "epoch": 0.9893992932862191,
      "grad_norm": 0.1211659237742424,
      "learning_rate": 4.505568047970875e-05,
      "loss": 0.101,
      "step": 9240
    },
    {
      "epoch": 0.9904700717421565,
      "grad_norm": 0.3429073691368103,
      "learning_rate": 4.505032658742907e-05,
      "loss": 0.1177,
      "step": 9250
    },
    {
      "epoch": 0.991540850198094,
      "grad_norm": 0.10457024723291397,
      "learning_rate": 4.504497269514937e-05,
      "loss": 0.1079,
      "step": 9260
    },
    {
      "epoch": 0.9926116286540315,
      "grad_norm": 0.12470296025276184,
      "learning_rate": 4.503961880286969e-05,
      "loss": 0.0962,
      "step": 9270
    },
    {
      "epoch": 0.9936824071099689,
      "grad_norm": 0.14894257485866547,
      "learning_rate": 4.503426491059e-05,
      "loss": 0.1079,
      "step": 9280
    },
    {
      "epoch": 0.9947531855659064,
      "grad_norm": 0.12787064909934998,
      "learning_rate": 4.502891101831031e-05,
      "loss": 0.1056,
      "step": 9290
    },
    {
      "epoch": 0.9958239640218439,
      "grad_norm": 0.21932575106620789,
      "learning_rate": 4.5023557126030625e-05,
      "loss": 0.1055,
      "step": 9300
    },
    {
      "epoch": 0.9968947424777813,
      "grad_norm": 0.11136143654584885,
      "learning_rate": 4.5018203233750936e-05,
      "loss": 0.104,
      "step": 9310
    },
    {
      "epoch": 0.9979655209337188,
      "grad_norm": 0.14334611594676971,
      "learning_rate": 4.5012849341471254e-05,
      "loss": 0.0981,
      "step": 9320
    },
    {
      "epoch": 0.9990362993896563,
      "grad_norm": 0.1448213905096054,
      "learning_rate": 4.5007495449191566e-05,
      "loss": 0.0943,
      "step": 9330
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.09256803244352341,
      "eval_runtime": 140.3831,
      "eval_samples_per_second": 59.138,
      "eval_steps_per_second": 7.394,
      "step": 9339
    },
    {
      "epoch": 1.0001070778455938,
      "grad_norm": 0.15864308178424835,
      "learning_rate": 4.500214155691188e-05,
      "loss": 0.1245,
      "step": 9340
    },
    {
      "epoch": 1.0011778563015312,
      "grad_norm": 0.19007034599781036,
      "learning_rate": 4.499678766463219e-05,
      "loss": 0.1171,
      "step": 9350
    },
    {
      "epoch": 1.0022486347574686,
      "grad_norm": 0.17942079901695251,
      "learning_rate": 4.4991433772352506e-05,
      "loss": 0.1177,
      "step": 9360
    },
    {
      "epoch": 1.0033194132134062,
      "grad_norm": 0.16998189687728882,
      "learning_rate": 4.498607988007282e-05,
      "loss": 0.1237,
      "step": 9370
    },
    {
      "epoch": 1.0043901916693436,
      "grad_norm": 0.13201528787612915,
      "learning_rate": 4.498072598779313e-05,
      "loss": 0.113,
      "step": 9380
    },
    {
      "epoch": 1.005460970125281,
      "grad_norm": 0.19063273072242737,
      "learning_rate": 4.497537209551344e-05,
      "loss": 0.103,
      "step": 9390
    },
    {
      "epoch": 1.0065317485812186,
      "grad_norm": 0.18631316721439362,
      "learning_rate": 4.497001820323375e-05,
      "loss": 0.1102,
      "step": 9400
    },
    {
      "epoch": 1.007602527037156,
      "grad_norm": 0.26254749298095703,
      "learning_rate": 4.4964664310954063e-05,
      "loss": 0.1104,
      "step": 9410
    },
    {
      "epoch": 1.0086733054930934,
      "grad_norm": 0.12126170098781586,
      "learning_rate": 4.4959310418674375e-05,
      "loss": 0.1148,
      "step": 9420
    },
    {
      "epoch": 1.009744083949031,
      "grad_norm": 0.24992908537387848,
      "learning_rate": 4.495395652639469e-05,
      "loss": 0.1005,
      "step": 9430
    },
    {
      "epoch": 1.0108148624049684,
      "grad_norm": 0.1480202078819275,
      "learning_rate": 4.4948602634115004e-05,
      "loss": 0.1015,
      "step": 9440
    },
    {
      "epoch": 1.0118856408609058,
      "grad_norm": 0.26882776618003845,
      "learning_rate": 4.4943248741835316e-05,
      "loss": 0.1215,
      "step": 9450
    },
    {
      "epoch": 1.0129564193168434,
      "grad_norm": 0.13689127564430237,
      "learning_rate": 4.493789484955563e-05,
      "loss": 0.1139,
      "step": 9460
    },
    {
      "epoch": 1.0140271977727808,
      "grad_norm": 0.2203177511692047,
      "learning_rate": 4.4932540957275945e-05,
      "loss": 0.1153,
      "step": 9470
    },
    {
      "epoch": 1.0150979762287182,
      "grad_norm": 0.1636662632226944,
      "learning_rate": 4.492718706499626e-05,
      "loss": 0.1177,
      "step": 9480
    },
    {
      "epoch": 1.0161687546846558,
      "grad_norm": 0.25173521041870117,
      "learning_rate": 4.492183317271657e-05,
      "loss": 0.1015,
      "step": 9490
    },
    {
      "epoch": 1.0172395331405932,
      "grad_norm": 0.13148817420005798,
      "learning_rate": 4.491647928043688e-05,
      "loss": 0.1024,
      "step": 9500
    },
    {
      "epoch": 1.0183103115965306,
      "grad_norm": 0.12733817100524902,
      "learning_rate": 4.491112538815719e-05,
      "loss": 0.104,
      "step": 9510
    },
    {
      "epoch": 1.0193810900524682,
      "grad_norm": 0.27941322326660156,
      "learning_rate": 4.490577149587751e-05,
      "loss": 0.1416,
      "step": 9520
    },
    {
      "epoch": 1.0204518685084056,
      "grad_norm": 0.16490280628204346,
      "learning_rate": 4.4900417603597814e-05,
      "loss": 0.1106,
      "step": 9530
    },
    {
      "epoch": 1.021522646964343,
      "grad_norm": 0.1466512382030487,
      "learning_rate": 4.489506371131813e-05,
      "loss": 0.1098,
      "step": 9540
    },
    {
      "epoch": 1.0225934254202806,
      "grad_norm": 0.1536099761724472,
      "learning_rate": 4.4889709819038443e-05,
      "loss": 0.1107,
      "step": 9550
    },
    {
      "epoch": 1.023664203876218,
      "grad_norm": 0.16823309659957886,
      "learning_rate": 4.4884355926758755e-05,
      "loss": 0.1005,
      "step": 9560
    },
    {
      "epoch": 1.0247349823321554,
      "grad_norm": 0.14033830165863037,
      "learning_rate": 4.4879002034479066e-05,
      "loss": 0.0934,
      "step": 9570
    },
    {
      "epoch": 1.025805760788093,
      "grad_norm": 0.14824390411376953,
      "learning_rate": 4.4873648142199384e-05,
      "loss": 0.1119,
      "step": 9580
    },
    {
      "epoch": 1.0268765392440304,
      "grad_norm": 0.22913643717765808,
      "learning_rate": 4.4868294249919696e-05,
      "loss": 0.1175,
      "step": 9590
    },
    {
      "epoch": 1.0279473176999678,
      "grad_norm": 0.399077832698822,
      "learning_rate": 4.486294035764001e-05,
      "loss": 0.1038,
      "step": 9600
    },
    {
      "epoch": 1.0290180961559054,
      "grad_norm": 0.17707884311676025,
      "learning_rate": 4.485758646536032e-05,
      "loss": 0.1195,
      "step": 9610
    },
    {
      "epoch": 1.0300888746118428,
      "grad_norm": 0.20060984790325165,
      "learning_rate": 4.485223257308063e-05,
      "loss": 0.1123,
      "step": 9620
    },
    {
      "epoch": 1.0311596530677802,
      "grad_norm": 0.1814049631357193,
      "learning_rate": 4.484687868080095e-05,
      "loss": 0.1075,
      "step": 9630
    },
    {
      "epoch": 1.0322304315237179,
      "grad_norm": 0.2144412398338318,
      "learning_rate": 4.484152478852125e-05,
      "loss": 0.1091,
      "step": 9640
    },
    {
      "epoch": 1.0333012099796552,
      "grad_norm": 0.14252902567386627,
      "learning_rate": 4.483617089624157e-05,
      "loss": 0.1149,
      "step": 9650
    },
    {
      "epoch": 1.0343719884355926,
      "grad_norm": 0.14099173247814178,
      "learning_rate": 4.483081700396188e-05,
      "loss": 0.1002,
      "step": 9660
    },
    {
      "epoch": 1.03544276689153,
      "grad_norm": 0.3147027790546417,
      "learning_rate": 4.48254631116822e-05,
      "loss": 0.1031,
      "step": 9670
    },
    {
      "epoch": 1.0365135453474676,
      "grad_norm": 0.1745763123035431,
      "learning_rate": 4.4820109219402505e-05,
      "loss": 0.1174,
      "step": 9680
    },
    {
      "epoch": 1.037584323803405,
      "grad_norm": 0.13873878121376038,
      "learning_rate": 4.481475532712282e-05,
      "loss": 0.1054,
      "step": 9690
    },
    {
      "epoch": 1.0386551022593427,
      "grad_norm": 0.1572226583957672,
      "learning_rate": 4.4809401434843135e-05,
      "loss": 0.0975,
      "step": 9700
    },
    {
      "epoch": 1.03972588071528,
      "grad_norm": 0.1747484803199768,
      "learning_rate": 4.4804047542563446e-05,
      "loss": 0.1038,
      "step": 9710
    },
    {
      "epoch": 1.0407966591712174,
      "grad_norm": 0.20218907296657562,
      "learning_rate": 4.479869365028376e-05,
      "loss": 0.1187,
      "step": 9720
    },
    {
      "epoch": 1.0418674376271548,
      "grad_norm": 0.15092439949512482,
      "learning_rate": 4.479333975800407e-05,
      "loss": 0.1239,
      "step": 9730
    },
    {
      "epoch": 1.0429382160830925,
      "grad_norm": 0.18938593566417694,
      "learning_rate": 4.478798586572439e-05,
      "loss": 0.1127,
      "step": 9740
    },
    {
      "epoch": 1.0440089945390298,
      "grad_norm": 0.19678691029548645,
      "learning_rate": 4.478263197344469e-05,
      "loss": 0.0952,
      "step": 9750
    },
    {
      "epoch": 1.0450797729949672,
      "grad_norm": 0.18266689777374268,
      "learning_rate": 4.477727808116501e-05,
      "loss": 0.109,
      "step": 9760
    },
    {
      "epoch": 1.0461505514509049,
      "grad_norm": 0.23947416245937347,
      "learning_rate": 4.477192418888532e-05,
      "loss": 0.0883,
      "step": 9770
    },
    {
      "epoch": 1.0472213299068422,
      "grad_norm": 0.2090725600719452,
      "learning_rate": 4.476657029660564e-05,
      "loss": 0.1206,
      "step": 9780
    },
    {
      "epoch": 1.0482921083627796,
      "grad_norm": 0.15533728897571564,
      "learning_rate": 4.4761216404325944e-05,
      "loss": 0.11,
      "step": 9790
    },
    {
      "epoch": 1.0493628868187173,
      "grad_norm": 0.136226087808609,
      "learning_rate": 4.475586251204626e-05,
      "loss": 0.1149,
      "step": 9800
    },
    {
      "epoch": 1.0504336652746546,
      "grad_norm": 0.20905666053295135,
      "learning_rate": 4.4750508619766574e-05,
      "loss": 0.1124,
      "step": 9810
    },
    {
      "epoch": 1.051504443730592,
      "grad_norm": 0.14890481531620026,
      "learning_rate": 4.4745154727486885e-05,
      "loss": 0.1077,
      "step": 9820
    },
    {
      "epoch": 1.0525752221865297,
      "grad_norm": 0.22781285643577576,
      "learning_rate": 4.4739800835207197e-05,
      "loss": 0.1142,
      "step": 9830
    },
    {
      "epoch": 1.053646000642467,
      "grad_norm": 0.12761180102825165,
      "learning_rate": 4.473444694292751e-05,
      "loss": 0.117,
      "step": 9840
    },
    {
      "epoch": 1.0547167790984044,
      "grad_norm": 0.2742331624031067,
      "learning_rate": 4.4729093050647826e-05,
      "loss": 0.1095,
      "step": 9850
    },
    {
      "epoch": 1.055787557554342,
      "grad_norm": 0.21694086492061615,
      "learning_rate": 4.472373915836813e-05,
      "loss": 0.126,
      "step": 9860
    },
    {
      "epoch": 1.0568583360102795,
      "grad_norm": 0.1544310599565506,
      "learning_rate": 4.471838526608845e-05,
      "loss": 0.0974,
      "step": 9870
    },
    {
      "epoch": 1.0579291144662168,
      "grad_norm": 0.19415704905986786,
      "learning_rate": 4.471303137380876e-05,
      "loss": 0.099,
      "step": 9880
    },
    {
      "epoch": 1.0589998929221545,
      "grad_norm": 0.25390559434890747,
      "learning_rate": 4.470767748152908e-05,
      "loss": 0.1204,
      "step": 9890
    },
    {
      "epoch": 1.0600706713780919,
      "grad_norm": 0.17193403840065002,
      "learning_rate": 4.470232358924938e-05,
      "loss": 0.1024,
      "step": 9900
    },
    {
      "epoch": 1.0611414498340292,
      "grad_norm": 0.1647241711616516,
      "learning_rate": 4.46969696969697e-05,
      "loss": 0.1068,
      "step": 9910
    },
    {
      "epoch": 1.0622122282899669,
      "grad_norm": 0.16160771250724792,
      "learning_rate": 4.469161580469001e-05,
      "loss": 0.1079,
      "step": 9920
    },
    {
      "epoch": 1.0632830067459043,
      "grad_norm": 0.13513055443763733,
      "learning_rate": 4.4686261912410324e-05,
      "loss": 0.1196,
      "step": 9930
    },
    {
      "epoch": 1.0643537852018417,
      "grad_norm": 0.17679129540920258,
      "learning_rate": 4.4680908020130635e-05,
      "loss": 0.1032,
      "step": 9940
    },
    {
      "epoch": 1.0654245636577793,
      "grad_norm": 0.15826375782489777,
      "learning_rate": 4.467555412785095e-05,
      "loss": 0.1059,
      "step": 9950
    },
    {
      "epoch": 1.0664953421137167,
      "grad_norm": 0.1255495250225067,
      "learning_rate": 4.4670200235571265e-05,
      "loss": 0.1132,
      "step": 9960
    },
    {
      "epoch": 1.067566120569654,
      "grad_norm": 0.14767181873321533,
      "learning_rate": 4.4664846343291576e-05,
      "loss": 0.1225,
      "step": 9970
    },
    {
      "epoch": 1.0686368990255917,
      "grad_norm": 0.1418716460466385,
      "learning_rate": 4.465949245101189e-05,
      "loss": 0.1011,
      "step": 9980
    },
    {
      "epoch": 1.069707677481529,
      "grad_norm": 0.15261287987232208,
      "learning_rate": 4.46541385587322e-05,
      "loss": 0.1129,
      "step": 9990
    },
    {
      "epoch": 1.0707784559374665,
      "grad_norm": 0.188803568482399,
      "learning_rate": 4.464878466645252e-05,
      "loss": 0.1277,
      "step": 10000
    },
    {
      "epoch": 1.071849234393404,
      "grad_norm": 0.13946276903152466,
      "learning_rate": 4.464343077417282e-05,
      "loss": 0.1139,
      "step": 10010
    },
    {
      "epoch": 1.0729200128493415,
      "grad_norm": 0.1916520595550537,
      "learning_rate": 4.463807688189314e-05,
      "loss": 0.1047,
      "step": 10020
    },
    {
      "epoch": 1.0739907913052789,
      "grad_norm": 0.1641698032617569,
      "learning_rate": 4.463272298961345e-05,
      "loss": 0.1132,
      "step": 10030
    },
    {
      "epoch": 1.0750615697612165,
      "grad_norm": 0.24174615740776062,
      "learning_rate": 4.462736909733376e-05,
      "loss": 0.1096,
      "step": 10040
    },
    {
      "epoch": 1.0761323482171539,
      "grad_norm": 0.14928899705410004,
      "learning_rate": 4.4622015205054074e-05,
      "loss": 0.0986,
      "step": 10050
    },
    {
      "epoch": 1.0772031266730913,
      "grad_norm": 0.12021391838788986,
      "learning_rate": 4.4616661312774386e-05,
      "loss": 0.1072,
      "step": 10060
    },
    {
      "epoch": 1.0782739051290289,
      "grad_norm": 0.19540567696094513,
      "learning_rate": 4.4611307420494704e-05,
      "loss": 0.1223,
      "step": 10070
    },
    {
      "epoch": 1.0793446835849663,
      "grad_norm": 0.19310015439987183,
      "learning_rate": 4.4605953528215015e-05,
      "loss": 0.1186,
      "step": 10080
    },
    {
      "epoch": 1.0804154620409037,
      "grad_norm": 0.11456461995840073,
      "learning_rate": 4.460059963593533e-05,
      "loss": 0.11,
      "step": 10090
    },
    {
      "epoch": 1.0814862404968413,
      "grad_norm": 0.1679612100124359,
      "learning_rate": 4.459524574365564e-05,
      "loss": 0.104,
      "step": 10100
    },
    {
      "epoch": 1.0825570189527787,
      "grad_norm": 0.17450430989265442,
      "learning_rate": 4.4589891851375956e-05,
      "loss": 0.1031,
      "step": 10110
    },
    {
      "epoch": 1.083627797408716,
      "grad_norm": 0.17544929683208466,
      "learning_rate": 4.458453795909627e-05,
      "loss": 0.1113,
      "step": 10120
    },
    {
      "epoch": 1.0846985758646537,
      "grad_norm": 0.18263572454452515,
      "learning_rate": 4.457918406681658e-05,
      "loss": 0.1035,
      "step": 10130
    },
    {
      "epoch": 1.085769354320591,
      "grad_norm": 0.15162472426891327,
      "learning_rate": 4.457383017453689e-05,
      "loss": 0.0968,
      "step": 10140
    },
    {
      "epoch": 1.0868401327765285,
      "grad_norm": 0.3422949016094208,
      "learning_rate": 4.45684762822572e-05,
      "loss": 0.1124,
      "step": 10150
    },
    {
      "epoch": 1.087910911232466,
      "grad_norm": 0.11569152772426605,
      "learning_rate": 4.456312238997752e-05,
      "loss": 0.1107,
      "step": 10160
    },
    {
      "epoch": 1.0889816896884035,
      "grad_norm": 0.16002653539180756,
      "learning_rate": 4.4557768497697825e-05,
      "loss": 0.1013,
      "step": 10170
    },
    {
      "epoch": 1.0900524681443409,
      "grad_norm": 0.19975906610488892,
      "learning_rate": 4.455241460541814e-05,
      "loss": 0.1273,
      "step": 10180
    },
    {
      "epoch": 1.0911232466002785,
      "grad_norm": 0.1472300887107849,
      "learning_rate": 4.4547060713138454e-05,
      "loss": 0.1079,
      "step": 10190
    },
    {
      "epoch": 1.0921940250562159,
      "grad_norm": 0.1452077329158783,
      "learning_rate": 4.4541706820858766e-05,
      "loss": 0.1053,
      "step": 10200
    },
    {
      "epoch": 1.0932648035121533,
      "grad_norm": 0.1796565055847168,
      "learning_rate": 4.453635292857908e-05,
      "loss": 0.0994,
      "step": 10210
    },
    {
      "epoch": 1.0943355819680909,
      "grad_norm": 0.11785932630300522,
      "learning_rate": 4.4530999036299395e-05,
      "loss": 0.1015,
      "step": 10220
    },
    {
      "epoch": 1.0954063604240283,
      "grad_norm": 0.19147548079490662,
      "learning_rate": 4.452564514401971e-05,
      "loss": 0.104,
      "step": 10230
    },
    {
      "epoch": 1.0964771388799657,
      "grad_norm": 0.1729084551334381,
      "learning_rate": 4.452029125174002e-05,
      "loss": 0.105,
      "step": 10240
    },
    {
      "epoch": 1.0975479173359033,
      "grad_norm": 0.18976075947284698,
      "learning_rate": 4.451493735946033e-05,
      "loss": 0.1109,
      "step": 10250
    },
    {
      "epoch": 1.0986186957918407,
      "grad_norm": 0.1296250969171524,
      "learning_rate": 4.450958346718064e-05,
      "loss": 0.11,
      "step": 10260
    },
    {
      "epoch": 1.099689474247778,
      "grad_norm": 0.17504474520683289,
      "learning_rate": 4.450422957490096e-05,
      "loss": 0.1047,
      "step": 10270
    },
    {
      "epoch": 1.1007602527037157,
      "grad_norm": 0.10473454743623734,
      "learning_rate": 4.4498875682621264e-05,
      "loss": 0.0848,
      "step": 10280
    },
    {
      "epoch": 1.101831031159653,
      "grad_norm": 0.12300942093133926,
      "learning_rate": 4.449352179034158e-05,
      "loss": 0.1121,
      "step": 10290
    },
    {
      "epoch": 1.1029018096155905,
      "grad_norm": 0.18285351991653442,
      "learning_rate": 4.448816789806189e-05,
      "loss": 0.1123,
      "step": 10300
    },
    {
      "epoch": 1.103972588071528,
      "grad_norm": 0.18248263001441956,
      "learning_rate": 4.448281400578221e-05,
      "loss": 0.1093,
      "step": 10310
    },
    {
      "epoch": 1.1050433665274655,
      "grad_norm": 0.1583092212677002,
      "learning_rate": 4.4477460113502516e-05,
      "loss": 0.0994,
      "step": 10320
    },
    {
      "epoch": 1.1061141449834029,
      "grad_norm": 0.20105673372745514,
      "learning_rate": 4.4472106221222834e-05,
      "loss": 0.1097,
      "step": 10330
    },
    {
      "epoch": 1.1071849234393405,
      "grad_norm": 0.13820494711399078,
      "learning_rate": 4.4466752328943146e-05,
      "loss": 0.1114,
      "step": 10340
    },
    {
      "epoch": 1.108255701895278,
      "grad_norm": 0.1886531412601471,
      "learning_rate": 4.446139843666346e-05,
      "loss": 0.1064,
      "step": 10350
    },
    {
      "epoch": 1.1093264803512153,
      "grad_norm": 0.21449404954910278,
      "learning_rate": 4.445604454438377e-05,
      "loss": 0.1299,
      "step": 10360
    },
    {
      "epoch": 1.110397258807153,
      "grad_norm": 0.17693324387073517,
      "learning_rate": 4.445069065210408e-05,
      "loss": 0.1128,
      "step": 10370
    },
    {
      "epoch": 1.1114680372630903,
      "grad_norm": 0.1840045005083084,
      "learning_rate": 4.44453367598244e-05,
      "loss": 0.1202,
      "step": 10380
    },
    {
      "epoch": 1.1125388157190277,
      "grad_norm": 0.12375888973474503,
      "learning_rate": 4.44399828675447e-05,
      "loss": 0.0972,
      "step": 10390
    },
    {
      "epoch": 1.1136095941749653,
      "grad_norm": 0.12360503524541855,
      "learning_rate": 4.443462897526502e-05,
      "loss": 0.1161,
      "step": 10400
    },
    {
      "epoch": 1.1146803726309027,
      "grad_norm": 0.200940802693367,
      "learning_rate": 4.442927508298533e-05,
      "loss": 0.1042,
      "step": 10410
    },
    {
      "epoch": 1.11575115108684,
      "grad_norm": 0.17994163930416107,
      "learning_rate": 4.442392119070565e-05,
      "loss": 0.1135,
      "step": 10420
    },
    {
      "epoch": 1.1168219295427777,
      "grad_norm": 0.12945838272571564,
      "learning_rate": 4.4418567298425955e-05,
      "loss": 0.1217,
      "step": 10430
    },
    {
      "epoch": 1.117892707998715,
      "grad_norm": 0.2601165175437927,
      "learning_rate": 4.441321340614627e-05,
      "loss": 0.1249,
      "step": 10440
    },
    {
      "epoch": 1.1189634864546525,
      "grad_norm": 0.2013959288597107,
      "learning_rate": 4.4407859513866585e-05,
      "loss": 0.1097,
      "step": 10450
    },
    {
      "epoch": 1.1200342649105899,
      "grad_norm": 0.17359954118728638,
      "learning_rate": 4.4402505621586896e-05,
      "loss": 0.1002,
      "step": 10460
    },
    {
      "epoch": 1.1211050433665275,
      "grad_norm": 0.3064023554325104,
      "learning_rate": 4.439715172930721e-05,
      "loss": 0.1041,
      "step": 10470
    },
    {
      "epoch": 1.122175821822465,
      "grad_norm": 0.14565177261829376,
      "learning_rate": 4.439179783702752e-05,
      "loss": 0.105,
      "step": 10480
    },
    {
      "epoch": 1.1232466002784025,
      "grad_norm": 0.18131335079669952,
      "learning_rate": 4.438644394474784e-05,
      "loss": 0.1039,
      "step": 10490
    },
    {
      "epoch": 1.12431737873434,
      "grad_norm": 0.20044206082820892,
      "learning_rate": 4.438109005246814e-05,
      "loss": 0.1101,
      "step": 10500
    },
    {
      "epoch": 1.1253881571902773,
      "grad_norm": 0.18043088912963867,
      "learning_rate": 4.437573616018846e-05,
      "loss": 0.1096,
      "step": 10510
    },
    {
      "epoch": 1.1264589356462147,
      "grad_norm": 0.14277295768260956,
      "learning_rate": 4.437038226790877e-05,
      "loss": 0.1049,
      "step": 10520
    },
    {
      "epoch": 1.1275297141021523,
      "grad_norm": 0.18038228154182434,
      "learning_rate": 4.436502837562909e-05,
      "loss": 0.1048,
      "step": 10530
    },
    {
      "epoch": 1.1286004925580897,
      "grad_norm": 0.11825624853372574,
      "learning_rate": 4.4359674483349394e-05,
      "loss": 0.0937,
      "step": 10540
    },
    {
      "epoch": 1.1296712710140273,
      "grad_norm": 0.1421666145324707,
      "learning_rate": 4.435432059106971e-05,
      "loss": 0.1121,
      "step": 10550
    },
    {
      "epoch": 1.1307420494699647,
      "grad_norm": 0.17530065774917603,
      "learning_rate": 4.4348966698790024e-05,
      "loss": 0.1075,
      "step": 10560
    },
    {
      "epoch": 1.131812827925902,
      "grad_norm": 0.17043080925941467,
      "learning_rate": 4.4343612806510335e-05,
      "loss": 0.1049,
      "step": 10570
    },
    {
      "epoch": 1.1328836063818395,
      "grad_norm": 0.19295893609523773,
      "learning_rate": 4.4338258914230646e-05,
      "loss": 0.1056,
      "step": 10580
    },
    {
      "epoch": 1.133954384837777,
      "grad_norm": 0.18809360265731812,
      "learning_rate": 4.433290502195096e-05,
      "loss": 0.1093,
      "step": 10590
    },
    {
      "epoch": 1.1350251632937145,
      "grad_norm": 0.15094035863876343,
      "learning_rate": 4.4327551129671276e-05,
      "loss": 0.1114,
      "step": 10600
    },
    {
      "epoch": 1.1360959417496521,
      "grad_norm": 0.18473221361637115,
      "learning_rate": 4.432219723739159e-05,
      "loss": 0.1053,
      "step": 10610
    },
    {
      "epoch": 1.1371667202055895,
      "grad_norm": 0.18885548412799835,
      "learning_rate": 4.43168433451119e-05,
      "loss": 0.1162,
      "step": 10620
    },
    {
      "epoch": 1.138237498661527,
      "grad_norm": 0.19753962755203247,
      "learning_rate": 4.431148945283221e-05,
      "loss": 0.1086,
      "step": 10630
    },
    {
      "epoch": 1.1393082771174643,
      "grad_norm": 0.19004154205322266,
      "learning_rate": 4.430613556055253e-05,
      "loss": 0.1132,
      "step": 10640
    },
    {
      "epoch": 1.140379055573402,
      "grad_norm": 0.20768283307552338,
      "learning_rate": 4.430078166827283e-05,
      "loss": 0.1065,
      "step": 10650
    },
    {
      "epoch": 1.1414498340293393,
      "grad_norm": 0.14460204541683197,
      "learning_rate": 4.429542777599315e-05,
      "loss": 0.1009,
      "step": 10660
    },
    {
      "epoch": 1.142520612485277,
      "grad_norm": 0.15078777074813843,
      "learning_rate": 4.429007388371346e-05,
      "loss": 0.1072,
      "step": 10670
    },
    {
      "epoch": 1.1435913909412143,
      "grad_norm": 0.2359822690486908,
      "learning_rate": 4.4284719991433774e-05,
      "loss": 0.0984,
      "step": 10680
    },
    {
      "epoch": 1.1446621693971517,
      "grad_norm": 0.15712310373783112,
      "learning_rate": 4.4279366099154085e-05,
      "loss": 0.1243,
      "step": 10690
    },
    {
      "epoch": 1.145732947853089,
      "grad_norm": 0.14743943512439728,
      "learning_rate": 4.42740122068744e-05,
      "loss": 0.1057,
      "step": 10700
    },
    {
      "epoch": 1.1468037263090267,
      "grad_norm": 0.24924448132514954,
      "learning_rate": 4.4268658314594715e-05,
      "loss": 0.1095,
      "step": 10710
    },
    {
      "epoch": 1.147874504764964,
      "grad_norm": 0.17311133444309235,
      "learning_rate": 4.4263304422315026e-05,
      "loss": 0.1087,
      "step": 10720
    },
    {
      "epoch": 1.1489452832209015,
      "grad_norm": 0.15073874592781067,
      "learning_rate": 4.425795053003534e-05,
      "loss": 0.1121,
      "step": 10730
    },
    {
      "epoch": 1.1500160616768391,
      "grad_norm": 0.16274690628051758,
      "learning_rate": 4.425259663775565e-05,
      "loss": 0.1088,
      "step": 10740
    },
    {
      "epoch": 1.1510868401327765,
      "grad_norm": 0.2289530336856842,
      "learning_rate": 4.424724274547597e-05,
      "loss": 0.1128,
      "step": 10750
    },
    {
      "epoch": 1.152157618588714,
      "grad_norm": 0.13927578926086426,
      "learning_rate": 4.424188885319628e-05,
      "loss": 0.1117,
      "step": 10760
    },
    {
      "epoch": 1.1532283970446515,
      "grad_norm": 0.10309144109487534,
      "learning_rate": 4.423653496091659e-05,
      "loss": 0.0996,
      "step": 10770
    },
    {
      "epoch": 1.154299175500589,
      "grad_norm": 0.16956748068332672,
      "learning_rate": 4.42311810686369e-05,
      "loss": 0.0993,
      "step": 10780
    },
    {
      "epoch": 1.1553699539565263,
      "grad_norm": 0.10474642366170883,
      "learning_rate": 4.422582717635721e-05,
      "loss": 0.1072,
      "step": 10790
    },
    {
      "epoch": 1.156440732412464,
      "grad_norm": 0.17044615745544434,
      "learning_rate": 4.4220473284077524e-05,
      "loss": 0.1167,
      "step": 10800
    },
    {
      "epoch": 1.1575115108684013,
      "grad_norm": 0.1875244826078415,
      "learning_rate": 4.4215119391797836e-05,
      "loss": 0.1193,
      "step": 10810
    },
    {
      "epoch": 1.1585822893243387,
      "grad_norm": 0.16266360878944397,
      "learning_rate": 4.4209765499518154e-05,
      "loss": 0.0974,
      "step": 10820
    },
    {
      "epoch": 1.1596530677802763,
      "grad_norm": 0.1116933673620224,
      "learning_rate": 4.4204411607238465e-05,
      "loss": 0.1091,
      "step": 10830
    },
    {
      "epoch": 1.1607238462362137,
      "grad_norm": 0.12627482414245605,
      "learning_rate": 4.419905771495878e-05,
      "loss": 0.1258,
      "step": 10840
    },
    {
      "epoch": 1.1617946246921511,
      "grad_norm": 0.142207533121109,
      "learning_rate": 4.419370382267909e-05,
      "loss": 0.1098,
      "step": 10850
    },
    {
      "epoch": 1.1628654031480887,
      "grad_norm": 0.25667211413383484,
      "learning_rate": 4.4188349930399406e-05,
      "loss": 0.1129,
      "step": 10860
    },
    {
      "epoch": 1.1639361816040261,
      "grad_norm": 0.18012069165706635,
      "learning_rate": 4.418299603811972e-05,
      "loss": 0.1114,
      "step": 10870
    },
    {
      "epoch": 1.1650069600599635,
      "grad_norm": 0.21362939476966858,
      "learning_rate": 4.417764214584003e-05,
      "loss": 0.1138,
      "step": 10880
    },
    {
      "epoch": 1.1660777385159011,
      "grad_norm": 0.10358770936727524,
      "learning_rate": 4.417228825356034e-05,
      "loss": 0.1089,
      "step": 10890
    },
    {
      "epoch": 1.1671485169718385,
      "grad_norm": 0.16757625341415405,
      "learning_rate": 4.416693436128065e-05,
      "loss": 0.1026,
      "step": 10900
    },
    {
      "epoch": 1.168219295427776,
      "grad_norm": 0.15520194172859192,
      "learning_rate": 4.416158046900097e-05,
      "loss": 0.1063,
      "step": 10910
    },
    {
      "epoch": 1.1692900738837135,
      "grad_norm": 0.13907861709594727,
      "learning_rate": 4.4156226576721275e-05,
      "loss": 0.109,
      "step": 10920
    },
    {
      "epoch": 1.170360852339651,
      "grad_norm": 0.31028497219085693,
      "learning_rate": 4.415087268444159e-05,
      "loss": 0.122,
      "step": 10930
    },
    {
      "epoch": 1.1714316307955883,
      "grad_norm": 0.11326499283313751,
      "learning_rate": 4.4145518792161904e-05,
      "loss": 0.1104,
      "step": 10940
    },
    {
      "epoch": 1.172502409251526,
      "grad_norm": 0.2202603667974472,
      "learning_rate": 4.414016489988222e-05,
      "loss": 0.1015,
      "step": 10950
    },
    {
      "epoch": 1.1735731877074633,
      "grad_norm": 0.15481267869472504,
      "learning_rate": 4.413481100760253e-05,
      "loss": 0.0903,
      "step": 10960
    },
    {
      "epoch": 1.1746439661634007,
      "grad_norm": 0.15079094469547272,
      "learning_rate": 4.4129457115322845e-05,
      "loss": 0.1079,
      "step": 10970
    },
    {
      "epoch": 1.1757147446193383,
      "grad_norm": 0.12748852372169495,
      "learning_rate": 4.412410322304316e-05,
      "loss": 0.1111,
      "step": 10980
    },
    {
      "epoch": 1.1767855230752757,
      "grad_norm": 0.3006821274757385,
      "learning_rate": 4.411874933076347e-05,
      "loss": 0.13,
      "step": 10990
    },
    {
      "epoch": 1.1778563015312131,
      "grad_norm": 0.15924671292304993,
      "learning_rate": 4.411339543848378e-05,
      "loss": 0.1026,
      "step": 11000
    },
    {
      "epoch": 1.1789270799871507,
      "grad_norm": 0.17414337396621704,
      "learning_rate": 4.410804154620409e-05,
      "loss": 0.1023,
      "step": 11010
    },
    {
      "epoch": 1.1799978584430881,
      "grad_norm": 0.33164170384407043,
      "learning_rate": 4.410268765392441e-05,
      "loss": 0.1202,
      "step": 11020
    },
    {
      "epoch": 1.1810686368990255,
      "grad_norm": 0.16212789714336395,
      "learning_rate": 4.4097333761644714e-05,
      "loss": 0.1072,
      "step": 11030
    },
    {
      "epoch": 1.1821394153549631,
      "grad_norm": 0.25075745582580566,
      "learning_rate": 4.409197986936503e-05,
      "loss": 0.1001,
      "step": 11040
    },
    {
      "epoch": 1.1832101938109005,
      "grad_norm": 0.19243396818637848,
      "learning_rate": 4.408662597708534e-05,
      "loss": 0.112,
      "step": 11050
    },
    {
      "epoch": 1.184280972266838,
      "grad_norm": 0.12706062197685242,
      "learning_rate": 4.408127208480566e-05,
      "loss": 0.1047,
      "step": 11060
    },
    {
      "epoch": 1.1853517507227755,
      "grad_norm": 0.19868215918540955,
      "learning_rate": 4.4075918192525966e-05,
      "loss": 0.1112,
      "step": 11070
    },
    {
      "epoch": 1.186422529178713,
      "grad_norm": 0.19864264130592346,
      "learning_rate": 4.4070564300246284e-05,
      "loss": 0.1044,
      "step": 11080
    },
    {
      "epoch": 1.1874933076346503,
      "grad_norm": 0.17208124697208405,
      "learning_rate": 4.4065210407966596e-05,
      "loss": 0.1242,
      "step": 11090
    },
    {
      "epoch": 1.188564086090588,
      "grad_norm": 0.104741670191288,
      "learning_rate": 4.405985651568691e-05,
      "loss": 0.0848,
      "step": 11100
    },
    {
      "epoch": 1.1896348645465253,
      "grad_norm": 0.13816317915916443,
      "learning_rate": 4.405450262340722e-05,
      "loss": 0.0951,
      "step": 11110
    },
    {
      "epoch": 1.1907056430024627,
      "grad_norm": 0.1642885059118271,
      "learning_rate": 4.404914873112753e-05,
      "loss": 0.1157,
      "step": 11120
    },
    {
      "epoch": 1.1917764214584003,
      "grad_norm": 0.19676731526851654,
      "learning_rate": 4.404379483884785e-05,
      "loss": 0.0966,
      "step": 11130
    },
    {
      "epoch": 1.1928471999143377,
      "grad_norm": 0.11861677467823029,
      "learning_rate": 4.403844094656815e-05,
      "loss": 0.0957,
      "step": 11140
    },
    {
      "epoch": 1.1939179783702751,
      "grad_norm": 0.24073240160942078,
      "learning_rate": 4.403308705428847e-05,
      "loss": 0.1145,
      "step": 11150
    },
    {
      "epoch": 1.1949887568262128,
      "grad_norm": 0.5226326584815979,
      "learning_rate": 4.402773316200878e-05,
      "loss": 0.1016,
      "step": 11160
    },
    {
      "epoch": 1.1960595352821501,
      "grad_norm": 0.12152698636054993,
      "learning_rate": 4.40223792697291e-05,
      "loss": 0.1012,
      "step": 11170
    },
    {
      "epoch": 1.1971303137380875,
      "grad_norm": 0.1787329465150833,
      "learning_rate": 4.4017025377449405e-05,
      "loss": 0.1078,
      "step": 11180
    },
    {
      "epoch": 1.1982010921940252,
      "grad_norm": 0.13533064723014832,
      "learning_rate": 4.401167148516972e-05,
      "loss": 0.1079,
      "step": 11190
    },
    {
      "epoch": 1.1992718706499625,
      "grad_norm": 0.15463434159755707,
      "learning_rate": 4.4006317592890035e-05,
      "loss": 0.1068,
      "step": 11200
    },
    {
      "epoch": 1.2003426491059,
      "grad_norm": 0.2397112250328064,
      "learning_rate": 4.4000963700610346e-05,
      "loss": 0.1044,
      "step": 11210
    },
    {
      "epoch": 1.2014134275618376,
      "grad_norm": 0.1700507402420044,
      "learning_rate": 4.399560980833066e-05,
      "loss": 0.0973,
      "step": 11220
    },
    {
      "epoch": 1.202484206017775,
      "grad_norm": 0.23878470063209534,
      "learning_rate": 4.399025591605097e-05,
      "loss": 0.0975,
      "step": 11230
    },
    {
      "epoch": 1.2035549844737123,
      "grad_norm": 0.1194695457816124,
      "learning_rate": 4.398490202377129e-05,
      "loss": 0.0997,
      "step": 11240
    },
    {
      "epoch": 1.2046257629296497,
      "grad_norm": 0.10931765288114548,
      "learning_rate": 4.39795481314916e-05,
      "loss": 0.0985,
      "step": 11250
    },
    {
      "epoch": 1.2056965413855874,
      "grad_norm": 0.16753865778446198,
      "learning_rate": 4.397419423921191e-05,
      "loss": 0.101,
      "step": 11260
    },
    {
      "epoch": 1.2067673198415247,
      "grad_norm": 0.2269783616065979,
      "learning_rate": 4.396884034693222e-05,
      "loss": 0.0967,
      "step": 11270
    },
    {
      "epoch": 1.2078380982974624,
      "grad_norm": 0.10682433098554611,
      "learning_rate": 4.396348645465254e-05,
      "loss": 0.1033,
      "step": 11280
    },
    {
      "epoch": 1.2089088767533998,
      "grad_norm": 0.2541590929031372,
      "learning_rate": 4.3958132562372844e-05,
      "loss": 0.1121,
      "step": 11290
    },
    {
      "epoch": 1.2099796552093371,
      "grad_norm": 0.13439467549324036,
      "learning_rate": 4.395277867009316e-05,
      "loss": 0.0971,
      "step": 11300
    },
    {
      "epoch": 1.2110504336652745,
      "grad_norm": 0.21583528816699982,
      "learning_rate": 4.3947424777813473e-05,
      "loss": 0.1177,
      "step": 11310
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 0.12328502535820007,
      "learning_rate": 4.3942070885533785e-05,
      "loss": 0.0938,
      "step": 11320
    },
    {
      "epoch": 1.2131919905771495,
      "grad_norm": 0.2784636914730072,
      "learning_rate": 4.3936716993254096e-05,
      "loss": 0.1212,
      "step": 11330
    },
    {
      "epoch": 1.2142627690330872,
      "grad_norm": 0.21930652856826782,
      "learning_rate": 4.393136310097441e-05,
      "loss": 0.1094,
      "step": 11340
    },
    {
      "epoch": 1.2153335474890246,
      "grad_norm": 0.16647794842720032,
      "learning_rate": 4.3926009208694726e-05,
      "loss": 0.1035,
      "step": 11350
    },
    {
      "epoch": 1.216404325944962,
      "grad_norm": 0.19452673196792603,
      "learning_rate": 4.392065531641504e-05,
      "loss": 0.1,
      "step": 11360
    },
    {
      "epoch": 1.2174751044008993,
      "grad_norm": 0.16818730533123016,
      "learning_rate": 4.391530142413535e-05,
      "loss": 0.1124,
      "step": 11370
    },
    {
      "epoch": 1.218545882856837,
      "grad_norm": 0.13872812688350677,
      "learning_rate": 4.390994753185566e-05,
      "loss": 0.1035,
      "step": 11380
    },
    {
      "epoch": 1.2196166613127744,
      "grad_norm": 0.13531595468521118,
      "learning_rate": 4.390459363957598e-05,
      "loss": 0.1089,
      "step": 11390
    },
    {
      "epoch": 1.220687439768712,
      "grad_norm": 0.17781701683998108,
      "learning_rate": 4.389923974729629e-05,
      "loss": 0.1062,
      "step": 11400
    },
    {
      "epoch": 1.2217582182246494,
      "grad_norm": 0.18445797264575958,
      "learning_rate": 4.38938858550166e-05,
      "loss": 0.1169,
      "step": 11410
    },
    {
      "epoch": 1.2228289966805868,
      "grad_norm": 0.17267100512981415,
      "learning_rate": 4.388853196273691e-05,
      "loss": 0.0979,
      "step": 11420
    },
    {
      "epoch": 1.2238997751365241,
      "grad_norm": 0.13581356406211853,
      "learning_rate": 4.3883178070457224e-05,
      "loss": 0.1109,
      "step": 11430
    },
    {
      "epoch": 1.2249705535924618,
      "grad_norm": 0.09293390065431595,
      "learning_rate": 4.3877824178177535e-05,
      "loss": 0.0934,
      "step": 11440
    },
    {
      "epoch": 1.2260413320483992,
      "grad_norm": 0.1706460565328598,
      "learning_rate": 4.387247028589785e-05,
      "loss": 0.0805,
      "step": 11450
    },
    {
      "epoch": 1.2271121105043368,
      "grad_norm": 0.17434322834014893,
      "learning_rate": 4.3867116393618165e-05,
      "loss": 0.1098,
      "step": 11460
    },
    {
      "epoch": 1.2281828889602742,
      "grad_norm": 0.22178640961647034,
      "learning_rate": 4.3861762501338476e-05,
      "loss": 0.1198,
      "step": 11470
    },
    {
      "epoch": 1.2292536674162116,
      "grad_norm": 0.18508560955524445,
      "learning_rate": 4.385640860905879e-05,
      "loss": 0.1064,
      "step": 11480
    },
    {
      "epoch": 1.230324445872149,
      "grad_norm": 0.16122587025165558,
      "learning_rate": 4.38510547167791e-05,
      "loss": 0.1105,
      "step": 11490
    },
    {
      "epoch": 1.2313952243280866,
      "grad_norm": 0.3082684576511383,
      "learning_rate": 4.384570082449942e-05,
      "loss": 0.1084,
      "step": 11500
    },
    {
      "epoch": 1.232466002784024,
      "grad_norm": 0.1310693323612213,
      "learning_rate": 4.384034693221973e-05,
      "loss": 0.1113,
      "step": 11510
    },
    {
      "epoch": 1.2335367812399614,
      "grad_norm": 0.16031385958194733,
      "learning_rate": 4.383499303994003e-05,
      "loss": 0.1016,
      "step": 11520
    },
    {
      "epoch": 1.234607559695899,
      "grad_norm": 0.32885846495628357,
      "learning_rate": 4.382963914766035e-05,
      "loss": 0.1067,
      "step": 11530
    },
    {
      "epoch": 1.2356783381518364,
      "grad_norm": 0.14900176227092743,
      "learning_rate": 4.382428525538066e-05,
      "loss": 0.1054,
      "step": 11540
    },
    {
      "epoch": 1.2367491166077738,
      "grad_norm": 0.16431325674057007,
      "learning_rate": 4.381893136310098e-05,
      "loss": 0.0894,
      "step": 11550
    },
    {
      "epoch": 1.2378198950637114,
      "grad_norm": 0.16273078322410583,
      "learning_rate": 4.3813577470821286e-05,
      "loss": 0.0964,
      "step": 11560
    },
    {
      "epoch": 1.2388906735196488,
      "grad_norm": 0.3500199019908905,
      "learning_rate": 4.3808223578541604e-05,
      "loss": 0.1111,
      "step": 11570
    },
    {
      "epoch": 1.2399614519755862,
      "grad_norm": 0.1230822503566742,
      "learning_rate": 4.3802869686261915e-05,
      "loss": 0.091,
      "step": 11580
    },
    {
      "epoch": 1.2410322304315238,
      "grad_norm": 0.21858428418636322,
      "learning_rate": 4.3797515793982227e-05,
      "loss": 0.1074,
      "step": 11590
    },
    {
      "epoch": 1.2421030088874612,
      "grad_norm": 0.1525212675333023,
      "learning_rate": 4.379216190170254e-05,
      "loss": 0.1031,
      "step": 11600
    },
    {
      "epoch": 1.2431737873433986,
      "grad_norm": 0.15647101402282715,
      "learning_rate": 4.3786808009422856e-05,
      "loss": 0.0987,
      "step": 11610
    },
    {
      "epoch": 1.2442445657993362,
      "grad_norm": 0.17976433038711548,
      "learning_rate": 4.378145411714317e-05,
      "loss": 0.1009,
      "step": 11620
    },
    {
      "epoch": 1.2453153442552736,
      "grad_norm": 0.15330693125724792,
      "learning_rate": 4.377610022486347e-05,
      "loss": 0.0984,
      "step": 11630
    },
    {
      "epoch": 1.246386122711211,
      "grad_norm": 0.13188540935516357,
      "learning_rate": 4.377074633258379e-05,
      "loss": 0.0991,
      "step": 11640
    },
    {
      "epoch": 1.2474569011671486,
      "grad_norm": 0.17485687136650085,
      "learning_rate": 4.37653924403041e-05,
      "loss": 0.097,
      "step": 11650
    },
    {
      "epoch": 1.248527679623086,
      "grad_norm": 0.24684925377368927,
      "learning_rate": 4.376003854802442e-05,
      "loss": 0.1135,
      "step": 11660
    },
    {
      "epoch": 1.2495984580790234,
      "grad_norm": 0.11653200536966324,
      "learning_rate": 4.3754684655744725e-05,
      "loss": 0.1007,
      "step": 11670
    },
    {
      "epoch": 1.250669236534961,
      "grad_norm": 0.16442464292049408,
      "learning_rate": 4.374933076346504e-05,
      "loss": 0.1048,
      "step": 11680
    },
    {
      "epoch": 1.2517400149908984,
      "grad_norm": 0.23297308385372162,
      "learning_rate": 4.3743976871185354e-05,
      "loss": 0.0899,
      "step": 11690
    },
    {
      "epoch": 1.2528107934468358,
      "grad_norm": 0.1458292156457901,
      "learning_rate": 4.373862297890567e-05,
      "loss": 0.1168,
      "step": 11700
    },
    {
      "epoch": 1.2538815719027734,
      "grad_norm": 0.13798029720783234,
      "learning_rate": 4.373326908662598e-05,
      "loss": 0.1009,
      "step": 11710
    },
    {
      "epoch": 1.2549523503587108,
      "grad_norm": 0.17032691836357117,
      "learning_rate": 4.372791519434629e-05,
      "loss": 0.1135,
      "step": 11720
    },
    {
      "epoch": 1.2560231288146482,
      "grad_norm": 0.32555946707725525,
      "learning_rate": 4.3722561302066606e-05,
      "loss": 0.0949,
      "step": 11730
    },
    {
      "epoch": 1.2570939072705858,
      "grad_norm": 0.12944819033145905,
      "learning_rate": 4.371720740978691e-05,
      "loss": 0.1,
      "step": 11740
    },
    {
      "epoch": 1.2581646857265232,
      "grad_norm": 0.16963422298431396,
      "learning_rate": 4.371185351750723e-05,
      "loss": 0.0917,
      "step": 11750
    },
    {
      "epoch": 1.2592354641824606,
      "grad_norm": 0.12823571264743805,
      "learning_rate": 4.370649962522754e-05,
      "loss": 0.1075,
      "step": 11760
    },
    {
      "epoch": 1.2603062426383982,
      "grad_norm": 0.23834142088890076,
      "learning_rate": 4.370114573294786e-05,
      "loss": 0.115,
      "step": 11770
    },
    {
      "epoch": 1.2613770210943356,
      "grad_norm": 0.166746124625206,
      "learning_rate": 4.3695791840668163e-05,
      "loss": 0.1041,
      "step": 11780
    },
    {
      "epoch": 1.262447799550273,
      "grad_norm": 0.21391348540782928,
      "learning_rate": 4.369043794838848e-05,
      "loss": 0.0944,
      "step": 11790
    },
    {
      "epoch": 1.2635185780062106,
      "grad_norm": 0.13725103437900543,
      "learning_rate": 4.368508405610879e-05,
      "loss": 0.1103,
      "step": 11800
    },
    {
      "epoch": 1.264589356462148,
      "grad_norm": 0.10277613252401352,
      "learning_rate": 4.367973016382911e-05,
      "loss": 0.104,
      "step": 11810
    },
    {
      "epoch": 1.2656601349180854,
      "grad_norm": 0.20818999409675598,
      "learning_rate": 4.3674376271549416e-05,
      "loss": 0.1128,
      "step": 11820
    },
    {
      "epoch": 1.266730913374023,
      "grad_norm": 0.13625991344451904,
      "learning_rate": 4.366902237926973e-05,
      "loss": 0.1203,
      "step": 11830
    },
    {
      "epoch": 1.2678016918299604,
      "grad_norm": 0.08959225565195084,
      "learning_rate": 4.3663668486990045e-05,
      "loss": 0.0885,
      "step": 11840
    },
    {
      "epoch": 1.2688724702858978,
      "grad_norm": 0.16965118050575256,
      "learning_rate": 4.365831459471036e-05,
      "loss": 0.0999,
      "step": 11850
    },
    {
      "epoch": 1.2699432487418354,
      "grad_norm": 0.1345779448747635,
      "learning_rate": 4.365296070243067e-05,
      "loss": 0.1051,
      "step": 11860
    },
    {
      "epoch": 1.2710140271977728,
      "grad_norm": 0.21996182203292847,
      "learning_rate": 4.364760681015098e-05,
      "loss": 0.1154,
      "step": 11870
    },
    {
      "epoch": 1.2720848056537102,
      "grad_norm": 0.1495433747768402,
      "learning_rate": 4.36422529178713e-05,
      "loss": 0.1,
      "step": 11880
    },
    {
      "epoch": 1.2731555841096478,
      "grad_norm": 0.1344318836927414,
      "learning_rate": 4.363689902559161e-05,
      "loss": 0.1025,
      "step": 11890
    },
    {
      "epoch": 1.2742263625655852,
      "grad_norm": 0.17544019222259521,
      "learning_rate": 4.363154513331192e-05,
      "loss": 0.096,
      "step": 11900
    },
    {
      "epoch": 1.2752971410215226,
      "grad_norm": 0.2629387080669403,
      "learning_rate": 4.362619124103223e-05,
      "loss": 0.1127,
      "step": 11910
    },
    {
      "epoch": 1.27636791947746,
      "grad_norm": 0.23764395713806152,
      "learning_rate": 4.3620837348752543e-05,
      "loss": 0.1053,
      "step": 11920
    },
    {
      "epoch": 1.2774386979333976,
      "grad_norm": 0.16644975543022156,
      "learning_rate": 4.3615483456472855e-05,
      "loss": 0.0791,
      "step": 11930
    },
    {
      "epoch": 1.278509476389335,
      "grad_norm": 0.15607717633247375,
      "learning_rate": 4.3610129564193166e-05,
      "loss": 0.0958,
      "step": 11940
    },
    {
      "epoch": 1.2795802548452726,
      "grad_norm": 0.1691720187664032,
      "learning_rate": 4.3604775671913484e-05,
      "loss": 0.104,
      "step": 11950
    },
    {
      "epoch": 1.28065103330121,
      "grad_norm": 0.1411573439836502,
      "learning_rate": 4.3599421779633796e-05,
      "loss": 0.1025,
      "step": 11960
    },
    {
      "epoch": 1.2817218117571474,
      "grad_norm": 0.12534143030643463,
      "learning_rate": 4.359406788735411e-05,
      "loss": 0.0951,
      "step": 11970
    },
    {
      "epoch": 1.2827925902130848,
      "grad_norm": 0.16218428313732147,
      "learning_rate": 4.358871399507442e-05,
      "loss": 0.0976,
      "step": 11980
    },
    {
      "epoch": 1.2838633686690224,
      "grad_norm": 0.10709408670663834,
      "learning_rate": 4.358336010279474e-05,
      "loss": 0.0961,
      "step": 11990
    },
    {
      "epoch": 1.2849341471249598,
      "grad_norm": 0.1266299933195114,
      "learning_rate": 4.357800621051505e-05,
      "loss": 0.1114,
      "step": 12000
    },
    {
      "epoch": 1.2860049255808974,
      "grad_norm": 0.11621174216270447,
      "learning_rate": 4.357265231823536e-05,
      "loss": 0.0961,
      "step": 12010
    },
    {
      "epoch": 1.2870757040368348,
      "grad_norm": 0.14315049350261688,
      "learning_rate": 4.356729842595567e-05,
      "loss": 0.1285,
      "step": 12020
    },
    {
      "epoch": 1.2881464824927722,
      "grad_norm": 0.1798851490020752,
      "learning_rate": 4.356194453367598e-05,
      "loss": 0.11,
      "step": 12030
    },
    {
      "epoch": 1.2892172609487096,
      "grad_norm": 0.23566024005413055,
      "learning_rate": 4.35565906413963e-05,
      "loss": 0.0948,
      "step": 12040
    },
    {
      "epoch": 1.2902880394046472,
      "grad_norm": 0.15016832947731018,
      "learning_rate": 4.3551236749116605e-05,
      "loss": 0.1083,
      "step": 12050
    },
    {
      "epoch": 1.2913588178605846,
      "grad_norm": 0.3068857192993164,
      "learning_rate": 4.354588285683692e-05,
      "loss": 0.1192,
      "step": 12060
    },
    {
      "epoch": 1.2924295963165222,
      "grad_norm": 0.2284049242734909,
      "learning_rate": 4.3540528964557235e-05,
      "loss": 0.1101,
      "step": 12070
    },
    {
      "epoch": 1.2935003747724596,
      "grad_norm": 0.13779957592487335,
      "learning_rate": 4.3535175072277546e-05,
      "loss": 0.1056,
      "step": 12080
    },
    {
      "epoch": 1.294571153228397,
      "grad_norm": 0.16910359263420105,
      "learning_rate": 4.352982117999786e-05,
      "loss": 0.1055,
      "step": 12090
    },
    {
      "epoch": 1.2956419316843344,
      "grad_norm": 0.1360110491514206,
      "learning_rate": 4.3524467287718176e-05,
      "loss": 0.0924,
      "step": 12100
    },
    {
      "epoch": 1.296712710140272,
      "grad_norm": 0.2810034453868866,
      "learning_rate": 4.351911339543849e-05,
      "loss": 0.1059,
      "step": 12110
    },
    {
      "epoch": 1.2977834885962094,
      "grad_norm": 0.13770760595798492,
      "learning_rate": 4.35137595031588e-05,
      "loss": 0.1005,
      "step": 12120
    },
    {
      "epoch": 1.298854267052147,
      "grad_norm": 0.18986913561820984,
      "learning_rate": 4.350840561087911e-05,
      "loss": 0.114,
      "step": 12130
    },
    {
      "epoch": 1.2999250455080844,
      "grad_norm": 0.30619126558303833,
      "learning_rate": 4.350305171859942e-05,
      "loss": 0.1017,
      "step": 12140
    },
    {
      "epoch": 1.3009958239640218,
      "grad_norm": 0.24899403750896454,
      "learning_rate": 4.349769782631974e-05,
      "loss": 0.0946,
      "step": 12150
    },
    {
      "epoch": 1.3020666024199592,
      "grad_norm": 0.11655452102422714,
      "learning_rate": 4.3492343934040044e-05,
      "loss": 0.098,
      "step": 12160
    },
    {
      "epoch": 1.3031373808758968,
      "grad_norm": 0.1669733226299286,
      "learning_rate": 4.348699004176036e-05,
      "loss": 0.1046,
      "step": 12170
    },
    {
      "epoch": 1.3042081593318342,
      "grad_norm": 0.18693065643310547,
      "learning_rate": 4.3481636149480674e-05,
      "loss": 0.099,
      "step": 12180
    },
    {
      "epoch": 1.3052789377877718,
      "grad_norm": 0.20343004167079926,
      "learning_rate": 4.347628225720099e-05,
      "loss": 0.1074,
      "step": 12190
    },
    {
      "epoch": 1.3063497162437092,
      "grad_norm": 0.12528322637081146,
      "learning_rate": 4.3470928364921297e-05,
      "loss": 0.0951,
      "step": 12200
    },
    {
      "epoch": 1.3074204946996466,
      "grad_norm": 0.18172098696231842,
      "learning_rate": 4.3465574472641615e-05,
      "loss": 0.0941,
      "step": 12210
    },
    {
      "epoch": 1.308491273155584,
      "grad_norm": 0.12939980626106262,
      "learning_rate": 4.3460220580361926e-05,
      "loss": 0.0932,
      "step": 12220
    },
    {
      "epoch": 1.3095620516115216,
      "grad_norm": 0.27576056122779846,
      "learning_rate": 4.345486668808224e-05,
      "loss": 0.0853,
      "step": 12230
    },
    {
      "epoch": 1.310632830067459,
      "grad_norm": 0.17127792537212372,
      "learning_rate": 4.344951279580255e-05,
      "loss": 0.107,
      "step": 12240
    },
    {
      "epoch": 1.3117036085233966,
      "grad_norm": 0.20012958347797394,
      "learning_rate": 4.344415890352286e-05,
      "loss": 0.1075,
      "step": 12250
    },
    {
      "epoch": 1.312774386979334,
      "grad_norm": 0.1414276361465454,
      "learning_rate": 4.343880501124318e-05,
      "loss": 0.1033,
      "step": 12260
    },
    {
      "epoch": 1.3138451654352714,
      "grad_norm": 0.24269063770771027,
      "learning_rate": 4.343345111896348e-05,
      "loss": 0.0923,
      "step": 12270
    },
    {
      "epoch": 1.3149159438912088,
      "grad_norm": 0.11936244368553162,
      "learning_rate": 4.34280972266838e-05,
      "loss": 0.0948,
      "step": 12280
    },
    {
      "epoch": 1.3159867223471464,
      "grad_norm": 0.14604641497135162,
      "learning_rate": 4.342274333440411e-05,
      "loss": 0.1002,
      "step": 12290
    },
    {
      "epoch": 1.3170575008030838,
      "grad_norm": 0.16539965569972992,
      "learning_rate": 4.341738944212443e-05,
      "loss": 0.099,
      "step": 12300
    },
    {
      "epoch": 1.3181282792590214,
      "grad_norm": 0.11218088865280151,
      "learning_rate": 4.3412035549844735e-05,
      "loss": 0.0939,
      "step": 12310
    },
    {
      "epoch": 1.3191990577149588,
      "grad_norm": 0.3874460458755493,
      "learning_rate": 4.3406681657565054e-05,
      "loss": 0.0994,
      "step": 12320
    },
    {
      "epoch": 1.3202698361708962,
      "grad_norm": 0.2032517045736313,
      "learning_rate": 4.3401327765285365e-05,
      "loss": 0.1155,
      "step": 12330
    },
    {
      "epoch": 1.3213406146268336,
      "grad_norm": 0.11914698779582977,
      "learning_rate": 4.3395973873005676e-05,
      "loss": 0.1137,
      "step": 12340
    },
    {
      "epoch": 1.3224113930827712,
      "grad_norm": 0.4050449728965759,
      "learning_rate": 4.339061998072599e-05,
      "loss": 0.1027,
      "step": 12350
    },
    {
      "epoch": 1.3234821715387086,
      "grad_norm": 0.1487421989440918,
      "learning_rate": 4.33852660884463e-05,
      "loss": 0.1009,
      "step": 12360
    },
    {
      "epoch": 1.3245529499946462,
      "grad_norm": 0.18547987937927246,
      "learning_rate": 4.337991219616662e-05,
      "loss": 0.0975,
      "step": 12370
    },
    {
      "epoch": 1.3256237284505836,
      "grad_norm": 0.13521993160247803,
      "learning_rate": 4.337455830388692e-05,
      "loss": 0.1006,
      "step": 12380
    },
    {
      "epoch": 1.326694506906521,
      "grad_norm": 0.2192450910806656,
      "learning_rate": 4.336920441160724e-05,
      "loss": 0.1036,
      "step": 12390
    },
    {
      "epoch": 1.3277652853624584,
      "grad_norm": 0.18328875303268433,
      "learning_rate": 4.336385051932755e-05,
      "loss": 0.0841,
      "step": 12400
    },
    {
      "epoch": 1.328836063818396,
      "grad_norm": 0.1267957091331482,
      "learning_rate": 4.335849662704787e-05,
      "loss": 0.0966,
      "step": 12410
    },
    {
      "epoch": 1.3299068422743334,
      "grad_norm": 0.17944081127643585,
      "learning_rate": 4.3353142734768174e-05,
      "loss": 0.0819,
      "step": 12420
    },
    {
      "epoch": 1.330977620730271,
      "grad_norm": 0.2005673348903656,
      "learning_rate": 4.334778884248849e-05,
      "loss": 0.1185,
      "step": 12430
    },
    {
      "epoch": 1.3320483991862084,
      "grad_norm": 0.18211396038532257,
      "learning_rate": 4.3342434950208804e-05,
      "loss": 0.1095,
      "step": 12440
    },
    {
      "epoch": 1.3331191776421458,
      "grad_norm": 0.17592473328113556,
      "learning_rate": 4.3337081057929115e-05,
      "loss": 0.0908,
      "step": 12450
    },
    {
      "epoch": 1.3341899560980832,
      "grad_norm": 0.14461323618888855,
      "learning_rate": 4.333172716564943e-05,
      "loss": 0.0946,
      "step": 12460
    },
    {
      "epoch": 1.3352607345540208,
      "grad_norm": 0.19956006109714508,
      "learning_rate": 4.332637327336974e-05,
      "loss": 0.0942,
      "step": 12470
    },
    {
      "epoch": 1.3363315130099582,
      "grad_norm": 0.11242514848709106,
      "learning_rate": 4.3321019381090056e-05,
      "loss": 0.0831,
      "step": 12480
    },
    {
      "epoch": 1.3374022914658958,
      "grad_norm": 0.18191035091876984,
      "learning_rate": 4.331566548881037e-05,
      "loss": 0.113,
      "step": 12490
    },
    {
      "epoch": 1.3384730699218332,
      "grad_norm": 0.15019507706165314,
      "learning_rate": 4.331031159653068e-05,
      "loss": 0.0892,
      "step": 12500
    },
    {
      "epoch": 1.3395438483777706,
      "grad_norm": 0.14137688279151917,
      "learning_rate": 4.330495770425099e-05,
      "loss": 0.1057,
      "step": 12510
    },
    {
      "epoch": 1.340614626833708,
      "grad_norm": 0.16188645362854004,
      "learning_rate": 4.329960381197131e-05,
      "loss": 0.1068,
      "step": 12520
    },
    {
      "epoch": 1.3416854052896456,
      "grad_norm": 0.16331002116203308,
      "learning_rate": 4.329424991969161e-05,
      "loss": 0.0958,
      "step": 12530
    },
    {
      "epoch": 1.342756183745583,
      "grad_norm": 0.17203284800052643,
      "learning_rate": 4.328889602741193e-05,
      "loss": 0.0916,
      "step": 12540
    },
    {
      "epoch": 1.3438269622015204,
      "grad_norm": 0.14580094814300537,
      "learning_rate": 4.328354213513224e-05,
      "loss": 0.1029,
      "step": 12550
    },
    {
      "epoch": 1.344897740657458,
      "grad_norm": 0.1192331612110138,
      "learning_rate": 4.3278188242852554e-05,
      "loss": 0.0992,
      "step": 12560
    },
    {
      "epoch": 1.3459685191133954,
      "grad_norm": 0.10831510275602341,
      "learning_rate": 4.3272834350572866e-05,
      "loss": 0.1179,
      "step": 12570
    },
    {
      "epoch": 1.3470392975693328,
      "grad_norm": 0.16306240856647491,
      "learning_rate": 4.326748045829318e-05,
      "loss": 0.0971,
      "step": 12580
    },
    {
      "epoch": 1.3481100760252704,
      "grad_norm": 0.18779204785823822,
      "learning_rate": 4.3262126566013495e-05,
      "loss": 0.1071,
      "step": 12590
    },
    {
      "epoch": 1.3491808544812078,
      "grad_norm": 0.15244783461093903,
      "learning_rate": 4.325677267373381e-05,
      "loss": 0.1079,
      "step": 12600
    },
    {
      "epoch": 1.3502516329371452,
      "grad_norm": 0.2752625048160553,
      "learning_rate": 4.325141878145412e-05,
      "loss": 0.1004,
      "step": 12610
    },
    {
      "epoch": 1.3513224113930828,
      "grad_norm": 0.22294560074806213,
      "learning_rate": 4.324606488917443e-05,
      "loss": 0.1012,
      "step": 12620
    },
    {
      "epoch": 1.3523931898490202,
      "grad_norm": 0.1295473873615265,
      "learning_rate": 4.324071099689475e-05,
      "loss": 0.1187,
      "step": 12630
    },
    {
      "epoch": 1.3534639683049576,
      "grad_norm": 1.0808287858963013,
      "learning_rate": 4.323535710461506e-05,
      "loss": 0.0986,
      "step": 12640
    },
    {
      "epoch": 1.3545347467608952,
      "grad_norm": 0.1728122979402542,
      "learning_rate": 4.323000321233537e-05,
      "loss": 0.0968,
      "step": 12650
    },
    {
      "epoch": 1.3556055252168326,
      "grad_norm": 0.19639548659324646,
      "learning_rate": 4.322464932005568e-05,
      "loss": 0.0973,
      "step": 12660
    },
    {
      "epoch": 1.35667630367277,
      "grad_norm": 0.17569178342819214,
      "learning_rate": 4.321929542777599e-05,
      "loss": 0.124,
      "step": 12670
    },
    {
      "epoch": 1.3577470821287076,
      "grad_norm": 0.14960791170597076,
      "learning_rate": 4.321394153549631e-05,
      "loss": 0.1027,
      "step": 12680
    },
    {
      "epoch": 1.358817860584645,
      "grad_norm": 0.1746644675731659,
      "learning_rate": 4.3208587643216616e-05,
      "loss": 0.0896,
      "step": 12690
    },
    {
      "epoch": 1.3598886390405824,
      "grad_norm": 0.18101754784584045,
      "learning_rate": 4.3203233750936934e-05,
      "loss": 0.1135,
      "step": 12700
    },
    {
      "epoch": 1.36095941749652,
      "grad_norm": 0.1526067554950714,
      "learning_rate": 4.3197879858657246e-05,
      "loss": 0.079,
      "step": 12710
    },
    {
      "epoch": 1.3620301959524574,
      "grad_norm": 0.258169949054718,
      "learning_rate": 4.319252596637756e-05,
      "loss": 0.0975,
      "step": 12720
    },
    {
      "epoch": 1.3631009744083948,
      "grad_norm": 0.12391898036003113,
      "learning_rate": 4.318717207409787e-05,
      "loss": 0.1084,
      "step": 12730
    },
    {
      "epoch": 1.3641717528643325,
      "grad_norm": 0.1985354870557785,
      "learning_rate": 4.318181818181819e-05,
      "loss": 0.1033,
      "step": 12740
    },
    {
      "epoch": 1.3652425313202698,
      "grad_norm": 0.17744633555412292,
      "learning_rate": 4.31764642895385e-05,
      "loss": 0.1139,
      "step": 12750
    },
    {
      "epoch": 1.3663133097762072,
      "grad_norm": 0.2544134259223938,
      "learning_rate": 4.317111039725881e-05,
      "loss": 0.0902,
      "step": 12760
    },
    {
      "epoch": 1.3673840882321446,
      "grad_norm": 0.183297798037529,
      "learning_rate": 4.316575650497912e-05,
      "loss": 0.1095,
      "step": 12770
    },
    {
      "epoch": 1.3684548666880822,
      "grad_norm": 0.14072971045970917,
      "learning_rate": 4.316040261269943e-05,
      "loss": 0.0915,
      "step": 12780
    },
    {
      "epoch": 1.3695256451440196,
      "grad_norm": 0.14014795422554016,
      "learning_rate": 4.315504872041975e-05,
      "loss": 0.0999,
      "step": 12790
    },
    {
      "epoch": 1.3705964235999573,
      "grad_norm": 0.1388004869222641,
      "learning_rate": 4.3149694828140055e-05,
      "loss": 0.1029,
      "step": 12800
    },
    {
      "epoch": 1.3716672020558947,
      "grad_norm": 0.14387772977352142,
      "learning_rate": 4.314434093586037e-05,
      "loss": 0.1141,
      "step": 12810
    },
    {
      "epoch": 1.372737980511832,
      "grad_norm": 0.20979724824428558,
      "learning_rate": 4.3138987043580685e-05,
      "loss": 0.1117,
      "step": 12820
    },
    {
      "epoch": 1.3738087589677694,
      "grad_norm": 0.2056279182434082,
      "learning_rate": 4.3133633151301e-05,
      "loss": 0.1036,
      "step": 12830
    },
    {
      "epoch": 1.374879537423707,
      "grad_norm": 0.16782152652740479,
      "learning_rate": 4.312827925902131e-05,
      "loss": 0.1029,
      "step": 12840
    },
    {
      "epoch": 1.3759503158796444,
      "grad_norm": 0.17382459342479706,
      "learning_rate": 4.3122925366741626e-05,
      "loss": 0.1007,
      "step": 12850
    },
    {
      "epoch": 1.377021094335582,
      "grad_norm": 0.13976530730724335,
      "learning_rate": 4.311757147446194e-05,
      "loss": 0.1149,
      "step": 12860
    },
    {
      "epoch": 1.3780918727915195,
      "grad_norm": 0.13708806037902832,
      "learning_rate": 4.311221758218225e-05,
      "loss": 0.1039,
      "step": 12870
    },
    {
      "epoch": 1.3791626512474569,
      "grad_norm": 0.35960546135902405,
      "learning_rate": 4.310686368990256e-05,
      "loss": 0.1141,
      "step": 12880
    },
    {
      "epoch": 1.3802334297033942,
      "grad_norm": 0.16749300062656403,
      "learning_rate": 4.310150979762287e-05,
      "loss": 0.0986,
      "step": 12890
    },
    {
      "epoch": 1.3813042081593319,
      "grad_norm": 0.12748606503009796,
      "learning_rate": 4.309615590534319e-05,
      "loss": 0.0958,
      "step": 12900
    },
    {
      "epoch": 1.3823749866152693,
      "grad_norm": 0.2251707911491394,
      "learning_rate": 4.3090802013063494e-05,
      "loss": 0.0964,
      "step": 12910
    },
    {
      "epoch": 1.3834457650712069,
      "grad_norm": 0.24505311250686646,
      "learning_rate": 4.308544812078381e-05,
      "loss": 0.0979,
      "step": 12920
    },
    {
      "epoch": 1.3845165435271443,
      "grad_norm": 0.11796656996011734,
      "learning_rate": 4.3080094228504124e-05,
      "loss": 0.0999,
      "step": 12930
    },
    {
      "epoch": 1.3855873219830817,
      "grad_norm": 0.2346426099538803,
      "learning_rate": 4.307474033622444e-05,
      "loss": 0.1045,
      "step": 12940
    },
    {
      "epoch": 1.386658100439019,
      "grad_norm": 0.17907118797302246,
      "learning_rate": 4.3069386443944746e-05,
      "loss": 0.1168,
      "step": 12950
    },
    {
      "epoch": 1.3877288788949567,
      "grad_norm": 0.1545642614364624,
      "learning_rate": 4.3064032551665065e-05,
      "loss": 0.1042,
      "step": 12960
    },
    {
      "epoch": 1.388799657350894,
      "grad_norm": 0.21247369050979614,
      "learning_rate": 4.3058678659385376e-05,
      "loss": 0.1106,
      "step": 12970
    },
    {
      "epoch": 1.3898704358068317,
      "grad_norm": 0.2762584090232849,
      "learning_rate": 4.305332476710569e-05,
      "loss": 0.115,
      "step": 12980
    },
    {
      "epoch": 1.390941214262769,
      "grad_norm": 0.15454089641571045,
      "learning_rate": 4.3047970874826e-05,
      "loss": 0.101,
      "step": 12990
    },
    {
      "epoch": 1.3920119927187065,
      "grad_norm": 0.17719978094100952,
      "learning_rate": 4.304261698254631e-05,
      "loss": 0.1087,
      "step": 13000
    },
    {
      "epoch": 1.3930827711746439,
      "grad_norm": 0.1898590326309204,
      "learning_rate": 4.303726309026663e-05,
      "loss": 0.1012,
      "step": 13010
    },
    {
      "epoch": 1.3941535496305815,
      "grad_norm": 0.140007883310318,
      "learning_rate": 4.303190919798693e-05,
      "loss": 0.099,
      "step": 13020
    },
    {
      "epoch": 1.3952243280865189,
      "grad_norm": 0.2528948485851288,
      "learning_rate": 4.302655530570725e-05,
      "loss": 0.0886,
      "step": 13030
    },
    {
      "epoch": 1.3962951065424565,
      "grad_norm": 0.1547541320323944,
      "learning_rate": 4.302120141342756e-05,
      "loss": 0.1056,
      "step": 13040
    },
    {
      "epoch": 1.3973658849983939,
      "grad_norm": 0.2083079218864441,
      "learning_rate": 4.301584752114788e-05,
      "loss": 0.1005,
      "step": 13050
    },
    {
      "epoch": 1.3984366634543313,
      "grad_norm": 0.1214451715350151,
      "learning_rate": 4.3010493628868185e-05,
      "loss": 0.0988,
      "step": 13060
    },
    {
      "epoch": 1.3995074419102687,
      "grad_norm": 0.18690906465053558,
      "learning_rate": 4.3005139736588504e-05,
      "loss": 0.0911,
      "step": 13070
    },
    {
      "epoch": 1.4005782203662063,
      "grad_norm": 0.23246419429779053,
      "learning_rate": 4.2999785844308815e-05,
      "loss": 0.0881,
      "step": 13080
    },
    {
      "epoch": 1.4016489988221437,
      "grad_norm": 0.17462481558322906,
      "learning_rate": 4.2994431952029126e-05,
      "loss": 0.1099,
      "step": 13090
    },
    {
      "epoch": 1.4027197772780813,
      "grad_norm": 0.1607215702533722,
      "learning_rate": 4.298907805974944e-05,
      "loss": 0.1043,
      "step": 13100
    },
    {
      "epoch": 1.4037905557340187,
      "grad_norm": 0.177735835313797,
      "learning_rate": 4.298372416746975e-05,
      "loss": 0.0989,
      "step": 13110
    },
    {
      "epoch": 1.404861334189956,
      "grad_norm": 0.14948682487010956,
      "learning_rate": 4.297837027519007e-05,
      "loss": 0.0935,
      "step": 13120
    },
    {
      "epoch": 1.4059321126458935,
      "grad_norm": 0.191023051738739,
      "learning_rate": 4.297301638291038e-05,
      "loss": 0.1047,
      "step": 13130
    },
    {
      "epoch": 1.407002891101831,
      "grad_norm": 0.1541929692029953,
      "learning_rate": 4.296766249063069e-05,
      "loss": 0.0988,
      "step": 13140
    },
    {
      "epoch": 1.4080736695577685,
      "grad_norm": 0.20123356580734253,
      "learning_rate": 4.2962308598351e-05,
      "loss": 0.1078,
      "step": 13150
    },
    {
      "epoch": 1.409144448013706,
      "grad_norm": 0.22009976208209991,
      "learning_rate": 4.295695470607132e-05,
      "loss": 0.098,
      "step": 13160
    },
    {
      "epoch": 1.4102152264696435,
      "grad_norm": 0.1536937803030014,
      "learning_rate": 4.2951600813791624e-05,
      "loss": 0.0847,
      "step": 13170
    },
    {
      "epoch": 1.4112860049255809,
      "grad_norm": 0.23048537969589233,
      "learning_rate": 4.294624692151194e-05,
      "loss": 0.098,
      "step": 13180
    },
    {
      "epoch": 1.4123567833815183,
      "grad_norm": 0.19268541038036346,
      "learning_rate": 4.2940893029232254e-05,
      "loss": 0.099,
      "step": 13190
    },
    {
      "epoch": 1.4134275618374559,
      "grad_norm": 0.14214454591274261,
      "learning_rate": 4.2935539136952565e-05,
      "loss": 0.0897,
      "step": 13200
    },
    {
      "epoch": 1.4144983402933933,
      "grad_norm": 0.17017138004302979,
      "learning_rate": 4.293018524467288e-05,
      "loss": 0.1086,
      "step": 13210
    },
    {
      "epoch": 1.415569118749331,
      "grad_norm": 0.17726044356822968,
      "learning_rate": 4.292483135239319e-05,
      "loss": 0.1079,
      "step": 13220
    },
    {
      "epoch": 1.4166398972052683,
      "grad_norm": 0.5383259057998657,
      "learning_rate": 4.2919477460113506e-05,
      "loss": 0.0987,
      "step": 13230
    },
    {
      "epoch": 1.4177106756612057,
      "grad_norm": 0.11401759088039398,
      "learning_rate": 4.291412356783382e-05,
      "loss": 0.0916,
      "step": 13240
    },
    {
      "epoch": 1.418781454117143,
      "grad_norm": 0.17294760048389435,
      "learning_rate": 4.290876967555413e-05,
      "loss": 0.0904,
      "step": 13250
    },
    {
      "epoch": 1.4198522325730807,
      "grad_norm": 0.16929282248020172,
      "learning_rate": 4.290341578327444e-05,
      "loss": 0.099,
      "step": 13260
    },
    {
      "epoch": 1.420923011029018,
      "grad_norm": 0.2497400939464569,
      "learning_rate": 4.289806189099476e-05,
      "loss": 0.1013,
      "step": 13270
    },
    {
      "epoch": 1.4219937894849557,
      "grad_norm": 0.16163669526576996,
      "learning_rate": 4.289270799871507e-05,
      "loss": 0.1029,
      "step": 13280
    },
    {
      "epoch": 1.423064567940893,
      "grad_norm": 0.20567944645881653,
      "learning_rate": 4.288735410643538e-05,
      "loss": 0.108,
      "step": 13290
    },
    {
      "epoch": 1.4241353463968305,
      "grad_norm": 0.29167336225509644,
      "learning_rate": 4.288200021415569e-05,
      "loss": 0.0904,
      "step": 13300
    },
    {
      "epoch": 1.4252061248527679,
      "grad_norm": 0.1047256588935852,
      "learning_rate": 4.2876646321876004e-05,
      "loss": 0.1142,
      "step": 13310
    },
    {
      "epoch": 1.4262769033087055,
      "grad_norm": 0.1753438115119934,
      "learning_rate": 4.2871292429596316e-05,
      "loss": 0.0937,
      "step": 13320
    },
    {
      "epoch": 1.4273476817646429,
      "grad_norm": 0.13115358352661133,
      "learning_rate": 4.286593853731663e-05,
      "loss": 0.1009,
      "step": 13330
    },
    {
      "epoch": 1.4284184602205805,
      "grad_norm": 0.15223950147628784,
      "learning_rate": 4.2860584645036945e-05,
      "loss": 0.0962,
      "step": 13340
    },
    {
      "epoch": 1.429489238676518,
      "grad_norm": 0.1942594051361084,
      "learning_rate": 4.2855230752757257e-05,
      "loss": 0.0924,
      "step": 13350
    },
    {
      "epoch": 1.4305600171324553,
      "grad_norm": 0.14982227981090546,
      "learning_rate": 4.284987686047757e-05,
      "loss": 0.1201,
      "step": 13360
    },
    {
      "epoch": 1.4316307955883927,
      "grad_norm": 0.18884330987930298,
      "learning_rate": 4.284452296819788e-05,
      "loss": 0.0957,
      "step": 13370
    },
    {
      "epoch": 1.4327015740443303,
      "grad_norm": 0.1690128743648529,
      "learning_rate": 4.28391690759182e-05,
      "loss": 0.0923,
      "step": 13380
    },
    {
      "epoch": 1.4337723525002677,
      "grad_norm": 0.13149362802505493,
      "learning_rate": 4.283381518363851e-05,
      "loss": 0.0886,
      "step": 13390
    },
    {
      "epoch": 1.434843130956205,
      "grad_norm": 0.1381976306438446,
      "learning_rate": 4.282846129135882e-05,
      "loss": 0.0992,
      "step": 13400
    },
    {
      "epoch": 1.4359139094121427,
      "grad_norm": 0.15161952376365662,
      "learning_rate": 4.282310739907913e-05,
      "loss": 0.1009,
      "step": 13410
    },
    {
      "epoch": 1.43698468786808,
      "grad_norm": 0.11264094710350037,
      "learning_rate": 4.281775350679944e-05,
      "loss": 0.0978,
      "step": 13420
    },
    {
      "epoch": 1.4380554663240175,
      "grad_norm": 0.16311167180538177,
      "learning_rate": 4.281239961451976e-05,
      "loss": 0.0911,
      "step": 13430
    },
    {
      "epoch": 1.439126244779955,
      "grad_norm": 0.23718687891960144,
      "learning_rate": 4.2807045722240066e-05,
      "loss": 0.1081,
      "step": 13440
    },
    {
      "epoch": 1.4401970232358925,
      "grad_norm": 0.15338921546936035,
      "learning_rate": 4.2801691829960384e-05,
      "loss": 0.1076,
      "step": 13450
    },
    {
      "epoch": 1.4412678016918299,
      "grad_norm": 0.2060348391532898,
      "learning_rate": 4.2796337937680696e-05,
      "loss": 0.1129,
      "step": 13460
    },
    {
      "epoch": 1.4423385801477675,
      "grad_norm": 0.1634412407875061,
      "learning_rate": 4.2790984045401014e-05,
      "loss": 0.0981,
      "step": 13470
    },
    {
      "epoch": 1.443409358603705,
      "grad_norm": 0.1522158980369568,
      "learning_rate": 4.278563015312132e-05,
      "loss": 0.0853,
      "step": 13480
    },
    {
      "epoch": 1.4444801370596423,
      "grad_norm": 0.15789639949798584,
      "learning_rate": 4.2780276260841637e-05,
      "loss": 0.0907,
      "step": 13490
    },
    {
      "epoch": 1.44555091551558,
      "grad_norm": 0.11956152319908142,
      "learning_rate": 4.277492236856195e-05,
      "loss": 0.1001,
      "step": 13500
    },
    {
      "epoch": 1.4466216939715173,
      "grad_norm": 0.1501285284757614,
      "learning_rate": 4.276956847628226e-05,
      "loss": 0.1109,
      "step": 13510
    },
    {
      "epoch": 1.4476924724274547,
      "grad_norm": 0.09473174810409546,
      "learning_rate": 4.276421458400257e-05,
      "loss": 0.0914,
      "step": 13520
    },
    {
      "epoch": 1.4487632508833923,
      "grad_norm": 0.150363489985466,
      "learning_rate": 4.275886069172288e-05,
      "loss": 0.0875,
      "step": 13530
    },
    {
      "epoch": 1.4498340293393297,
      "grad_norm": 0.24838106334209442,
      "learning_rate": 4.27535067994432e-05,
      "loss": 0.1092,
      "step": 13540
    },
    {
      "epoch": 1.450904807795267,
      "grad_norm": 0.13295437395572662,
      "learning_rate": 4.2748152907163505e-05,
      "loss": 0.0895,
      "step": 13550
    },
    {
      "epoch": 1.4519755862512047,
      "grad_norm": 0.12198687344789505,
      "learning_rate": 4.274279901488382e-05,
      "loss": 0.1,
      "step": 13560
    },
    {
      "epoch": 1.453046364707142,
      "grad_norm": 0.15897364914417267,
      "learning_rate": 4.2737445122604135e-05,
      "loss": 0.1186,
      "step": 13570
    },
    {
      "epoch": 1.4541171431630795,
      "grad_norm": 0.15849046409130096,
      "learning_rate": 4.273209123032445e-05,
      "loss": 0.0957,
      "step": 13580
    },
    {
      "epoch": 1.455187921619017,
      "grad_norm": 0.14518573880195618,
      "learning_rate": 4.272673733804476e-05,
      "loss": 0.0953,
      "step": 13590
    },
    {
      "epoch": 1.4562587000749545,
      "grad_norm": 0.16516533493995667,
      "learning_rate": 4.2721383445765075e-05,
      "loss": 0.0863,
      "step": 13600
    },
    {
      "epoch": 1.457329478530892,
      "grad_norm": 0.16290904581546783,
      "learning_rate": 4.271602955348539e-05,
      "loss": 0.1031,
      "step": 13610
    },
    {
      "epoch": 1.4584002569868293,
      "grad_norm": 0.23483236134052277,
      "learning_rate": 4.27106756612057e-05,
      "loss": 0.1009,
      "step": 13620
    },
    {
      "epoch": 1.459471035442767,
      "grad_norm": 0.1439775973558426,
      "learning_rate": 4.270532176892601e-05,
      "loss": 0.0953,
      "step": 13630
    },
    {
      "epoch": 1.4605418138987043,
      "grad_norm": 0.16827301681041718,
      "learning_rate": 4.269996787664632e-05,
      "loss": 0.0924,
      "step": 13640
    },
    {
      "epoch": 1.461612592354642,
      "grad_norm": 0.13033343851566315,
      "learning_rate": 4.269461398436664e-05,
      "loss": 0.0914,
      "step": 13650
    },
    {
      "epoch": 1.4626833708105793,
      "grad_norm": 0.11100876331329346,
      "learning_rate": 4.2689260092086944e-05,
      "loss": 0.0936,
      "step": 13660
    },
    {
      "epoch": 1.4637541492665167,
      "grad_norm": 0.1422959864139557,
      "learning_rate": 4.268390619980726e-05,
      "loss": 0.0971,
      "step": 13670
    },
    {
      "epoch": 1.464824927722454,
      "grad_norm": 0.11628904938697815,
      "learning_rate": 4.2678552307527573e-05,
      "loss": 0.0843,
      "step": 13680
    },
    {
      "epoch": 1.4658957061783917,
      "grad_norm": 0.1774294674396515,
      "learning_rate": 4.267319841524789e-05,
      "loss": 0.1117,
      "step": 13690
    },
    {
      "epoch": 1.466966484634329,
      "grad_norm": 0.1349058300256729,
      "learning_rate": 4.2667844522968196e-05,
      "loss": 0.0872,
      "step": 13700
    },
    {
      "epoch": 1.4680372630902667,
      "grad_norm": 0.16593195497989655,
      "learning_rate": 4.2662490630688514e-05,
      "loss": 0.1064,
      "step": 13710
    },
    {
      "epoch": 1.4691080415462041,
      "grad_norm": 0.1501832753419876,
      "learning_rate": 4.2657136738408826e-05,
      "loss": 0.0985,
      "step": 13720
    },
    {
      "epoch": 1.4701788200021415,
      "grad_norm": 0.14171436429023743,
      "learning_rate": 4.265178284612914e-05,
      "loss": 0.0992,
      "step": 13730
    },
    {
      "epoch": 1.471249598458079,
      "grad_norm": 0.1193535253405571,
      "learning_rate": 4.264642895384945e-05,
      "loss": 0.0951,
      "step": 13740
    },
    {
      "epoch": 1.4723203769140165,
      "grad_norm": 0.17482268810272217,
      "learning_rate": 4.264107506156976e-05,
      "loss": 0.1123,
      "step": 13750
    },
    {
      "epoch": 1.473391155369954,
      "grad_norm": 0.2188737690448761,
      "learning_rate": 4.263572116929008e-05,
      "loss": 0.1006,
      "step": 13760
    },
    {
      "epoch": 1.4744619338258915,
      "grad_norm": 0.15574690699577332,
      "learning_rate": 4.263036727701039e-05,
      "loss": 0.0937,
      "step": 13770
    },
    {
      "epoch": 1.475532712281829,
      "grad_norm": 0.1624278426170349,
      "learning_rate": 4.26250133847307e-05,
      "loss": 0.1044,
      "step": 13780
    },
    {
      "epoch": 1.4766034907377663,
      "grad_norm": 0.1858244240283966,
      "learning_rate": 4.261965949245101e-05,
      "loss": 0.0888,
      "step": 13790
    },
    {
      "epoch": 1.4776742691937037,
      "grad_norm": 0.17541638016700745,
      "learning_rate": 4.261430560017133e-05,
      "loss": 0.1004,
      "step": 13800
    },
    {
      "epoch": 1.4787450476496413,
      "grad_norm": 0.15093351900577545,
      "learning_rate": 4.2608951707891635e-05,
      "loss": 0.0859,
      "step": 13810
    },
    {
      "epoch": 1.4798158261055787,
      "grad_norm": 0.16900819540023804,
      "learning_rate": 4.2603597815611953e-05,
      "loss": 0.0915,
      "step": 13820
    },
    {
      "epoch": 1.4808866045615163,
      "grad_norm": 0.16369585692882538,
      "learning_rate": 4.2598243923332265e-05,
      "loss": 0.079,
      "step": 13830
    },
    {
      "epoch": 1.4819573830174537,
      "grad_norm": 0.1509782075881958,
      "learning_rate": 4.2592890031052576e-05,
      "loss": 0.0901,
      "step": 13840
    },
    {
      "epoch": 1.4830281614733911,
      "grad_norm": 0.20575790107250214,
      "learning_rate": 4.258753613877289e-05,
      "loss": 0.0908,
      "step": 13850
    },
    {
      "epoch": 1.4840989399293285,
      "grad_norm": 0.14697086811065674,
      "learning_rate": 4.25821822464932e-05,
      "loss": 0.0919,
      "step": 13860
    },
    {
      "epoch": 1.4851697183852661,
      "grad_norm": 0.149961918592453,
      "learning_rate": 4.257682835421352e-05,
      "loss": 0.0962,
      "step": 13870
    },
    {
      "epoch": 1.4862404968412035,
      "grad_norm": 0.116287462413311,
      "learning_rate": 4.257147446193383e-05,
      "loss": 0.0848,
      "step": 13880
    },
    {
      "epoch": 1.4873112752971411,
      "grad_norm": 0.14752206206321716,
      "learning_rate": 4.256612056965414e-05,
      "loss": 0.1066,
      "step": 13890
    },
    {
      "epoch": 1.4883820537530785,
      "grad_norm": 0.14238354563713074,
      "learning_rate": 4.256076667737445e-05,
      "loss": 0.1033,
      "step": 13900
    },
    {
      "epoch": 1.489452832209016,
      "grad_norm": 0.11203665286302567,
      "learning_rate": 4.255541278509477e-05,
      "loss": 0.0905,
      "step": 13910
    },
    {
      "epoch": 1.4905236106649533,
      "grad_norm": 0.1741487830877304,
      "learning_rate": 4.255005889281508e-05,
      "loss": 0.1046,
      "step": 13920
    },
    {
      "epoch": 1.491594389120891,
      "grad_norm": 0.20677819848060608,
      "learning_rate": 4.254470500053539e-05,
      "loss": 0.0935,
      "step": 13930
    },
    {
      "epoch": 1.4926651675768283,
      "grad_norm": 0.13562601804733276,
      "learning_rate": 4.2539351108255704e-05,
      "loss": 0.0942,
      "step": 13940
    },
    {
      "epoch": 1.493735946032766,
      "grad_norm": 0.20594321191310883,
      "learning_rate": 4.2533997215976015e-05,
      "loss": 0.0911,
      "step": 13950
    },
    {
      "epoch": 1.4948067244887033,
      "grad_norm": 0.31856638193130493,
      "learning_rate": 4.2528643323696327e-05,
      "loss": 0.109,
      "step": 13960
    },
    {
      "epoch": 1.4958775029446407,
      "grad_norm": 0.15814433991909027,
      "learning_rate": 4.252328943141664e-05,
      "loss": 0.1097,
      "step": 13970
    },
    {
      "epoch": 1.4969482814005781,
      "grad_norm": 0.127161905169487,
      "learning_rate": 4.2517935539136956e-05,
      "loss": 0.0968,
      "step": 13980
    },
    {
      "epoch": 1.4980190598565157,
      "grad_norm": 0.2524675130844116,
      "learning_rate": 4.251258164685727e-05,
      "loss": 0.1133,
      "step": 13990
    },
    {
      "epoch": 1.4990898383124531,
      "grad_norm": 0.1493709534406662,
      "learning_rate": 4.250722775457758e-05,
      "loss": 0.1028,
      "step": 14000
    },
    {
      "epoch": 1.5001606167683907,
      "grad_norm": 0.11386837065219879,
      "learning_rate": 4.250187386229789e-05,
      "loss": 0.0966,
      "step": 14010
    },
    {
      "epoch": 1.5012313952243281,
      "grad_norm": 0.10121694207191467,
      "learning_rate": 4.249651997001821e-05,
      "loss": 0.0882,
      "step": 14020
    },
    {
      "epoch": 1.5023021736802655,
      "grad_norm": 0.1821325719356537,
      "learning_rate": 4.249116607773852e-05,
      "loss": 0.0969,
      "step": 14030
    },
    {
      "epoch": 1.503372952136203,
      "grad_norm": 0.16784192621707916,
      "learning_rate": 4.248581218545883e-05,
      "loss": 0.0945,
      "step": 14040
    },
    {
      "epoch": 1.5044437305921405,
      "grad_norm": 0.19956578314304352,
      "learning_rate": 4.248045829317914e-05,
      "loss": 0.1067,
      "step": 14050
    },
    {
      "epoch": 1.505514509048078,
      "grad_norm": 0.2093575894832611,
      "learning_rate": 4.2475104400899454e-05,
      "loss": 0.1028,
      "step": 14060
    },
    {
      "epoch": 1.5065852875040155,
      "grad_norm": 0.18839794397354126,
      "learning_rate": 4.246975050861977e-05,
      "loss": 0.1035,
      "step": 14070
    },
    {
      "epoch": 1.507656065959953,
      "grad_norm": 0.24682803452014923,
      "learning_rate": 4.246439661634008e-05,
      "loss": 0.092,
      "step": 14080
    },
    {
      "epoch": 1.5087268444158903,
      "grad_norm": 0.14125269651412964,
      "learning_rate": 4.2459042724060395e-05,
      "loss": 0.0974,
      "step": 14090
    },
    {
      "epoch": 1.5097976228718277,
      "grad_norm": 0.17537473142147064,
      "learning_rate": 4.2453688831780706e-05,
      "loss": 0.0964,
      "step": 14100
    },
    {
      "epoch": 1.5108684013277651,
      "grad_norm": 0.15427230298519135,
      "learning_rate": 4.244833493950102e-05,
      "loss": 0.1058,
      "step": 14110
    },
    {
      "epoch": 1.5119391797837027,
      "grad_norm": 0.1894785612821579,
      "learning_rate": 4.244298104722133e-05,
      "loss": 0.1075,
      "step": 14120
    },
    {
      "epoch": 1.5130099582396404,
      "grad_norm": 0.22906063497066498,
      "learning_rate": 4.243762715494165e-05,
      "loss": 0.1105,
      "step": 14130
    },
    {
      "epoch": 1.5140807366955777,
      "grad_norm": 0.14678660035133362,
      "learning_rate": 4.243227326266196e-05,
      "loss": 0.1071,
      "step": 14140
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 0.15614913403987885,
      "learning_rate": 4.242691937038227e-05,
      "loss": 0.0925,
      "step": 14150
    },
    {
      "epoch": 1.5162222936074525,
      "grad_norm": 0.20669586956501007,
      "learning_rate": 4.242156547810258e-05,
      "loss": 0.0905,
      "step": 14160
    },
    {
      "epoch": 1.51729307206339,
      "grad_norm": 0.15837614238262177,
      "learning_rate": 4.241621158582289e-05,
      "loss": 0.0882,
      "step": 14170
    },
    {
      "epoch": 1.5183638505193275,
      "grad_norm": 0.15815985202789307,
      "learning_rate": 4.241085769354321e-05,
      "loss": 0.0911,
      "step": 14180
    },
    {
      "epoch": 1.5194346289752652,
      "grad_norm": 0.17176078259944916,
      "learning_rate": 4.2405503801263516e-05,
      "loss": 0.097,
      "step": 14190
    },
    {
      "epoch": 1.5205054074312025,
      "grad_norm": 0.2885144352912903,
      "learning_rate": 4.2400149908983834e-05,
      "loss": 0.1041,
      "step": 14200
    },
    {
      "epoch": 1.52157618588714,
      "grad_norm": 0.21080130338668823,
      "learning_rate": 4.2394796016704145e-05,
      "loss": 0.0899,
      "step": 14210
    },
    {
      "epoch": 1.5226469643430773,
      "grad_norm": 0.15609177947044373,
      "learning_rate": 4.2389442124424464e-05,
      "loss": 0.0886,
      "step": 14220
    },
    {
      "epoch": 1.5237177427990147,
      "grad_norm": 0.14156505465507507,
      "learning_rate": 4.238408823214477e-05,
      "loss": 0.1116,
      "step": 14230
    },
    {
      "epoch": 1.5247885212549523,
      "grad_norm": 0.20222683250904083,
      "learning_rate": 4.2378734339865086e-05,
      "loss": 0.0969,
      "step": 14240
    },
    {
      "epoch": 1.52585929971089,
      "grad_norm": 0.15563906729221344,
      "learning_rate": 4.23733804475854e-05,
      "loss": 0.0889,
      "step": 14250
    },
    {
      "epoch": 1.5269300781668274,
      "grad_norm": 0.1459321826696396,
      "learning_rate": 4.236802655530571e-05,
      "loss": 0.1001,
      "step": 14260
    },
    {
      "epoch": 1.5280008566227647,
      "grad_norm": 0.16784335672855377,
      "learning_rate": 4.236267266302602e-05,
      "loss": 0.0937,
      "step": 14270
    },
    {
      "epoch": 1.5290716350787021,
      "grad_norm": 0.18692681193351746,
      "learning_rate": 4.235731877074633e-05,
      "loss": 0.1063,
      "step": 14280
    },
    {
      "epoch": 1.5301424135346395,
      "grad_norm": 0.14710678160190582,
      "learning_rate": 4.235196487846665e-05,
      "loss": 0.0881,
      "step": 14290
    },
    {
      "epoch": 1.5312131919905771,
      "grad_norm": 0.15811598300933838,
      "learning_rate": 4.2346610986186955e-05,
      "loss": 0.0984,
      "step": 14300
    },
    {
      "epoch": 1.5322839704465148,
      "grad_norm": 0.15986590087413788,
      "learning_rate": 4.234125709390727e-05,
      "loss": 0.1199,
      "step": 14310
    },
    {
      "epoch": 1.5333547489024522,
      "grad_norm": 0.15128575265407562,
      "learning_rate": 4.2335903201627584e-05,
      "loss": 0.089,
      "step": 14320
    },
    {
      "epoch": 1.5344255273583896,
      "grad_norm": 0.1597944051027298,
      "learning_rate": 4.23305493093479e-05,
      "loss": 0.0873,
      "step": 14330
    },
    {
      "epoch": 1.535496305814327,
      "grad_norm": 0.14845135807991028,
      "learning_rate": 4.232519541706821e-05,
      "loss": 0.095,
      "step": 14340
    },
    {
      "epoch": 1.5365670842702643,
      "grad_norm": 0.22626695036888123,
      "learning_rate": 4.2319841524788525e-05,
      "loss": 0.103,
      "step": 14350
    },
    {
      "epoch": 1.537637862726202,
      "grad_norm": 0.14167526364326477,
      "learning_rate": 4.231448763250884e-05,
      "loss": 0.0999,
      "step": 14360
    },
    {
      "epoch": 1.5387086411821396,
      "grad_norm": 0.2075665444135666,
      "learning_rate": 4.230913374022915e-05,
      "loss": 0.1008,
      "step": 14370
    },
    {
      "epoch": 1.539779419638077,
      "grad_norm": 0.12664981186389923,
      "learning_rate": 4.230377984794946e-05,
      "loss": 0.0926,
      "step": 14380
    },
    {
      "epoch": 1.5408501980940144,
      "grad_norm": 0.2573558986186981,
      "learning_rate": 4.229842595566977e-05,
      "loss": 0.1071,
      "step": 14390
    },
    {
      "epoch": 1.5419209765499517,
      "grad_norm": 0.20429107546806335,
      "learning_rate": 4.229307206339009e-05,
      "loss": 0.0858,
      "step": 14400
    },
    {
      "epoch": 1.5429917550058891,
      "grad_norm": 0.16656778752803802,
      "learning_rate": 4.22877181711104e-05,
      "loss": 0.0937,
      "step": 14410
    },
    {
      "epoch": 1.5440625334618268,
      "grad_norm": 1.6657222509384155,
      "learning_rate": 4.228236427883071e-05,
      "loss": 0.0841,
      "step": 14420
    },
    {
      "epoch": 1.5451333119177644,
      "grad_norm": 0.24347004294395447,
      "learning_rate": 4.227701038655102e-05,
      "loss": 0.0845,
      "step": 14430
    },
    {
      "epoch": 1.5462040903737018,
      "grad_norm": 0.15652889013290405,
      "learning_rate": 4.227165649427134e-05,
      "loss": 0.1033,
      "step": 14440
    },
    {
      "epoch": 1.5472748688296392,
      "grad_norm": 0.15887244045734406,
      "learning_rate": 4.2266302601991646e-05,
      "loss": 0.0978,
      "step": 14450
    },
    {
      "epoch": 1.5483456472855766,
      "grad_norm": 0.18069083988666534,
      "learning_rate": 4.2260948709711964e-05,
      "loss": 0.0921,
      "step": 14460
    },
    {
      "epoch": 1.549416425741514,
      "grad_norm": 0.17830805480480194,
      "learning_rate": 4.2255594817432276e-05,
      "loss": 0.1258,
      "step": 14470
    },
    {
      "epoch": 1.5504872041974516,
      "grad_norm": 0.1176295205950737,
      "learning_rate": 4.225024092515259e-05,
      "loss": 0.0939,
      "step": 14480
    },
    {
      "epoch": 1.5515579826533892,
      "grad_norm": 0.13679732382297516,
      "learning_rate": 4.22448870328729e-05,
      "loss": 0.0926,
      "step": 14490
    },
    {
      "epoch": 1.5526287611093266,
      "grad_norm": 0.1614871770143509,
      "learning_rate": 4.223953314059321e-05,
      "loss": 0.1027,
      "step": 14500
    },
    {
      "epoch": 1.553699539565264,
      "grad_norm": 0.7410343885421753,
      "learning_rate": 4.223417924831353e-05,
      "loss": 0.0995,
      "step": 14510
    },
    {
      "epoch": 1.5547703180212014,
      "grad_norm": 0.10734883695840836,
      "learning_rate": 4.222882535603384e-05,
      "loss": 0.0966,
      "step": 14520
    },
    {
      "epoch": 1.5558410964771388,
      "grad_norm": 0.11620081216096878,
      "learning_rate": 4.222347146375415e-05,
      "loss": 0.1018,
      "step": 14530
    },
    {
      "epoch": 1.5569118749330764,
      "grad_norm": 0.2601665258407593,
      "learning_rate": 4.221811757147446e-05,
      "loss": 0.1,
      "step": 14540
    },
    {
      "epoch": 1.5579826533890138,
      "grad_norm": 0.11364118754863739,
      "learning_rate": 4.221276367919478e-05,
      "loss": 0.0817,
      "step": 14550
    },
    {
      "epoch": 1.5590534318449514,
      "grad_norm": 0.16335254907608032,
      "learning_rate": 4.220740978691509e-05,
      "loss": 0.0878,
      "step": 14560
    },
    {
      "epoch": 1.5601242103008888,
      "grad_norm": 0.12158763408660889,
      "learning_rate": 4.22020558946354e-05,
      "loss": 0.0938,
      "step": 14570
    },
    {
      "epoch": 1.5611949887568262,
      "grad_norm": 0.14729373157024384,
      "learning_rate": 4.2196702002355715e-05,
      "loss": 0.0882,
      "step": 14580
    },
    {
      "epoch": 1.5622657672127636,
      "grad_norm": 0.13266171514987946,
      "learning_rate": 4.2191348110076026e-05,
      "loss": 0.0946,
      "step": 14590
    },
    {
      "epoch": 1.5633365456687012,
      "grad_norm": 0.16381961107254028,
      "learning_rate": 4.218599421779634e-05,
      "loss": 0.1046,
      "step": 14600
    },
    {
      "epoch": 1.5644073241246386,
      "grad_norm": 0.1644187867641449,
      "learning_rate": 4.218064032551665e-05,
      "loss": 0.0996,
      "step": 14610
    },
    {
      "epoch": 1.5654781025805762,
      "grad_norm": 0.18015405535697937,
      "learning_rate": 4.217528643323697e-05,
      "loss": 0.0897,
      "step": 14620
    },
    {
      "epoch": 1.5665488810365136,
      "grad_norm": 0.19207948446273804,
      "learning_rate": 4.216993254095728e-05,
      "loss": 0.1029,
      "step": 14630
    },
    {
      "epoch": 1.567619659492451,
      "grad_norm": 0.15293022990226746,
      "learning_rate": 4.216457864867759e-05,
      "loss": 0.0933,
      "step": 14640
    },
    {
      "epoch": 1.5686904379483884,
      "grad_norm": 0.13958987593650818,
      "learning_rate": 4.21592247563979e-05,
      "loss": 0.1036,
      "step": 14650
    },
    {
      "epoch": 1.569761216404326,
      "grad_norm": 0.13498955965042114,
      "learning_rate": 4.215387086411822e-05,
      "loss": 0.0971,
      "step": 14660
    },
    {
      "epoch": 1.5708319948602634,
      "grad_norm": 0.16076865792274475,
      "learning_rate": 4.214851697183853e-05,
      "loss": 0.0918,
      "step": 14670
    },
    {
      "epoch": 1.571902773316201,
      "grad_norm": 0.10370227694511414,
      "learning_rate": 4.214316307955884e-05,
      "loss": 0.0969,
      "step": 14680
    },
    {
      "epoch": 1.5729735517721384,
      "grad_norm": 0.32752925157546997,
      "learning_rate": 4.2137809187279154e-05,
      "loss": 0.096,
      "step": 14690
    },
    {
      "epoch": 1.5740443302280758,
      "grad_norm": 0.2352803498506546,
      "learning_rate": 4.2132455294999465e-05,
      "loss": 0.11,
      "step": 14700
    },
    {
      "epoch": 1.5751151086840132,
      "grad_norm": 0.20279431343078613,
      "learning_rate": 4.212710140271978e-05,
      "loss": 0.0976,
      "step": 14710
    },
    {
      "epoch": 1.5761858871399508,
      "grad_norm": 0.14333301782608032,
      "learning_rate": 4.212174751044009e-05,
      "loss": 0.097,
      "step": 14720
    },
    {
      "epoch": 1.5772566655958882,
      "grad_norm": 0.18633289635181427,
      "learning_rate": 4.2116393618160406e-05,
      "loss": 0.1066,
      "step": 14730
    },
    {
      "epoch": 1.5783274440518258,
      "grad_norm": 0.13068073987960815,
      "learning_rate": 4.211103972588072e-05,
      "loss": 0.1032,
      "step": 14740
    },
    {
      "epoch": 1.5793982225077632,
      "grad_norm": 0.2533734440803528,
      "learning_rate": 4.210568583360103e-05,
      "loss": 0.0888,
      "step": 14750
    },
    {
      "epoch": 1.5804690009637006,
      "grad_norm": 0.14804606139659882,
      "learning_rate": 4.210033194132134e-05,
      "loss": 0.0942,
      "step": 14760
    },
    {
      "epoch": 1.581539779419638,
      "grad_norm": 0.1749120056629181,
      "learning_rate": 4.209497804904166e-05,
      "loss": 0.0904,
      "step": 14770
    },
    {
      "epoch": 1.5826105578755756,
      "grad_norm": 0.14427787065505981,
      "learning_rate": 4.208962415676197e-05,
      "loss": 0.0979,
      "step": 14780
    },
    {
      "epoch": 1.583681336331513,
      "grad_norm": 0.09702763706445694,
      "learning_rate": 4.208427026448228e-05,
      "loss": 0.0929,
      "step": 14790
    },
    {
      "epoch": 1.5847521147874506,
      "grad_norm": 0.1432163566350937,
      "learning_rate": 4.207891637220259e-05,
      "loss": 0.0936,
      "step": 14800
    },
    {
      "epoch": 1.585822893243388,
      "grad_norm": 0.12862110137939453,
      "learning_rate": 4.2073562479922904e-05,
      "loss": 0.0915,
      "step": 14810
    },
    {
      "epoch": 1.5868936716993254,
      "grad_norm": 0.16304242610931396,
      "learning_rate": 4.206820858764322e-05,
      "loss": 0.1018,
      "step": 14820
    },
    {
      "epoch": 1.5879644501552628,
      "grad_norm": 0.16896981000900269,
      "learning_rate": 4.206285469536353e-05,
      "loss": 0.0952,
      "step": 14830
    },
    {
      "epoch": 1.5890352286112004,
      "grad_norm": 0.1614747941493988,
      "learning_rate": 4.2057500803083845e-05,
      "loss": 0.1034,
      "step": 14840
    },
    {
      "epoch": 1.5901060070671378,
      "grad_norm": 0.08489912003278732,
      "learning_rate": 4.2052146910804156e-05,
      "loss": 0.0826,
      "step": 14850
    },
    {
      "epoch": 1.5911767855230754,
      "grad_norm": 0.21343286335468292,
      "learning_rate": 4.2046793018524475e-05,
      "loss": 0.1034,
      "step": 14860
    },
    {
      "epoch": 1.5922475639790128,
      "grad_norm": 0.15972399711608887,
      "learning_rate": 4.204143912624478e-05,
      "loss": 0.1013,
      "step": 14870
    },
    {
      "epoch": 1.5933183424349502,
      "grad_norm": 0.17119699716567993,
      "learning_rate": 4.20360852339651e-05,
      "loss": 0.0945,
      "step": 14880
    },
    {
      "epoch": 1.5943891208908876,
      "grad_norm": 0.1655399352312088,
      "learning_rate": 4.203073134168541e-05,
      "loss": 0.1077,
      "step": 14890
    },
    {
      "epoch": 1.5954598993468252,
      "grad_norm": 0.14981497824192047,
      "learning_rate": 4.202537744940572e-05,
      "loss": 0.0981,
      "step": 14900
    },
    {
      "epoch": 1.5965306778027626,
      "grad_norm": 0.12247844785451889,
      "learning_rate": 4.202002355712603e-05,
      "loss": 0.0836,
      "step": 14910
    },
    {
      "epoch": 1.5976014562587002,
      "grad_norm": 0.1332162618637085,
      "learning_rate": 4.201466966484634e-05,
      "loss": 0.1042,
      "step": 14920
    },
    {
      "epoch": 1.5986722347146376,
      "grad_norm": 0.2439393848180771,
      "learning_rate": 4.200931577256666e-05,
      "loss": 0.0991,
      "step": 14930
    },
    {
      "epoch": 1.599743013170575,
      "grad_norm": 0.14777252078056335,
      "learning_rate": 4.2003961880286966e-05,
      "loss": 0.1056,
      "step": 14940
    },
    {
      "epoch": 1.6008137916265124,
      "grad_norm": 0.14557187259197235,
      "learning_rate": 4.1998607988007284e-05,
      "loss": 0.104,
      "step": 14950
    },
    {
      "epoch": 1.6018845700824498,
      "grad_norm": 0.12188134342432022,
      "learning_rate": 4.1993254095727595e-05,
      "loss": 0.0892,
      "step": 14960
    },
    {
      "epoch": 1.6029553485383874,
      "grad_norm": 0.14355267584323883,
      "learning_rate": 4.1987900203447914e-05,
      "loss": 0.1059,
      "step": 14970
    },
    {
      "epoch": 1.604026126994325,
      "grad_norm": 0.13024422526359558,
      "learning_rate": 4.198254631116822e-05,
      "loss": 0.0985,
      "step": 14980
    },
    {
      "epoch": 1.6050969054502624,
      "grad_norm": 0.16427873075008392,
      "learning_rate": 4.1977192418888536e-05,
      "loss": 0.1052,
      "step": 14990
    },
    {
      "epoch": 1.6061676839061998,
      "grad_norm": 0.14370156824588776,
      "learning_rate": 4.197183852660885e-05,
      "loss": 0.0931,
      "step": 15000
    },
    {
      "epoch": 1.6072384623621372,
      "grad_norm": 0.1310884952545166,
      "learning_rate": 4.196648463432916e-05,
      "loss": 0.0802,
      "step": 15010
    },
    {
      "epoch": 1.6083092408180746,
      "grad_norm": 0.13303573429584503,
      "learning_rate": 4.196113074204947e-05,
      "loss": 0.1043,
      "step": 15020
    },
    {
      "epoch": 1.6093800192740122,
      "grad_norm": 0.11001835018396378,
      "learning_rate": 4.195577684976978e-05,
      "loss": 0.0977,
      "step": 15030
    },
    {
      "epoch": 1.6104507977299498,
      "grad_norm": 0.17013925313949585,
      "learning_rate": 4.19504229574901e-05,
      "loss": 0.1019,
      "step": 15040
    },
    {
      "epoch": 1.6115215761858872,
      "grad_norm": 0.1500098556280136,
      "learning_rate": 4.1945069065210405e-05,
      "loss": 0.0901,
      "step": 15050
    },
    {
      "epoch": 1.6125923546418246,
      "grad_norm": 0.2370622158050537,
      "learning_rate": 4.193971517293072e-05,
      "loss": 0.1028,
      "step": 15060
    },
    {
      "epoch": 1.613663133097762,
      "grad_norm": 0.13407401740550995,
      "learning_rate": 4.1934361280651034e-05,
      "loss": 0.0941,
      "step": 15070
    },
    {
      "epoch": 1.6147339115536994,
      "grad_norm": 0.16034388542175293,
      "learning_rate": 4.192900738837135e-05,
      "loss": 0.0944,
      "step": 15080
    },
    {
      "epoch": 1.615804690009637,
      "grad_norm": 0.13754791021347046,
      "learning_rate": 4.192365349609166e-05,
      "loss": 0.1083,
      "step": 15090
    },
    {
      "epoch": 1.6168754684655746,
      "grad_norm": 0.1558978408575058,
      "learning_rate": 4.1918299603811975e-05,
      "loss": 0.1067,
      "step": 15100
    },
    {
      "epoch": 1.617946246921512,
      "grad_norm": 0.21433459222316742,
      "learning_rate": 4.191294571153229e-05,
      "loss": 0.1035,
      "step": 15110
    },
    {
      "epoch": 1.6190170253774494,
      "grad_norm": 0.13779641687870026,
      "learning_rate": 4.19075918192526e-05,
      "loss": 0.0785,
      "step": 15120
    },
    {
      "epoch": 1.6200878038333868,
      "grad_norm": 0.15732604265213013,
      "learning_rate": 4.190223792697291e-05,
      "loss": 0.1005,
      "step": 15130
    },
    {
      "epoch": 1.6211585822893242,
      "grad_norm": 0.19639578461647034,
      "learning_rate": 4.189688403469322e-05,
      "loss": 0.1183,
      "step": 15140
    },
    {
      "epoch": 1.6222293607452618,
      "grad_norm": 0.22801633179187775,
      "learning_rate": 4.189153014241354e-05,
      "loss": 0.0888,
      "step": 15150
    },
    {
      "epoch": 1.6233001392011994,
      "grad_norm": 0.18341149389743805,
      "learning_rate": 4.188617625013385e-05,
      "loss": 0.0969,
      "step": 15160
    },
    {
      "epoch": 1.6243709176571368,
      "grad_norm": 0.2160540372133255,
      "learning_rate": 4.188082235785416e-05,
      "loss": 0.103,
      "step": 15170
    },
    {
      "epoch": 1.6254416961130742,
      "grad_norm": 0.1844893842935562,
      "learning_rate": 4.187546846557447e-05,
      "loss": 0.1048,
      "step": 15180
    },
    {
      "epoch": 1.6265124745690116,
      "grad_norm": 0.11525078862905502,
      "learning_rate": 4.187011457329479e-05,
      "loss": 0.0995,
      "step": 15190
    },
    {
      "epoch": 1.627583253024949,
      "grad_norm": 0.1099298745393753,
      "learning_rate": 4.18647606810151e-05,
      "loss": 0.0953,
      "step": 15200
    },
    {
      "epoch": 1.6286540314808866,
      "grad_norm": 0.21517610549926758,
      "learning_rate": 4.1859406788735414e-05,
      "loss": 0.0981,
      "step": 15210
    },
    {
      "epoch": 1.6297248099368242,
      "grad_norm": 0.1591576486825943,
      "learning_rate": 4.1854052896455726e-05,
      "loss": 0.1015,
      "step": 15220
    },
    {
      "epoch": 1.6307955883927616,
      "grad_norm": 0.21860969066619873,
      "learning_rate": 4.184869900417604e-05,
      "loss": 0.0852,
      "step": 15230
    },
    {
      "epoch": 1.631866366848699,
      "grad_norm": 0.2516026198863983,
      "learning_rate": 4.184334511189635e-05,
      "loss": 0.1082,
      "step": 15240
    },
    {
      "epoch": 1.6329371453046364,
      "grad_norm": 0.15033526718616486,
      "learning_rate": 4.183799121961666e-05,
      "loss": 0.0837,
      "step": 15250
    },
    {
      "epoch": 1.6340079237605738,
      "grad_norm": 0.14741195738315582,
      "learning_rate": 4.183263732733698e-05,
      "loss": 0.1114,
      "step": 15260
    },
    {
      "epoch": 1.6350787022165114,
      "grad_norm": 0.18578781187534332,
      "learning_rate": 4.182728343505729e-05,
      "loss": 0.0977,
      "step": 15270
    },
    {
      "epoch": 1.636149480672449,
      "grad_norm": 0.16822250187397003,
      "learning_rate": 4.18219295427776e-05,
      "loss": 0.1011,
      "step": 15280
    },
    {
      "epoch": 1.6372202591283864,
      "grad_norm": 0.17484788596630096,
      "learning_rate": 4.181657565049791e-05,
      "loss": 0.086,
      "step": 15290
    },
    {
      "epoch": 1.6382910375843238,
      "grad_norm": 0.19042035937309265,
      "learning_rate": 4.181122175821823e-05,
      "loss": 0.1115,
      "step": 15300
    },
    {
      "epoch": 1.6393618160402612,
      "grad_norm": 0.15740707516670227,
      "learning_rate": 4.180586786593854e-05,
      "loss": 0.104,
      "step": 15310
    },
    {
      "epoch": 1.6404325944961986,
      "grad_norm": 0.34062573313713074,
      "learning_rate": 4.180051397365885e-05,
      "loss": 0.1001,
      "step": 15320
    },
    {
      "epoch": 1.6415033729521362,
      "grad_norm": 0.11451976746320724,
      "learning_rate": 4.1795160081379165e-05,
      "loss": 0.0814,
      "step": 15330
    },
    {
      "epoch": 1.6425741514080738,
      "grad_norm": 0.39449772238731384,
      "learning_rate": 4.1789806189099476e-05,
      "loss": 0.0925,
      "step": 15340
    },
    {
      "epoch": 1.6436449298640112,
      "grad_norm": 0.11663240194320679,
      "learning_rate": 4.1784452296819794e-05,
      "loss": 0.0876,
      "step": 15350
    },
    {
      "epoch": 1.6447157083199486,
      "grad_norm": 0.27265432476997375,
      "learning_rate": 4.17790984045401e-05,
      "loss": 0.1017,
      "step": 15360
    },
    {
      "epoch": 1.645786486775886,
      "grad_norm": 0.1871705800294876,
      "learning_rate": 4.177374451226042e-05,
      "loss": 0.0908,
      "step": 15370
    },
    {
      "epoch": 1.6468572652318234,
      "grad_norm": 0.12031841278076172,
      "learning_rate": 4.176839061998073e-05,
      "loss": 0.0929,
      "step": 15380
    },
    {
      "epoch": 1.647928043687761,
      "grad_norm": 0.14143413305282593,
      "learning_rate": 4.176303672770104e-05,
      "loss": 0.0918,
      "step": 15390
    },
    {
      "epoch": 1.6489988221436984,
      "grad_norm": 0.15176968276500702,
      "learning_rate": 4.175768283542135e-05,
      "loss": 0.0966,
      "step": 15400
    },
    {
      "epoch": 1.650069600599636,
      "grad_norm": 0.15796291828155518,
      "learning_rate": 4.175232894314167e-05,
      "loss": 0.1089,
      "step": 15410
    },
    {
      "epoch": 1.6511403790555734,
      "grad_norm": 0.10723312199115753,
      "learning_rate": 4.174697505086198e-05,
      "loss": 0.0932,
      "step": 15420
    },
    {
      "epoch": 1.6522111575115108,
      "grad_norm": 0.18889650702476501,
      "learning_rate": 4.174162115858229e-05,
      "loss": 0.0865,
      "step": 15430
    },
    {
      "epoch": 1.6532819359674482,
      "grad_norm": 0.15395821630954742,
      "learning_rate": 4.1736267266302604e-05,
      "loss": 0.096,
      "step": 15440
    },
    {
      "epoch": 1.6543527144233858,
      "grad_norm": 0.1712118685245514,
      "learning_rate": 4.1730913374022915e-05,
      "loss": 0.081,
      "step": 15450
    },
    {
      "epoch": 1.6554234928793232,
      "grad_norm": 0.23120605945587158,
      "learning_rate": 4.172555948174323e-05,
      "loss": 0.0907,
      "step": 15460
    },
    {
      "epoch": 1.6564942713352608,
      "grad_norm": 0.1850520670413971,
      "learning_rate": 4.172020558946354e-05,
      "loss": 0.0958,
      "step": 15470
    },
    {
      "epoch": 1.6575650497911982,
      "grad_norm": 0.1327001303434372,
      "learning_rate": 4.1714851697183856e-05,
      "loss": 0.0959,
      "step": 15480
    },
    {
      "epoch": 1.6586358282471356,
      "grad_norm": 0.1552012413740158,
      "learning_rate": 4.170949780490417e-05,
      "loss": 0.0965,
      "step": 15490
    },
    {
      "epoch": 1.659706606703073,
      "grad_norm": 0.16606317460536957,
      "learning_rate": 4.1704143912624485e-05,
      "loss": 0.0925,
      "step": 15500
    },
    {
      "epoch": 1.6607773851590106,
      "grad_norm": 0.24881429970264435,
      "learning_rate": 4.169879002034479e-05,
      "loss": 0.0965,
      "step": 15510
    },
    {
      "epoch": 1.661848163614948,
      "grad_norm": 0.13670971989631653,
      "learning_rate": 4.169343612806511e-05,
      "loss": 0.0856,
      "step": 15520
    },
    {
      "epoch": 1.6629189420708856,
      "grad_norm": 0.12452404946088791,
      "learning_rate": 4.168808223578542e-05,
      "loss": 0.1234,
      "step": 15530
    },
    {
      "epoch": 1.663989720526823,
      "grad_norm": 0.13639026880264282,
      "learning_rate": 4.168272834350573e-05,
      "loss": 0.0998,
      "step": 15540
    },
    {
      "epoch": 1.6650604989827604,
      "grad_norm": 0.125660702586174,
      "learning_rate": 4.167737445122604e-05,
      "loss": 0.1038,
      "step": 15550
    },
    {
      "epoch": 1.6661312774386978,
      "grad_norm": 0.1271018385887146,
      "learning_rate": 4.1672020558946354e-05,
      "loss": 0.0867,
      "step": 15560
    },
    {
      "epoch": 1.6672020558946354,
      "grad_norm": 0.2700308859348297,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.1028,
      "step": 15570
    },
    {
      "epoch": 1.6682728343505728,
      "grad_norm": 0.20711404085159302,
      "learning_rate": 4.166131277438698e-05,
      "loss": 0.0939,
      "step": 15580
    },
    {
      "epoch": 1.6693436128065104,
      "grad_norm": 0.1332194209098816,
      "learning_rate": 4.1655958882107295e-05,
      "loss": 0.086,
      "step": 15590
    },
    {
      "epoch": 1.6704143912624478,
      "grad_norm": 0.163636714220047,
      "learning_rate": 4.1650604989827606e-05,
      "loss": 0.0899,
      "step": 15600
    },
    {
      "epoch": 1.6714851697183852,
      "grad_norm": 0.16875410079956055,
      "learning_rate": 4.1645251097547924e-05,
      "loss": 0.0928,
      "step": 15610
    },
    {
      "epoch": 1.6725559481743226,
      "grad_norm": 0.14036300778388977,
      "learning_rate": 4.163989720526823e-05,
      "loss": 0.107,
      "step": 15620
    },
    {
      "epoch": 1.6736267266302602,
      "grad_norm": 0.17015257477760315,
      "learning_rate": 4.163454331298855e-05,
      "loss": 0.0939,
      "step": 15630
    },
    {
      "epoch": 1.6746975050861976,
      "grad_norm": 0.14117299020290375,
      "learning_rate": 4.162918942070886e-05,
      "loss": 0.0818,
      "step": 15640
    },
    {
      "epoch": 1.6757682835421353,
      "grad_norm": 0.17350566387176514,
      "learning_rate": 4.162383552842917e-05,
      "loss": 0.0947,
      "step": 15650
    },
    {
      "epoch": 1.6768390619980726,
      "grad_norm": 0.1635148525238037,
      "learning_rate": 4.161848163614948e-05,
      "loss": 0.0886,
      "step": 15660
    },
    {
      "epoch": 1.67790984045401,
      "grad_norm": 0.14235812425613403,
      "learning_rate": 4.161312774386979e-05,
      "loss": 0.0902,
      "step": 15670
    },
    {
      "epoch": 1.6789806189099474,
      "grad_norm": 0.12302219122648239,
      "learning_rate": 4.160777385159011e-05,
      "loss": 0.0851,
      "step": 15680
    },
    {
      "epoch": 1.680051397365885,
      "grad_norm": 0.17857472598552704,
      "learning_rate": 4.1602419959310416e-05,
      "loss": 0.0973,
      "step": 15690
    },
    {
      "epoch": 1.6811221758218224,
      "grad_norm": 0.198335662484169,
      "learning_rate": 4.1597066067030734e-05,
      "loss": 0.0898,
      "step": 15700
    },
    {
      "epoch": 1.68219295427776,
      "grad_norm": 0.15108874440193176,
      "learning_rate": 4.1591712174751045e-05,
      "loss": 0.0961,
      "step": 15710
    },
    {
      "epoch": 1.6832637327336974,
      "grad_norm": 0.16106891632080078,
      "learning_rate": 4.158635828247136e-05,
      "loss": 0.0867,
      "step": 15720
    },
    {
      "epoch": 1.6843345111896348,
      "grad_norm": 0.14206163585186005,
      "learning_rate": 4.158100439019167e-05,
      "loss": 0.0992,
      "step": 15730
    },
    {
      "epoch": 1.6854052896455722,
      "grad_norm": 0.2111717015504837,
      "learning_rate": 4.1575650497911986e-05,
      "loss": 0.0947,
      "step": 15740
    },
    {
      "epoch": 1.6864760681015099,
      "grad_norm": 0.21538639068603516,
      "learning_rate": 4.15702966056323e-05,
      "loss": 0.0995,
      "step": 15750
    },
    {
      "epoch": 1.6875468465574472,
      "grad_norm": 0.15122191607952118,
      "learning_rate": 4.156494271335261e-05,
      "loss": 0.0892,
      "step": 15760
    },
    {
      "epoch": 1.6886176250133849,
      "grad_norm": 0.1479981541633606,
      "learning_rate": 4.155958882107292e-05,
      "loss": 0.091,
      "step": 15770
    },
    {
      "epoch": 1.6896884034693223,
      "grad_norm": 0.13190129399299622,
      "learning_rate": 4.155423492879323e-05,
      "loss": 0.0872,
      "step": 15780
    },
    {
      "epoch": 1.6907591819252596,
      "grad_norm": 1.5560539960861206,
      "learning_rate": 4.154888103651355e-05,
      "loss": 0.1003,
      "step": 15790
    },
    {
      "epoch": 1.691829960381197,
      "grad_norm": 0.19789482653141022,
      "learning_rate": 4.154352714423386e-05,
      "loss": 0.0899,
      "step": 15800
    },
    {
      "epoch": 1.6929007388371344,
      "grad_norm": 0.17738644778728485,
      "learning_rate": 4.153817325195417e-05,
      "loss": 0.1004,
      "step": 15810
    },
    {
      "epoch": 1.693971517293072,
      "grad_norm": 0.21438263356685638,
      "learning_rate": 4.1532819359674484e-05,
      "loss": 0.0918,
      "step": 15820
    },
    {
      "epoch": 1.6950422957490097,
      "grad_norm": 0.2125442773103714,
      "learning_rate": 4.15274654673948e-05,
      "loss": 0.1023,
      "step": 15830
    },
    {
      "epoch": 1.696113074204947,
      "grad_norm": 0.20774561166763306,
      "learning_rate": 4.152211157511511e-05,
      "loss": 0.1,
      "step": 15840
    },
    {
      "epoch": 1.6971838526608845,
      "grad_norm": 0.19836777448654175,
      "learning_rate": 4.1516757682835425e-05,
      "loss": 0.1016,
      "step": 15850
    },
    {
      "epoch": 1.6982546311168218,
      "grad_norm": 0.15681205689907074,
      "learning_rate": 4.1511403790555737e-05,
      "loss": 0.0883,
      "step": 15860
    },
    {
      "epoch": 1.6993254095727592,
      "grad_norm": 0.15156131982803345,
      "learning_rate": 4.150604989827605e-05,
      "loss": 0.1142,
      "step": 15870
    },
    {
      "epoch": 1.7003961880286969,
      "grad_norm": 0.13829529285430908,
      "learning_rate": 4.150069600599636e-05,
      "loss": 0.0924,
      "step": 15880
    },
    {
      "epoch": 1.7014669664846345,
      "grad_norm": 0.20958174765110016,
      "learning_rate": 4.149534211371667e-05,
      "loss": 0.0912,
      "step": 15890
    },
    {
      "epoch": 1.7025377449405719,
      "grad_norm": 0.2263628989458084,
      "learning_rate": 4.148998822143699e-05,
      "loss": 0.0958,
      "step": 15900
    },
    {
      "epoch": 1.7036085233965093,
      "grad_norm": 0.193287193775177,
      "learning_rate": 4.14846343291573e-05,
      "loss": 0.0845,
      "step": 15910
    },
    {
      "epoch": 1.7046793018524466,
      "grad_norm": 0.09751562774181366,
      "learning_rate": 4.147928043687761e-05,
      "loss": 0.0869,
      "step": 15920
    },
    {
      "epoch": 1.705750080308384,
      "grad_norm": 0.1544777899980545,
      "learning_rate": 4.147392654459792e-05,
      "loss": 0.097,
      "step": 15930
    },
    {
      "epoch": 1.7068208587643217,
      "grad_norm": 0.16032053530216217,
      "learning_rate": 4.146857265231824e-05,
      "loss": 0.107,
      "step": 15940
    },
    {
      "epoch": 1.7078916372202593,
      "grad_norm": 0.13096994161605835,
      "learning_rate": 4.146321876003855e-05,
      "loss": 0.0889,
      "step": 15950
    },
    {
      "epoch": 1.7089624156761967,
      "grad_norm": 0.1133795976638794,
      "learning_rate": 4.1457864867758864e-05,
      "loss": 0.0893,
      "step": 15960
    },
    {
      "epoch": 1.710033194132134,
      "grad_norm": 0.24026817083358765,
      "learning_rate": 4.1452510975479175e-05,
      "loss": 0.0891,
      "step": 15970
    },
    {
      "epoch": 1.7111039725880715,
      "grad_norm": 0.28970956802368164,
      "learning_rate": 4.144715708319949e-05,
      "loss": 0.0941,
      "step": 15980
    },
    {
      "epoch": 1.7121747510440088,
      "grad_norm": 0.14328189194202423,
      "learning_rate": 4.14418031909198e-05,
      "loss": 0.0984,
      "step": 15990
    },
    {
      "epoch": 1.7132455294999465,
      "grad_norm": 0.17969734966754913,
      "learning_rate": 4.143644929864011e-05,
      "loss": 0.0974,
      "step": 16000
    },
    {
      "epoch": 1.714316307955884,
      "grad_norm": 0.13940365612506866,
      "learning_rate": 4.143109540636043e-05,
      "loss": 0.1108,
      "step": 16010
    },
    {
      "epoch": 1.7153870864118215,
      "grad_norm": 0.13695338368415833,
      "learning_rate": 4.142574151408074e-05,
      "loss": 0.0912,
      "step": 16020
    },
    {
      "epoch": 1.7164578648677589,
      "grad_norm": 0.25336435437202454,
      "learning_rate": 4.142038762180105e-05,
      "loss": 0.0877,
      "step": 16030
    },
    {
      "epoch": 1.7175286433236963,
      "grad_norm": 0.148067444562912,
      "learning_rate": 4.141503372952136e-05,
      "loss": 0.087,
      "step": 16040
    },
    {
      "epoch": 1.7185994217796337,
      "grad_norm": 0.17559102177619934,
      "learning_rate": 4.140967983724168e-05,
      "loss": 0.0909,
      "step": 16050
    },
    {
      "epoch": 1.7196702002355713,
      "grad_norm": 0.20495745539665222,
      "learning_rate": 4.140432594496199e-05,
      "loss": 0.094,
      "step": 16060
    },
    {
      "epoch": 1.7207409786915089,
      "grad_norm": 0.5732903480529785,
      "learning_rate": 4.13989720526823e-05,
      "loss": 0.1014,
      "step": 16070
    },
    {
      "epoch": 1.7218117571474463,
      "grad_norm": 0.4596424102783203,
      "learning_rate": 4.1393618160402614e-05,
      "loss": 0.092,
      "step": 16080
    },
    {
      "epoch": 1.7228825356033837,
      "grad_norm": 0.1403350830078125,
      "learning_rate": 4.1388264268122926e-05,
      "loss": 0.0876,
      "step": 16090
    },
    {
      "epoch": 1.723953314059321,
      "grad_norm": 0.134198859333992,
      "learning_rate": 4.1382910375843244e-05,
      "loss": 0.0999,
      "step": 16100
    },
    {
      "epoch": 1.7250240925152585,
      "grad_norm": 0.12098255753517151,
      "learning_rate": 4.137755648356355e-05,
      "loss": 0.0881,
      "step": 16110
    },
    {
      "epoch": 1.726094870971196,
      "grad_norm": 0.1979709416627884,
      "learning_rate": 4.137220259128387e-05,
      "loss": 0.1061,
      "step": 16120
    },
    {
      "epoch": 1.7271656494271337,
      "grad_norm": 0.15800943970680237,
      "learning_rate": 4.136684869900418e-05,
      "loss": 0.1003,
      "step": 16130
    },
    {
      "epoch": 1.728236427883071,
      "grad_norm": 0.1581019163131714,
      "learning_rate": 4.1361494806724496e-05,
      "loss": 0.087,
      "step": 16140
    },
    {
      "epoch": 1.7293072063390085,
      "grad_norm": 0.1732023060321808,
      "learning_rate": 4.13561409144448e-05,
      "loss": 0.1006,
      "step": 16150
    },
    {
      "epoch": 1.7303779847949459,
      "grad_norm": 0.15193751454353333,
      "learning_rate": 4.135078702216512e-05,
      "loss": 0.0741,
      "step": 16160
    },
    {
      "epoch": 1.7314487632508833,
      "grad_norm": 0.17096270620822906,
      "learning_rate": 4.134543312988543e-05,
      "loss": 0.0997,
      "step": 16170
    },
    {
      "epoch": 1.7325195417068209,
      "grad_norm": 0.23506128787994385,
      "learning_rate": 4.134007923760574e-05,
      "loss": 0.1131,
      "step": 16180
    },
    {
      "epoch": 1.7335903201627585,
      "grad_norm": 0.1608942151069641,
      "learning_rate": 4.1334725345326053e-05,
      "loss": 0.0903,
      "step": 16190
    },
    {
      "epoch": 1.7346610986186959,
      "grad_norm": 0.1455601006746292,
      "learning_rate": 4.1329371453046365e-05,
      "loss": 0.0857,
      "step": 16200
    },
    {
      "epoch": 1.7357318770746333,
      "grad_norm": 0.10804115235805511,
      "learning_rate": 4.132401756076668e-05,
      "loss": 0.0833,
      "step": 16210
    },
    {
      "epoch": 1.7368026555305707,
      "grad_norm": 0.18773892521858215,
      "learning_rate": 4.131866366848699e-05,
      "loss": 0.0922,
      "step": 16220
    },
    {
      "epoch": 1.737873433986508,
      "grad_norm": 0.24327805638313293,
      "learning_rate": 4.1313309776207306e-05,
      "loss": 0.0985,
      "step": 16230
    },
    {
      "epoch": 1.7389442124424457,
      "grad_norm": 0.15907445549964905,
      "learning_rate": 4.130795588392762e-05,
      "loss": 0.0945,
      "step": 16240
    },
    {
      "epoch": 1.740014990898383,
      "grad_norm": 0.47031348943710327,
      "learning_rate": 4.1302601991647935e-05,
      "loss": 0.1064,
      "step": 16250
    },
    {
      "epoch": 1.7410857693543207,
      "grad_norm": 0.12468145042657852,
      "learning_rate": 4.129724809936824e-05,
      "loss": 0.0912,
      "step": 16260
    },
    {
      "epoch": 1.742156547810258,
      "grad_norm": 0.14587698876857758,
      "learning_rate": 4.129189420708856e-05,
      "loss": 0.0754,
      "step": 16270
    },
    {
      "epoch": 1.7432273262661955,
      "grad_norm": 0.18504343926906586,
      "learning_rate": 4.128654031480887e-05,
      "loss": 0.0915,
      "step": 16280
    },
    {
      "epoch": 1.7442981047221329,
      "grad_norm": 0.21284042298793793,
      "learning_rate": 4.128118642252918e-05,
      "loss": 0.1006,
      "step": 16290
    },
    {
      "epoch": 1.7453688831780705,
      "grad_norm": 0.1500673145055771,
      "learning_rate": 4.127583253024949e-05,
      "loss": 0.0941,
      "step": 16300
    },
    {
      "epoch": 1.7464396616340079,
      "grad_norm": 0.136458620429039,
      "learning_rate": 4.1270478637969804e-05,
      "loss": 0.0887,
      "step": 16310
    },
    {
      "epoch": 1.7475104400899455,
      "grad_norm": 0.12074676901102066,
      "learning_rate": 4.126512474569012e-05,
      "loss": 0.0884,
      "step": 16320
    },
    {
      "epoch": 1.7485812185458829,
      "grad_norm": 0.13874012231826782,
      "learning_rate": 4.1259770853410427e-05,
      "loss": 0.0801,
      "step": 16330
    },
    {
      "epoch": 1.7496519970018203,
      "grad_norm": 0.24567145109176636,
      "learning_rate": 4.1254416961130745e-05,
      "loss": 0.1169,
      "step": 16340
    },
    {
      "epoch": 1.7507227754577577,
      "grad_norm": 0.14202246069908142,
      "learning_rate": 4.124959845807902e-05,
      "loss": 0.1014,
      "step": 16350
    },
    {
      "epoch": 1.7517935539136953,
      "grad_norm": 0.17584116756916046,
      "learning_rate": 4.124424456579934e-05,
      "loss": 0.0888,
      "step": 16360
    },
    {
      "epoch": 1.7528643323696327,
      "grad_norm": 0.21025538444519043,
      "learning_rate": 4.123889067351965e-05,
      "loss": 0.0875,
      "step": 16370
    },
    {
      "epoch": 1.7539351108255703,
      "grad_norm": 0.1415282040834427,
      "learning_rate": 4.1233536781239964e-05,
      "loss": 0.0979,
      "step": 16380
    },
    {
      "epoch": 1.7550058892815077,
      "grad_norm": 0.1727893054485321,
      "learning_rate": 4.1228182888960275e-05,
      "loss": 0.0753,
      "step": 16390
    },
    {
      "epoch": 1.756076667737445,
      "grad_norm": 0.1578141301870346,
      "learning_rate": 4.1222828996680594e-05,
      "loss": 0.0992,
      "step": 16400
    },
    {
      "epoch": 1.7571474461933825,
      "grad_norm": 0.14411678910255432,
      "learning_rate": 4.12174751044009e-05,
      "loss": 0.0796,
      "step": 16410
    },
    {
      "epoch": 1.75821822464932,
      "grad_norm": 0.14381784200668335,
      "learning_rate": 4.1212121212121216e-05,
      "loss": 0.0931,
      "step": 16420
    },
    {
      "epoch": 1.7592890031052575,
      "grad_norm": 0.22680561244487762,
      "learning_rate": 4.120676731984153e-05,
      "loss": 0.1084,
      "step": 16430
    },
    {
      "epoch": 1.760359781561195,
      "grad_norm": 0.14876201748847961,
      "learning_rate": 4.120141342756184e-05,
      "loss": 0.0904,
      "step": 16440
    },
    {
      "epoch": 1.7614305600171325,
      "grad_norm": 0.16378983855247498,
      "learning_rate": 4.119605953528215e-05,
      "loss": 0.0843,
      "step": 16450
    },
    {
      "epoch": 1.76250133847307,
      "grad_norm": 0.3253803551197052,
      "learning_rate": 4.119070564300246e-05,
      "loss": 0.0936,
      "step": 16460
    },
    {
      "epoch": 1.7635721169290073,
      "grad_norm": 0.11729244887828827,
      "learning_rate": 4.118535175072278e-05,
      "loss": 0.0956,
      "step": 16470
    },
    {
      "epoch": 1.764642895384945,
      "grad_norm": 0.13651488721370697,
      "learning_rate": 4.117999785844309e-05,
      "loss": 0.0902,
      "step": 16480
    },
    {
      "epoch": 1.7657136738408823,
      "grad_norm": 0.14879901707172394,
      "learning_rate": 4.11746439661634e-05,
      "loss": 0.0962,
      "step": 16490
    },
    {
      "epoch": 1.76678445229682,
      "grad_norm": 0.2209697812795639,
      "learning_rate": 4.1169290073883714e-05,
      "loss": 0.0909,
      "step": 16500
    },
    {
      "epoch": 1.7678552307527573,
      "grad_norm": 0.42447394132614136,
      "learning_rate": 4.116393618160403e-05,
      "loss": 0.0854,
      "step": 16510
    },
    {
      "epoch": 1.7689260092086947,
      "grad_norm": 0.2067011445760727,
      "learning_rate": 4.1158582289324344e-05,
      "loss": 0.0972,
      "step": 16520
    },
    {
      "epoch": 1.769996787664632,
      "grad_norm": 0.12744146585464478,
      "learning_rate": 4.1153228397044655e-05,
      "loss": 0.0835,
      "step": 16530
    },
    {
      "epoch": 1.7710675661205697,
      "grad_norm": 0.16409851610660553,
      "learning_rate": 4.114787450476497e-05,
      "loss": 0.0913,
      "step": 16540
    },
    {
      "epoch": 1.772138344576507,
      "grad_norm": 0.17131716012954712,
      "learning_rate": 4.114252061248528e-05,
      "loss": 0.0835,
      "step": 16550
    },
    {
      "epoch": 1.7732091230324447,
      "grad_norm": 0.14858019351959229,
      "learning_rate": 4.113716672020559e-05,
      "loss": 0.0839,
      "step": 16560
    },
    {
      "epoch": 1.774279901488382,
      "grad_norm": 0.1980951577425003,
      "learning_rate": 4.11318128279259e-05,
      "loss": 0.0978,
      "step": 16570
    },
    {
      "epoch": 1.7753506799443195,
      "grad_norm": 0.23332907259464264,
      "learning_rate": 4.112645893564622e-05,
      "loss": 0.1055,
      "step": 16580
    },
    {
      "epoch": 1.776421458400257,
      "grad_norm": 0.10590924322605133,
      "learning_rate": 4.112110504336653e-05,
      "loss": 0.0993,
      "step": 16590
    },
    {
      "epoch": 1.7774922368561945,
      "grad_norm": 0.11379160732030869,
      "learning_rate": 4.111575115108684e-05,
      "loss": 0.111,
      "step": 16600
    },
    {
      "epoch": 1.778563015312132,
      "grad_norm": 0.2497599869966507,
      "learning_rate": 4.111039725880715e-05,
      "loss": 0.1011,
      "step": 16610
    },
    {
      "epoch": 1.7796337937680695,
      "grad_norm": 0.13658316433429718,
      "learning_rate": 4.110504336652747e-05,
      "loss": 0.1,
      "step": 16620
    },
    {
      "epoch": 1.780704572224007,
      "grad_norm": 0.16755050420761108,
      "learning_rate": 4.109968947424778e-05,
      "loss": 0.0958,
      "step": 16630
    },
    {
      "epoch": 1.7817753506799443,
      "grad_norm": 0.13062965869903564,
      "learning_rate": 4.1094335581968094e-05,
      "loss": 0.0935,
      "step": 16640
    },
    {
      "epoch": 1.7828461291358817,
      "grad_norm": 0.17327560484409332,
      "learning_rate": 4.1088981689688406e-05,
      "loss": 0.0888,
      "step": 16650
    },
    {
      "epoch": 1.783916907591819,
      "grad_norm": 0.14022748172283173,
      "learning_rate": 4.108362779740872e-05,
      "loss": 0.0857,
      "step": 16660
    },
    {
      "epoch": 1.7849876860477567,
      "grad_norm": 0.16544851660728455,
      "learning_rate": 4.1078273905129035e-05,
      "loss": 0.0773,
      "step": 16670
    },
    {
      "epoch": 1.7860584645036943,
      "grad_norm": 0.1342487782239914,
      "learning_rate": 4.107292001284934e-05,
      "loss": 0.0959,
      "step": 16680
    },
    {
      "epoch": 1.7871292429596317,
      "grad_norm": 0.16219864785671234,
      "learning_rate": 4.106756612056966e-05,
      "loss": 0.095,
      "step": 16690
    },
    {
      "epoch": 1.788200021415569,
      "grad_norm": 0.19945377111434937,
      "learning_rate": 4.106221222828997e-05,
      "loss": 0.1021,
      "step": 16700
    },
    {
      "epoch": 1.7892707998715065,
      "grad_norm": 0.11957603693008423,
      "learning_rate": 4.105685833601028e-05,
      "loss": 0.0899,
      "step": 16710
    },
    {
      "epoch": 1.790341578327444,
      "grad_norm": 0.16481705009937286,
      "learning_rate": 4.105150444373059e-05,
      "loss": 0.1095,
      "step": 16720
    },
    {
      "epoch": 1.7914123567833815,
      "grad_norm": 0.2135908305644989,
      "learning_rate": 4.104615055145091e-05,
      "loss": 0.0847,
      "step": 16730
    },
    {
      "epoch": 1.7924831352393191,
      "grad_norm": 0.17181402444839478,
      "learning_rate": 4.104079665917122e-05,
      "loss": 0.0965,
      "step": 16740
    },
    {
      "epoch": 1.7935539136952565,
      "grad_norm": 0.2287931740283966,
      "learning_rate": 4.1035442766891526e-05,
      "loss": 0.107,
      "step": 16750
    },
    {
      "epoch": 1.794624692151194,
      "grad_norm": 0.1298820674419403,
      "learning_rate": 4.1030088874611845e-05,
      "loss": 0.0892,
      "step": 16760
    },
    {
      "epoch": 1.7956954706071313,
      "grad_norm": 0.12612397968769073,
      "learning_rate": 4.1024734982332156e-05,
      "loss": 0.0917,
      "step": 16770
    },
    {
      "epoch": 1.7967662490630687,
      "grad_norm": 0.1704288274049759,
      "learning_rate": 4.1019381090052474e-05,
      "loss": 0.0891,
      "step": 16780
    },
    {
      "epoch": 1.7978370275190063,
      "grad_norm": 0.15858274698257446,
      "learning_rate": 4.101402719777278e-05,
      "loss": 0.0849,
      "step": 16790
    },
    {
      "epoch": 1.798907805974944,
      "grad_norm": 0.1478080004453659,
      "learning_rate": 4.10086733054931e-05,
      "loss": 0.089,
      "step": 16800
    },
    {
      "epoch": 1.7999785844308813,
      "grad_norm": 0.12114845961332321,
      "learning_rate": 4.100331941321341e-05,
      "loss": 0.1155,
      "step": 16810
    },
    {
      "epoch": 1.8010493628868187,
      "grad_norm": 0.194199800491333,
      "learning_rate": 4.0997965520933727e-05,
      "loss": 0.1011,
      "step": 16820
    },
    {
      "epoch": 1.802120141342756,
      "grad_norm": 0.1665566861629486,
      "learning_rate": 4.099261162865403e-05,
      "loss": 0.0904,
      "step": 16830
    },
    {
      "epoch": 1.8031909197986935,
      "grad_norm": 0.1781318634748459,
      "learning_rate": 4.098725773637435e-05,
      "loss": 0.0844,
      "step": 16840
    },
    {
      "epoch": 1.8042616982546311,
      "grad_norm": 0.12932351231575012,
      "learning_rate": 4.098190384409466e-05,
      "loss": 0.0995,
      "step": 16850
    },
    {
      "epoch": 1.8053324767105687,
      "grad_norm": 0.12651501595973969,
      "learning_rate": 4.0976549951814965e-05,
      "loss": 0.0887,
      "step": 16860
    },
    {
      "epoch": 1.8064032551665061,
      "grad_norm": 0.12175820022821426,
      "learning_rate": 4.0971196059535284e-05,
      "loss": 0.109,
      "step": 16870
    },
    {
      "epoch": 1.8074740336224435,
      "grad_norm": 0.16537486016750336,
      "learning_rate": 4.0965842167255595e-05,
      "loss": 0.088,
      "step": 16880
    },
    {
      "epoch": 1.808544812078381,
      "grad_norm": 0.11546342819929123,
      "learning_rate": 4.096048827497591e-05,
      "loss": 0.1008,
      "step": 16890
    },
    {
      "epoch": 1.8096155905343183,
      "grad_norm": 0.20123036205768585,
      "learning_rate": 4.095513438269622e-05,
      "loss": 0.098,
      "step": 16900
    },
    {
      "epoch": 1.810686368990256,
      "grad_norm": 0.3276945948600769,
      "learning_rate": 4.0949780490416536e-05,
      "loss": 0.0777,
      "step": 16910
    },
    {
      "epoch": 1.8117571474461935,
      "grad_norm": 0.17874296009540558,
      "learning_rate": 4.094442659813685e-05,
      "loss": 0.0856,
      "step": 16920
    },
    {
      "epoch": 1.812827925902131,
      "grad_norm": 0.13050368428230286,
      "learning_rate": 4.0939072705857165e-05,
      "loss": 0.0802,
      "step": 16930
    },
    {
      "epoch": 1.8138987043580683,
      "grad_norm": 0.17042480409145355,
      "learning_rate": 4.093371881357747e-05,
      "loss": 0.0831,
      "step": 16940
    },
    {
      "epoch": 1.8149694828140057,
      "grad_norm": 0.16175653040409088,
      "learning_rate": 4.092836492129778e-05,
      "loss": 0.0976,
      "step": 16950
    },
    {
      "epoch": 1.8160402612699431,
      "grad_norm": 0.1896165907382965,
      "learning_rate": 4.09230110290181e-05,
      "loss": 0.0946,
      "step": 16960
    },
    {
      "epoch": 1.8171110397258807,
      "grad_norm": 0.20573410391807556,
      "learning_rate": 4.091765713673841e-05,
      "loss": 0.0877,
      "step": 16970
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.11566375195980072,
      "learning_rate": 4.091230324445872e-05,
      "loss": 0.086,
      "step": 16980
    },
    {
      "epoch": 1.8192525966377557,
      "grad_norm": 0.14263217151165009,
      "learning_rate": 4.0906949352179034e-05,
      "loss": 0.0973,
      "step": 16990
    },
    {
      "epoch": 1.8203233750936931,
      "grad_norm": 0.12054502964019775,
      "learning_rate": 4.090159545989935e-05,
      "loss": 0.0896,
      "step": 17000
    },
    {
      "epoch": 1.8213941535496305,
      "grad_norm": 0.18693353235721588,
      "learning_rate": 4.0896241567619663e-05,
      "loss": 0.1049,
      "step": 17010
    },
    {
      "epoch": 1.822464932005568,
      "grad_norm": 0.14097847044467926,
      "learning_rate": 4.0890887675339975e-05,
      "loss": 0.0984,
      "step": 17020
    },
    {
      "epoch": 1.8235357104615055,
      "grad_norm": 0.0952446237206459,
      "learning_rate": 4.0885533783060286e-05,
      "loss": 0.0757,
      "step": 17030
    },
    {
      "epoch": 1.824606488917443,
      "grad_norm": 0.23323525488376617,
      "learning_rate": 4.0880179890780604e-05,
      "loss": 0.0959,
      "step": 17040
    },
    {
      "epoch": 1.8256772673733805,
      "grad_norm": 0.14588651061058044,
      "learning_rate": 4.087482599850091e-05,
      "loss": 0.0939,
      "step": 17050
    },
    {
      "epoch": 1.826748045829318,
      "grad_norm": 0.16004568338394165,
      "learning_rate": 4.086947210622122e-05,
      "loss": 0.0936,
      "step": 17060
    },
    {
      "epoch": 1.8278188242852553,
      "grad_norm": 0.15780597925186157,
      "learning_rate": 4.086411821394154e-05,
      "loss": 0.0861,
      "step": 17070
    },
    {
      "epoch": 1.8288896027411927,
      "grad_norm": 0.1628347933292389,
      "learning_rate": 4.085876432166185e-05,
      "loss": 0.0942,
      "step": 17080
    },
    {
      "epoch": 1.8299603811971303,
      "grad_norm": 0.1575537919998169,
      "learning_rate": 4.085341042938216e-05,
      "loss": 0.0903,
      "step": 17090
    },
    {
      "epoch": 1.8310311596530677,
      "grad_norm": 0.18804079294204712,
      "learning_rate": 4.084805653710247e-05,
      "loss": 0.0893,
      "step": 17100
    },
    {
      "epoch": 1.8321019381090053,
      "grad_norm": 0.1386636346578598,
      "learning_rate": 4.084270264482279e-05,
      "loss": 0.0946,
      "step": 17110
    },
    {
      "epoch": 1.8331727165649427,
      "grad_norm": 0.11321459710597992,
      "learning_rate": 4.08373487525431e-05,
      "loss": 0.0925,
      "step": 17120
    },
    {
      "epoch": 1.8342434950208801,
      "grad_norm": 0.15506812930107117,
      "learning_rate": 4.0831994860263414e-05,
      "loss": 0.0922,
      "step": 17130
    },
    {
      "epoch": 1.8353142734768175,
      "grad_norm": 0.18475033342838287,
      "learning_rate": 4.0826640967983725e-05,
      "loss": 0.0983,
      "step": 17140
    },
    {
      "epoch": 1.8363850519327551,
      "grad_norm": 0.1393691450357437,
      "learning_rate": 4.082128707570404e-05,
      "loss": 0.0919,
      "step": 17150
    },
    {
      "epoch": 1.8374558303886925,
      "grad_norm": 0.17688211798667908,
      "learning_rate": 4.0815933183424355e-05,
      "loss": 0.079,
      "step": 17160
    },
    {
      "epoch": 1.8385266088446302,
      "grad_norm": 0.12065130472183228,
      "learning_rate": 4.081057929114466e-05,
      "loss": 0.0854,
      "step": 17170
    },
    {
      "epoch": 1.8395973873005675,
      "grad_norm": 0.11462162435054779,
      "learning_rate": 4.080522539886498e-05,
      "loss": 0.0796,
      "step": 17180
    },
    {
      "epoch": 1.840668165756505,
      "grad_norm": 0.1423584520816803,
      "learning_rate": 4.079987150658529e-05,
      "loss": 0.0895,
      "step": 17190
    },
    {
      "epoch": 1.8417389442124423,
      "grad_norm": 0.18317821621894836,
      "learning_rate": 4.07945176143056e-05,
      "loss": 0.0835,
      "step": 17200
    },
    {
      "epoch": 1.84280972266838,
      "grad_norm": 0.15913797914981842,
      "learning_rate": 4.078916372202591e-05,
      "loss": 0.0811,
      "step": 17210
    },
    {
      "epoch": 1.8438805011243173,
      "grad_norm": 0.10523267835378647,
      "learning_rate": 4.078380982974623e-05,
      "loss": 0.0898,
      "step": 17220
    },
    {
      "epoch": 1.844951279580255,
      "grad_norm": 0.12509028613567352,
      "learning_rate": 4.077845593746654e-05,
      "loss": 0.0859,
      "step": 17230
    },
    {
      "epoch": 1.8460220580361923,
      "grad_norm": 0.1809539496898651,
      "learning_rate": 4.077310204518685e-05,
      "loss": 0.1013,
      "step": 17240
    },
    {
      "epoch": 1.8470928364921297,
      "grad_norm": 0.1643579602241516,
      "learning_rate": 4.0767748152907164e-05,
      "loss": 0.09,
      "step": 17250
    },
    {
      "epoch": 1.8481636149480671,
      "grad_norm": 0.1959908902645111,
      "learning_rate": 4.0762394260627476e-05,
      "loss": 0.0874,
      "step": 17260
    },
    {
      "epoch": 1.8492343934040048,
      "grad_norm": 0.12703880667686462,
      "learning_rate": 4.0757040368347794e-05,
      "loss": 0.0977,
      "step": 17270
    },
    {
      "epoch": 1.8503051718599421,
      "grad_norm": 0.10299763828516006,
      "learning_rate": 4.07516864760681e-05,
      "loss": 0.0846,
      "step": 17280
    },
    {
      "epoch": 1.8513759503158798,
      "grad_norm": 0.14069896936416626,
      "learning_rate": 4.0746332583788417e-05,
      "loss": 0.1143,
      "step": 17290
    },
    {
      "epoch": 1.8524467287718172,
      "grad_norm": 0.14655111730098724,
      "learning_rate": 4.074097869150873e-05,
      "loss": 0.0844,
      "step": 17300
    },
    {
      "epoch": 1.8535175072277545,
      "grad_norm": 0.1153307631611824,
      "learning_rate": 4.0735624799229046e-05,
      "loss": 0.0901,
      "step": 17310
    },
    {
      "epoch": 1.854588285683692,
      "grad_norm": 0.2809578478336334,
      "learning_rate": 4.073027090694935e-05,
      "loss": 0.0989,
      "step": 17320
    },
    {
      "epoch": 1.8556590641396296,
      "grad_norm": 0.1395478993654251,
      "learning_rate": 4.072491701466967e-05,
      "loss": 0.0858,
      "step": 17330
    },
    {
      "epoch": 1.856729842595567,
      "grad_norm": 0.19759583473205566,
      "learning_rate": 4.071956312238998e-05,
      "loss": 0.0801,
      "step": 17340
    },
    {
      "epoch": 1.8578006210515046,
      "grad_norm": 0.15350909531116486,
      "learning_rate": 4.071420923011029e-05,
      "loss": 0.0877,
      "step": 17350
    },
    {
      "epoch": 1.858871399507442,
      "grad_norm": 0.13295532763004303,
      "learning_rate": 4.07088553378306e-05,
      "loss": 0.0825,
      "step": 17360
    },
    {
      "epoch": 1.8599421779633794,
      "grad_norm": 0.15183016657829285,
      "learning_rate": 4.0703501445550915e-05,
      "loss": 0.0934,
      "step": 17370
    },
    {
      "epoch": 1.8610129564193167,
      "grad_norm": 0.2177407592535019,
      "learning_rate": 4.069814755327123e-05,
      "loss": 0.1035,
      "step": 17380
    },
    {
      "epoch": 1.8620837348752544,
      "grad_norm": 0.2872498333454132,
      "learning_rate": 4.069279366099154e-05,
      "loss": 0.1014,
      "step": 17390
    },
    {
      "epoch": 1.8631545133311918,
      "grad_norm": 0.1770787537097931,
      "learning_rate": 4.0687439768711856e-05,
      "loss": 0.0897,
      "step": 17400
    },
    {
      "epoch": 1.8642252917871294,
      "grad_norm": 0.15549275279045105,
      "learning_rate": 4.068208587643217e-05,
      "loss": 0.0971,
      "step": 17410
    },
    {
      "epoch": 1.8652960702430668,
      "grad_norm": 0.16278474032878876,
      "learning_rate": 4.0676731984152485e-05,
      "loss": 0.0897,
      "step": 17420
    },
    {
      "epoch": 1.8663668486990042,
      "grad_norm": 0.16350296139717102,
      "learning_rate": 4.067137809187279e-05,
      "loss": 0.0881,
      "step": 17430
    },
    {
      "epoch": 1.8674376271549415,
      "grad_norm": 0.12305004894733429,
      "learning_rate": 4.066602419959311e-05,
      "loss": 0.0998,
      "step": 17440
    },
    {
      "epoch": 1.8685084056108792,
      "grad_norm": 0.2076214998960495,
      "learning_rate": 4.066067030731342e-05,
      "loss": 0.0849,
      "step": 17450
    },
    {
      "epoch": 1.8695791840668166,
      "grad_norm": 0.11959671974182129,
      "learning_rate": 4.065531641503373e-05,
      "loss": 0.0911,
      "step": 17460
    },
    {
      "epoch": 1.8706499625227542,
      "grad_norm": 0.1536821573972702,
      "learning_rate": 4.064996252275404e-05,
      "loss": 0.0973,
      "step": 17470
    },
    {
      "epoch": 1.8717207409786916,
      "grad_norm": 0.17286843061447144,
      "learning_rate": 4.0644608630474353e-05,
      "loss": 0.0891,
      "step": 17480
    },
    {
      "epoch": 1.872791519434629,
      "grad_norm": 0.229397714138031,
      "learning_rate": 4.063925473819467e-05,
      "loss": 0.0929,
      "step": 17490
    },
    {
      "epoch": 1.8738622978905664,
      "grad_norm": 0.11729216575622559,
      "learning_rate": 4.0633900845914976e-05,
      "loss": 0.0949,
      "step": 17500
    },
    {
      "epoch": 1.8749330763465037,
      "grad_norm": 0.17732465267181396,
      "learning_rate": 4.0628546953635294e-05,
      "loss": 0.1022,
      "step": 17510
    },
    {
      "epoch": 1.8760038548024414,
      "grad_norm": 0.10267657786607742,
      "learning_rate": 4.0623193061355606e-05,
      "loss": 0.1,
      "step": 17520
    },
    {
      "epoch": 1.877074633258379,
      "grad_norm": 0.18971426784992218,
      "learning_rate": 4.0617839169075924e-05,
      "loss": 0.0951,
      "step": 17530
    },
    {
      "epoch": 1.8781454117143164,
      "grad_norm": 0.1179940328001976,
      "learning_rate": 4.061248527679623e-05,
      "loss": 0.0901,
      "step": 17540
    },
    {
      "epoch": 1.8792161901702538,
      "grad_norm": 0.23229235410690308,
      "learning_rate": 4.060713138451655e-05,
      "loss": 0.092,
      "step": 17550
    },
    {
      "epoch": 1.8802869686261912,
      "grad_norm": 0.23306430876255035,
      "learning_rate": 4.060177749223686e-05,
      "loss": 0.0938,
      "step": 17560
    },
    {
      "epoch": 1.8813577470821286,
      "grad_norm": 0.1690579205751419,
      "learning_rate": 4.059642359995717e-05,
      "loss": 0.0827,
      "step": 17570
    },
    {
      "epoch": 1.8824285255380662,
      "grad_norm": 0.11817535012960434,
      "learning_rate": 4.059106970767748e-05,
      "loss": 0.0934,
      "step": 17580
    },
    {
      "epoch": 1.8834993039940038,
      "grad_norm": 0.2035944014787674,
      "learning_rate": 4.058571581539779e-05,
      "loss": 0.0998,
      "step": 17590
    },
    {
      "epoch": 1.8845700824499412,
      "grad_norm": 0.16652099788188934,
      "learning_rate": 4.058036192311811e-05,
      "loss": 0.1012,
      "step": 17600
    },
    {
      "epoch": 1.8856408609058786,
      "grad_norm": 0.1716744303703308,
      "learning_rate": 4.057500803083842e-05,
      "loss": 0.0966,
      "step": 17610
    },
    {
      "epoch": 1.886711639361816,
      "grad_norm": 0.2424224317073822,
      "learning_rate": 4.0569654138558733e-05,
      "loss": 0.1025,
      "step": 17620
    },
    {
      "epoch": 1.8877824178177534,
      "grad_norm": 0.1440139263868332,
      "learning_rate": 4.0564300246279045e-05,
      "loss": 0.0975,
      "step": 17630
    },
    {
      "epoch": 1.888853196273691,
      "grad_norm": 0.10277336835861206,
      "learning_rate": 4.055894635399936e-05,
      "loss": 0.079,
      "step": 17640
    },
    {
      "epoch": 1.8899239747296286,
      "grad_norm": 0.15317614376544952,
      "learning_rate": 4.055359246171967e-05,
      "loss": 0.0953,
      "step": 17650
    },
    {
      "epoch": 1.890994753185566,
      "grad_norm": 0.2476269155740738,
      "learning_rate": 4.0548238569439986e-05,
      "loss": 0.0951,
      "step": 17660
    },
    {
      "epoch": 1.8920655316415034,
      "grad_norm": 0.20054325461387634,
      "learning_rate": 4.05428846771603e-05,
      "loss": 0.0943,
      "step": 17670
    },
    {
      "epoch": 1.8931363100974408,
      "grad_norm": 0.16367207467556,
      "learning_rate": 4.053753078488061e-05,
      "loss": 0.0912,
      "step": 17680
    },
    {
      "epoch": 1.8942070885533782,
      "grad_norm": 0.2199513167142868,
      "learning_rate": 4.053217689260092e-05,
      "loss": 0.0849,
      "step": 17690
    },
    {
      "epoch": 1.8952778670093158,
      "grad_norm": 0.1861773133277893,
      "learning_rate": 4.052682300032123e-05,
      "loss": 0.0918,
      "step": 17700
    },
    {
      "epoch": 1.8963486454652534,
      "grad_norm": 0.1478831022977829,
      "learning_rate": 4.052146910804155e-05,
      "loss": 0.1006,
      "step": 17710
    },
    {
      "epoch": 1.8974194239211908,
      "grad_norm": 0.1571885496377945,
      "learning_rate": 4.051611521576186e-05,
      "loss": 0.0861,
      "step": 17720
    },
    {
      "epoch": 1.8984902023771282,
      "grad_norm": 0.14515569806098938,
      "learning_rate": 4.051076132348217e-05,
      "loss": 0.098,
      "step": 17730
    },
    {
      "epoch": 1.8995609808330656,
      "grad_norm": 0.313864141702652,
      "learning_rate": 4.0505407431202484e-05,
      "loss": 0.0994,
      "step": 17740
    },
    {
      "epoch": 1.900631759289003,
      "grad_norm": 0.2995030879974365,
      "learning_rate": 4.05000535389228e-05,
      "loss": 0.0996,
      "step": 17750
    },
    {
      "epoch": 1.9017025377449406,
      "grad_norm": 0.15263740718364716,
      "learning_rate": 4.049469964664311e-05,
      "loss": 0.0896,
      "step": 17760
    },
    {
      "epoch": 1.9027733162008782,
      "grad_norm": 0.12369494885206223,
      "learning_rate": 4.0489345754363425e-05,
      "loss": 0.0897,
      "step": 17770
    },
    {
      "epoch": 1.9038440946568156,
      "grad_norm": 0.13372178375720978,
      "learning_rate": 4.0483991862083736e-05,
      "loss": 0.0862,
      "step": 17780
    },
    {
      "epoch": 1.904914873112753,
      "grad_norm": 0.16085852682590485,
      "learning_rate": 4.047863796980405e-05,
      "loss": 0.0925,
      "step": 17790
    },
    {
      "epoch": 1.9059856515686904,
      "grad_norm": 0.10055936127901077,
      "learning_rate": 4.0473284077524366e-05,
      "loss": 0.0865,
      "step": 17800
    },
    {
      "epoch": 1.9070564300246278,
      "grad_norm": 0.11097793281078339,
      "learning_rate": 4.046793018524467e-05,
      "loss": 0.0816,
      "step": 17810
    },
    {
      "epoch": 1.9081272084805654,
      "grad_norm": 0.21455435454845428,
      "learning_rate": 4.046257629296499e-05,
      "loss": 0.1006,
      "step": 17820
    },
    {
      "epoch": 1.909197986936503,
      "grad_norm": 0.14179149270057678,
      "learning_rate": 4.04572224006853e-05,
      "loss": 0.0972,
      "step": 17830
    },
    {
      "epoch": 1.9102687653924404,
      "grad_norm": 0.14349181950092316,
      "learning_rate": 4.045186850840561e-05,
      "loss": 0.0982,
      "step": 17840
    },
    {
      "epoch": 1.9113395438483778,
      "grad_norm": 0.13308383524417877,
      "learning_rate": 4.044651461612592e-05,
      "loss": 0.0913,
      "step": 17850
    },
    {
      "epoch": 1.9124103223043152,
      "grad_norm": 0.11382082849740982,
      "learning_rate": 4.044116072384624e-05,
      "loss": 0.0843,
      "step": 17860
    },
    {
      "epoch": 1.9134811007602526,
      "grad_norm": 0.1254560351371765,
      "learning_rate": 4.043580683156655e-05,
      "loss": 0.0951,
      "step": 17870
    },
    {
      "epoch": 1.9145518792161902,
      "grad_norm": 0.09787063300609589,
      "learning_rate": 4.0430452939286864e-05,
      "loss": 0.0936,
      "step": 17880
    },
    {
      "epoch": 1.9156226576721276,
      "grad_norm": 0.1649751514196396,
      "learning_rate": 4.0425099047007175e-05,
      "loss": 0.0892,
      "step": 17890
    },
    {
      "epoch": 1.9166934361280652,
      "grad_norm": 0.14327263832092285,
      "learning_rate": 4.0419745154727486e-05,
      "loss": 0.0971,
      "step": 17900
    },
    {
      "epoch": 1.9177642145840026,
      "grad_norm": 0.1476965993642807,
      "learning_rate": 4.0414391262447805e-05,
      "loss": 0.0902,
      "step": 17910
    },
    {
      "epoch": 1.91883499303994,
      "grad_norm": 0.22849909961223602,
      "learning_rate": 4.040903737016811e-05,
      "loss": 0.0974,
      "step": 17920
    },
    {
      "epoch": 1.9199057714958774,
      "grad_norm": 0.1506723016500473,
      "learning_rate": 4.040368347788843e-05,
      "loss": 0.094,
      "step": 17930
    },
    {
      "epoch": 1.920976549951815,
      "grad_norm": 0.14363810420036316,
      "learning_rate": 4.039832958560874e-05,
      "loss": 0.0953,
      "step": 17940
    },
    {
      "epoch": 1.9220473284077524,
      "grad_norm": 0.37329214811325073,
      "learning_rate": 4.039297569332906e-05,
      "loss": 0.086,
      "step": 17950
    },
    {
      "epoch": 1.92311810686369,
      "grad_norm": 0.10706903785467148,
      "learning_rate": 4.038762180104936e-05,
      "loss": 0.1032,
      "step": 17960
    },
    {
      "epoch": 1.9241888853196274,
      "grad_norm": 0.13320371508598328,
      "learning_rate": 4.038226790876968e-05,
      "loss": 0.0948,
      "step": 17970
    },
    {
      "epoch": 1.9252596637755648,
      "grad_norm": 0.1874115914106369,
      "learning_rate": 4.037691401648999e-05,
      "loss": 0.0952,
      "step": 17980
    },
    {
      "epoch": 1.9263304422315022,
      "grad_norm": 0.14492516219615936,
      "learning_rate": 4.03715601242103e-05,
      "loss": 0.0878,
      "step": 17990
    },
    {
      "epoch": 1.9274012206874398,
      "grad_norm": 0.1492931991815567,
      "learning_rate": 4.0366206231930614e-05,
      "loss": 0.0928,
      "step": 18000
    },
    {
      "epoch": 1.9284719991433772,
      "grad_norm": 0.1382492184638977,
      "learning_rate": 4.0360852339650925e-05,
      "loss": 0.0847,
      "step": 18010
    },
    {
      "epoch": 1.9295427775993148,
      "grad_norm": 0.12153331935405731,
      "learning_rate": 4.0355498447371244e-05,
      "loss": 0.094,
      "step": 18020
    },
    {
      "epoch": 1.9306135560552522,
      "grad_norm": 0.15329596400260925,
      "learning_rate": 4.035014455509155e-05,
      "loss": 0.0853,
      "step": 18030
    },
    {
      "epoch": 1.9316843345111896,
      "grad_norm": 0.14664559066295624,
      "learning_rate": 4.0344790662811866e-05,
      "loss": 0.0966,
      "step": 18040
    },
    {
      "epoch": 1.932755112967127,
      "grad_norm": 0.12102165073156357,
      "learning_rate": 4.033943677053218e-05,
      "loss": 0.0943,
      "step": 18050
    },
    {
      "epoch": 1.9338258914230646,
      "grad_norm": 0.18480797111988068,
      "learning_rate": 4.0334082878252496e-05,
      "loss": 0.0915,
      "step": 18060
    },
    {
      "epoch": 1.934896669879002,
      "grad_norm": 0.21314658224582672,
      "learning_rate": 4.03287289859728e-05,
      "loss": 0.0988,
      "step": 18070
    },
    {
      "epoch": 1.9359674483349396,
      "grad_norm": 0.5566141605377197,
      "learning_rate": 4.032337509369312e-05,
      "loss": 0.0841,
      "step": 18080
    },
    {
      "epoch": 1.937038226790877,
      "grad_norm": 0.13667531311511993,
      "learning_rate": 4.031802120141343e-05,
      "loss": 0.074,
      "step": 18090
    },
    {
      "epoch": 1.9381090052468144,
      "grad_norm": 0.32827842235565186,
      "learning_rate": 4.031266730913374e-05,
      "loss": 0.1052,
      "step": 18100
    },
    {
      "epoch": 1.9391797837027518,
      "grad_norm": 0.14027725160121918,
      "learning_rate": 4.030731341685405e-05,
      "loss": 0.0887,
      "step": 18110
    },
    {
      "epoch": 1.9402505621586894,
      "grad_norm": 0.16470228135585785,
      "learning_rate": 4.0301959524574364e-05,
      "loss": 0.0923,
      "step": 18120
    },
    {
      "epoch": 1.9413213406146268,
      "grad_norm": 0.1705564707517624,
      "learning_rate": 4.029660563229468e-05,
      "loss": 0.0961,
      "step": 18130
    },
    {
      "epoch": 1.9423921190705644,
      "grad_norm": 0.18734873831272125,
      "learning_rate": 4.029125174001499e-05,
      "loss": 0.0959,
      "step": 18140
    },
    {
      "epoch": 1.9434628975265018,
      "grad_norm": 0.14857016503810883,
      "learning_rate": 4.0285897847735305e-05,
      "loss": 0.1029,
      "step": 18150
    },
    {
      "epoch": 1.9445336759824392,
      "grad_norm": 0.2190334051847458,
      "learning_rate": 4.028054395545562e-05,
      "loss": 0.0944,
      "step": 18160
    },
    {
      "epoch": 1.9456044544383766,
      "grad_norm": 0.22139789164066315,
      "learning_rate": 4.0275190063175935e-05,
      "loss": 0.0963,
      "step": 18170
    },
    {
      "epoch": 1.9466752328943142,
      "grad_norm": 0.23698174953460693,
      "learning_rate": 4.026983617089624e-05,
      "loss": 0.097,
      "step": 18180
    },
    {
      "epoch": 1.9477460113502516,
      "grad_norm": 0.2131853550672531,
      "learning_rate": 4.026448227861656e-05,
      "loss": 0.1142,
      "step": 18190
    },
    {
      "epoch": 1.9488167898061892,
      "grad_norm": 0.1281685084104538,
      "learning_rate": 4.025912838633687e-05,
      "loss": 0.0883,
      "step": 18200
    },
    {
      "epoch": 1.9498875682621266,
      "grad_norm": 0.09722971171140671,
      "learning_rate": 4.025377449405718e-05,
      "loss": 0.1003,
      "step": 18210
    },
    {
      "epoch": 1.950958346718064,
      "grad_norm": 0.14899158477783203,
      "learning_rate": 4.024842060177749e-05,
      "loss": 0.086,
      "step": 18220
    },
    {
      "epoch": 1.9520291251740014,
      "grad_norm": 0.2394581437110901,
      "learning_rate": 4.02430667094978e-05,
      "loss": 0.0877,
      "step": 18230
    },
    {
      "epoch": 1.953099903629939,
      "grad_norm": 0.30690106749534607,
      "learning_rate": 4.023771281721812e-05,
      "loss": 0.0872,
      "step": 18240
    },
    {
      "epoch": 1.9541706820858764,
      "grad_norm": 0.1282302737236023,
      "learning_rate": 4.023235892493843e-05,
      "loss": 0.0771,
      "step": 18250
    },
    {
      "epoch": 1.955241460541814,
      "grad_norm": 0.19515596330165863,
      "learning_rate": 4.0227005032658744e-05,
      "loss": 0.09,
      "step": 18260
    },
    {
      "epoch": 1.9563122389977514,
      "grad_norm": 0.16943441331386566,
      "learning_rate": 4.0221651140379056e-05,
      "loss": 0.0967,
      "step": 18270
    },
    {
      "epoch": 1.9573830174536888,
      "grad_norm": 0.23079892992973328,
      "learning_rate": 4.0216297248099374e-05,
      "loss": 0.0871,
      "step": 18280
    },
    {
      "epoch": 1.9584537959096262,
      "grad_norm": 0.12359828501939774,
      "learning_rate": 4.021094335581968e-05,
      "loss": 0.078,
      "step": 18290
    },
    {
      "epoch": 1.9595245743655636,
      "grad_norm": 0.11846152693033218,
      "learning_rate": 4.020558946354e-05,
      "loss": 0.0933,
      "step": 18300
    },
    {
      "epoch": 1.9605953528215012,
      "grad_norm": 0.14508327841758728,
      "learning_rate": 4.020023557126031e-05,
      "loss": 0.0921,
      "step": 18310
    },
    {
      "epoch": 1.9616661312774388,
      "grad_norm": 0.13401895761489868,
      "learning_rate": 4.019488167898062e-05,
      "loss": 0.088,
      "step": 18320
    },
    {
      "epoch": 1.9627369097333762,
      "grad_norm": 0.16448305547237396,
      "learning_rate": 4.018952778670093e-05,
      "loss": 0.0897,
      "step": 18330
    },
    {
      "epoch": 1.9638076881893136,
      "grad_norm": 0.11151743680238724,
      "learning_rate": 4.018417389442124e-05,
      "loss": 0.089,
      "step": 18340
    },
    {
      "epoch": 1.964878466645251,
      "grad_norm": 0.1327461451292038,
      "learning_rate": 4.017882000214156e-05,
      "loss": 0.0885,
      "step": 18350
    },
    {
      "epoch": 1.9659492451011884,
      "grad_norm": 0.16163340210914612,
      "learning_rate": 4.017346610986187e-05,
      "loss": 0.0928,
      "step": 18360
    },
    {
      "epoch": 1.967020023557126,
      "grad_norm": 0.22654132544994354,
      "learning_rate": 4.016864760681015e-05,
      "loss": 0.0911,
      "step": 18370
    },
    {
      "epoch": 1.9680908020130636,
      "grad_norm": 0.11008047312498093,
      "learning_rate": 4.016329371453046e-05,
      "loss": 0.0895,
      "step": 18380
    },
    {
      "epoch": 1.969161580469001,
      "grad_norm": 0.13920950889587402,
      "learning_rate": 4.015793982225078e-05,
      "loss": 0.0895,
      "step": 18390
    },
    {
      "epoch": 1.9702323589249384,
      "grad_norm": 0.15040166676044464,
      "learning_rate": 4.015258592997109e-05,
      "loss": 0.0834,
      "step": 18400
    },
    {
      "epoch": 1.9713031373808758,
      "grad_norm": 0.1986975520849228,
      "learning_rate": 4.01472320376914e-05,
      "loss": 0.0955,
      "step": 18410
    },
    {
      "epoch": 1.9723739158368132,
      "grad_norm": 0.1549229472875595,
      "learning_rate": 4.0141878145411714e-05,
      "loss": 0.0956,
      "step": 18420
    },
    {
      "epoch": 1.9734446942927508,
      "grad_norm": 0.2474711835384369,
      "learning_rate": 4.013652425313203e-05,
      "loss": 0.0823,
      "step": 18430
    },
    {
      "epoch": 1.9745154727486884,
      "grad_norm": 0.15297044813632965,
      "learning_rate": 4.0131170360852343e-05,
      "loss": 0.0834,
      "step": 18440
    },
    {
      "epoch": 1.9755862512046258,
      "grad_norm": 0.16794663667678833,
      "learning_rate": 4.0125816468572655e-05,
      "loss": 0.0886,
      "step": 18450
    },
    {
      "epoch": 1.9766570296605632,
      "grad_norm": 0.18521206080913544,
      "learning_rate": 4.0120462576292966e-05,
      "loss": 0.0845,
      "step": 18460
    },
    {
      "epoch": 1.9777278081165006,
      "grad_norm": 0.3292541205883026,
      "learning_rate": 4.011510868401328e-05,
      "loss": 0.0903,
      "step": 18470
    },
    {
      "epoch": 1.978798586572438,
      "grad_norm": 0.15998463332653046,
      "learning_rate": 4.0109754791733596e-05,
      "loss": 0.081,
      "step": 18480
    },
    {
      "epoch": 1.9798693650283756,
      "grad_norm": 0.17733345925807953,
      "learning_rate": 4.01044008994539e-05,
      "loss": 0.0909,
      "step": 18490
    },
    {
      "epoch": 1.9809401434843132,
      "grad_norm": 0.14806193113327026,
      "learning_rate": 4.009904700717422e-05,
      "loss": 0.0853,
      "step": 18500
    },
    {
      "epoch": 1.9820109219402506,
      "grad_norm": 0.1745268553495407,
      "learning_rate": 4.009369311489453e-05,
      "loss": 0.0864,
      "step": 18510
    },
    {
      "epoch": 1.983081700396188,
      "grad_norm": 0.19758066534996033,
      "learning_rate": 4.008833922261484e-05,
      "loss": 0.0958,
      "step": 18520
    },
    {
      "epoch": 1.9841524788521254,
      "grad_norm": 0.20692968368530273,
      "learning_rate": 4.008298533033515e-05,
      "loss": 0.095,
      "step": 18530
    },
    {
      "epoch": 1.9852232573080628,
      "grad_norm": 0.16714178025722504,
      "learning_rate": 4.007763143805547e-05,
      "loss": 0.0971,
      "step": 18540
    },
    {
      "epoch": 1.9862940357640004,
      "grad_norm": 0.19684185087680817,
      "learning_rate": 4.007227754577578e-05,
      "loss": 0.0841,
      "step": 18550
    },
    {
      "epoch": 1.987364814219938,
      "grad_norm": 0.16625964641571045,
      "learning_rate": 4.0066923653496094e-05,
      "loss": 0.0994,
      "step": 18560
    },
    {
      "epoch": 1.9884355926758754,
      "grad_norm": 0.4072137773036957,
      "learning_rate": 4.0061569761216405e-05,
      "loss": 0.0882,
      "step": 18570
    },
    {
      "epoch": 1.9895063711318128,
      "grad_norm": 0.3552267849445343,
      "learning_rate": 4.005621586893672e-05,
      "loss": 0.0922,
      "step": 18580
    },
    {
      "epoch": 1.9905771495877502,
      "grad_norm": 0.1715514063835144,
      "learning_rate": 4.0050861976657035e-05,
      "loss": 0.085,
      "step": 18590
    },
    {
      "epoch": 1.9916479280436876,
      "grad_norm": 0.24035300314426422,
      "learning_rate": 4.004550808437734e-05,
      "loss": 0.0877,
      "step": 18600
    },
    {
      "epoch": 1.9927187064996252,
      "grad_norm": 0.2723899781703949,
      "learning_rate": 4.004015419209766e-05,
      "loss": 0.0985,
      "step": 18610
    },
    {
      "epoch": 1.9937894849555629,
      "grad_norm": 0.13133475184440613,
      "learning_rate": 4.003480029981797e-05,
      "loss": 0.0917,
      "step": 18620
    },
    {
      "epoch": 1.9948602634115002,
      "grad_norm": 0.21597786247730255,
      "learning_rate": 4.002944640753829e-05,
      "loss": 0.0891,
      "step": 18630
    },
    {
      "epoch": 1.9959310418674376,
      "grad_norm": 0.13489624857902527,
      "learning_rate": 4.002409251525859e-05,
      "loss": 0.0914,
      "step": 18640
    },
    {
      "epoch": 1.997001820323375,
      "grad_norm": 0.1935008317232132,
      "learning_rate": 4.001873862297891e-05,
      "loss": 0.0924,
      "step": 18650
    },
    {
      "epoch": 1.9980725987793124,
      "grad_norm": 0.1363057792186737,
      "learning_rate": 4.001338473069922e-05,
      "loss": 0.1029,
      "step": 18660
    },
    {
      "epoch": 1.99914337723525,
      "grad_norm": 0.16471396386623383,
      "learning_rate": 4.000803083841953e-05,
      "loss": 0.0959,
      "step": 18670
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.07195912301540375,
      "eval_runtime": 140.6044,
      "eval_samples_per_second": 59.045,
      "eval_steps_per_second": 7.382,
      "step": 18678
    },
    {
      "epoch": 2.0002141556911877,
      "grad_norm": 0.20148468017578125,
      "learning_rate": 4.0002676946139844e-05,
      "loss": 0.0885,
      "step": 18680
    },
    {
      "epoch": 2.001284934147125,
      "grad_norm": 0.18550097942352295,
      "learning_rate": 3.9997323053860156e-05,
      "loss": 0.0797,
      "step": 18690
    },
    {
      "epoch": 2.0023557126030624,
      "grad_norm": 0.2274167686700821,
      "learning_rate": 3.9991969161580474e-05,
      "loss": 0.088,
      "step": 18700
    },
    {
      "epoch": 2.003426491059,
      "grad_norm": 0.20548199117183685,
      "learning_rate": 3.998661526930078e-05,
      "loss": 0.0901,
      "step": 18710
    },
    {
      "epoch": 2.0044972695149372,
      "grad_norm": 0.15342067182064056,
      "learning_rate": 3.9981261377021097e-05,
      "loss": 0.1052,
      "step": 18720
    },
    {
      "epoch": 2.0055680479708746,
      "grad_norm": 0.1521022915840149,
      "learning_rate": 3.997590748474141e-05,
      "loss": 0.0861,
      "step": 18730
    },
    {
      "epoch": 2.0066388264268125,
      "grad_norm": 0.19389508664608002,
      "learning_rate": 3.9970553592461726e-05,
      "loss": 0.0771,
      "step": 18740
    },
    {
      "epoch": 2.00770960488275,
      "grad_norm": 0.3270166516304016,
      "learning_rate": 3.996519970018203e-05,
      "loss": 0.0878,
      "step": 18750
    },
    {
      "epoch": 2.0087803833386872,
      "grad_norm": 0.11166536808013916,
      "learning_rate": 3.995984580790235e-05,
      "loss": 0.0929,
      "step": 18760
    },
    {
      "epoch": 2.0098511617946246,
      "grad_norm": 0.09528002142906189,
      "learning_rate": 3.995449191562266e-05,
      "loss": 0.0832,
      "step": 18770
    },
    {
      "epoch": 2.010921940250562,
      "grad_norm": 0.16385811567306519,
      "learning_rate": 3.994913802334297e-05,
      "loss": 0.0987,
      "step": 18780
    },
    {
      "epoch": 2.0119927187064994,
      "grad_norm": 0.17681077122688293,
      "learning_rate": 3.994378413106328e-05,
      "loss": 0.0912,
      "step": 18790
    },
    {
      "epoch": 2.0130634971624373,
      "grad_norm": 0.21150051057338715,
      "learning_rate": 3.9938430238783595e-05,
      "loss": 0.0931,
      "step": 18800
    },
    {
      "epoch": 2.0141342756183747,
      "grad_norm": 0.46744632720947266,
      "learning_rate": 3.993307634650391e-05,
      "loss": 0.0987,
      "step": 18810
    },
    {
      "epoch": 2.015205054074312,
      "grad_norm": 0.1336784064769745,
      "learning_rate": 3.9927722454224224e-05,
      "loss": 0.0801,
      "step": 18820
    },
    {
      "epoch": 2.0162758325302494,
      "grad_norm": 0.1343245506286621,
      "learning_rate": 3.9922368561944536e-05,
      "loss": 0.1012,
      "step": 18830
    },
    {
      "epoch": 2.017346610986187,
      "grad_norm": 0.2789468467235565,
      "learning_rate": 3.991701466966485e-05,
      "loss": 0.0853,
      "step": 18840
    },
    {
      "epoch": 2.0184173894421242,
      "grad_norm": 0.12597019970417023,
      "learning_rate": 3.9911660777385165e-05,
      "loss": 0.091,
      "step": 18850
    },
    {
      "epoch": 2.019488167898062,
      "grad_norm": 0.20749329030513763,
      "learning_rate": 3.990630688510547e-05,
      "loss": 0.075,
      "step": 18860
    },
    {
      "epoch": 2.0205589463539995,
      "grad_norm": 0.42001429200172424,
      "learning_rate": 3.990095299282579e-05,
      "loss": 0.0844,
      "step": 18870
    },
    {
      "epoch": 2.021629724809937,
      "grad_norm": 0.21221596002578735,
      "learning_rate": 3.98955991005461e-05,
      "loss": 0.0897,
      "step": 18880
    },
    {
      "epoch": 2.0227005032658743,
      "grad_norm": 0.2399488389492035,
      "learning_rate": 3.989024520826641e-05,
      "loss": 0.0893,
      "step": 18890
    },
    {
      "epoch": 2.0237712817218116,
      "grad_norm": 0.13083548843860626,
      "learning_rate": 3.988489131598672e-05,
      "loss": 0.0901,
      "step": 18900
    },
    {
      "epoch": 2.024842060177749,
      "grad_norm": 0.1400938630104065,
      "learning_rate": 3.9879537423707033e-05,
      "loss": 0.0802,
      "step": 18910
    },
    {
      "epoch": 2.025912838633687,
      "grad_norm": 0.1761927455663681,
      "learning_rate": 3.987418353142735e-05,
      "loss": 0.0946,
      "step": 18920
    },
    {
      "epoch": 2.0269836170896243,
      "grad_norm": 0.24000491201877594,
      "learning_rate": 3.986882963914766e-05,
      "loss": 0.0888,
      "step": 18930
    },
    {
      "epoch": 2.0280543955455617,
      "grad_norm": 0.14024028182029724,
      "learning_rate": 3.9863475746867974e-05,
      "loss": 0.1065,
      "step": 18940
    },
    {
      "epoch": 2.029125174001499,
      "grad_norm": 0.21820570528507233,
      "learning_rate": 3.9858121854588286e-05,
      "loss": 0.0844,
      "step": 18950
    },
    {
      "epoch": 2.0301959524574364,
      "grad_norm": 0.13094265758991241,
      "learning_rate": 3.9852767962308604e-05,
      "loss": 0.0989,
      "step": 18960
    },
    {
      "epoch": 2.031266730913374,
      "grad_norm": 0.1993454396724701,
      "learning_rate": 3.9847414070028915e-05,
      "loss": 0.1029,
      "step": 18970
    },
    {
      "epoch": 2.0323375093693117,
      "grad_norm": 0.1501304805278778,
      "learning_rate": 3.984206017774923e-05,
      "loss": 0.0975,
      "step": 18980
    },
    {
      "epoch": 2.033408287825249,
      "grad_norm": 0.11551034450531006,
      "learning_rate": 3.983670628546954e-05,
      "loss": 0.0918,
      "step": 18990
    },
    {
      "epoch": 2.0344790662811865,
      "grad_norm": 0.13983319699764252,
      "learning_rate": 3.983135239318985e-05,
      "loss": 0.0927,
      "step": 19000
    },
    {
      "epoch": 2.035549844737124,
      "grad_norm": 0.23460690677165985,
      "learning_rate": 3.982599850091016e-05,
      "loss": 0.0978,
      "step": 19010
    },
    {
      "epoch": 2.0366206231930613,
      "grad_norm": 0.30739468336105347,
      "learning_rate": 3.982064460863047e-05,
      "loss": 0.0915,
      "step": 19020
    },
    {
      "epoch": 2.0376914016489986,
      "grad_norm": 0.4126671254634857,
      "learning_rate": 3.981529071635079e-05,
      "loss": 0.0814,
      "step": 19030
    },
    {
      "epoch": 2.0387621801049365,
      "grad_norm": 0.15958473086357117,
      "learning_rate": 3.98099368240711e-05,
      "loss": 0.0915,
      "step": 19040
    },
    {
      "epoch": 2.039832958560874,
      "grad_norm": 0.1872277855873108,
      "learning_rate": 3.9804582931791413e-05,
      "loss": 0.0826,
      "step": 19050
    },
    {
      "epoch": 2.0409037370168113,
      "grad_norm": 0.19317282736301422,
      "learning_rate": 3.9799229039511725e-05,
      "loss": 0.0919,
      "step": 19060
    },
    {
      "epoch": 2.0419745154727487,
      "grad_norm": 0.1363508105278015,
      "learning_rate": 3.979387514723204e-05,
      "loss": 0.0809,
      "step": 19070
    },
    {
      "epoch": 2.043045293928686,
      "grad_norm": 0.13320864737033844,
      "learning_rate": 3.9788521254952354e-05,
      "loss": 0.0856,
      "step": 19080
    },
    {
      "epoch": 2.0441160723846235,
      "grad_norm": 0.20667116343975067,
      "learning_rate": 3.9783167362672666e-05,
      "loss": 0.0926,
      "step": 19090
    },
    {
      "epoch": 2.0451868508405613,
      "grad_norm": 0.11707678437232971,
      "learning_rate": 3.977781347039298e-05,
      "loss": 0.0784,
      "step": 19100
    },
    {
      "epoch": 2.0462576292964987,
      "grad_norm": 0.1641087681055069,
      "learning_rate": 3.977245957811329e-05,
      "loss": 0.0892,
      "step": 19110
    },
    {
      "epoch": 2.047328407752436,
      "grad_norm": 0.17639756202697754,
      "learning_rate": 3.976710568583361e-05,
      "loss": 0.0843,
      "step": 19120
    },
    {
      "epoch": 2.0483991862083735,
      "grad_norm": 0.14151479303836823,
      "learning_rate": 3.976175179355391e-05,
      "loss": 0.092,
      "step": 19130
    },
    {
      "epoch": 2.049469964664311,
      "grad_norm": 0.20626556873321533,
      "learning_rate": 3.975639790127423e-05,
      "loss": 0.1012,
      "step": 19140
    },
    {
      "epoch": 2.0505407431202483,
      "grad_norm": 0.18465769290924072,
      "learning_rate": 3.975104400899454e-05,
      "loss": 0.0913,
      "step": 19150
    },
    {
      "epoch": 2.051611521576186,
      "grad_norm": 0.18921247124671936,
      "learning_rate": 3.974569011671485e-05,
      "loss": 0.0978,
      "step": 19160
    },
    {
      "epoch": 2.0526823000321235,
      "grad_norm": 0.14867161214351654,
      "learning_rate": 3.9740336224435164e-05,
      "loss": 0.0889,
      "step": 19170
    },
    {
      "epoch": 2.053753078488061,
      "grad_norm": 0.12204901874065399,
      "learning_rate": 3.973498233215548e-05,
      "loss": 0.0777,
      "step": 19180
    },
    {
      "epoch": 2.0548238569439983,
      "grad_norm": 0.43881702423095703,
      "learning_rate": 3.972962843987579e-05,
      "loss": 0.0793,
      "step": 19190
    },
    {
      "epoch": 2.0558946353999357,
      "grad_norm": 0.18233658373355865,
      "learning_rate": 3.9724274547596105e-05,
      "loss": 0.0889,
      "step": 19200
    },
    {
      "epoch": 2.056965413855873,
      "grad_norm": 0.19786274433135986,
      "learning_rate": 3.9718920655316416e-05,
      "loss": 0.0864,
      "step": 19210
    },
    {
      "epoch": 2.058036192311811,
      "grad_norm": 0.15381386876106262,
      "learning_rate": 3.971356676303673e-05,
      "loss": 0.0986,
      "step": 19220
    },
    {
      "epoch": 2.0591069707677483,
      "grad_norm": 0.16159135103225708,
      "learning_rate": 3.9708212870757046e-05,
      "loss": 0.0863,
      "step": 19230
    },
    {
      "epoch": 2.0601777492236857,
      "grad_norm": 0.14627927541732788,
      "learning_rate": 3.970285897847735e-05,
      "loss": 0.0717,
      "step": 19240
    },
    {
      "epoch": 2.061248527679623,
      "grad_norm": 0.20551913976669312,
      "learning_rate": 3.969750508619767e-05,
      "loss": 0.0952,
      "step": 19250
    },
    {
      "epoch": 2.0623193061355605,
      "grad_norm": 0.16769623756408691,
      "learning_rate": 3.969215119391798e-05,
      "loss": 0.0909,
      "step": 19260
    },
    {
      "epoch": 2.063390084591498,
      "grad_norm": 0.12128481268882751,
      "learning_rate": 3.96867973016383e-05,
      "loss": 0.0707,
      "step": 19270
    },
    {
      "epoch": 2.0644608630474357,
      "grad_norm": 0.13736937940120697,
      "learning_rate": 3.96814434093586e-05,
      "loss": 0.0833,
      "step": 19280
    },
    {
      "epoch": 2.065531641503373,
      "grad_norm": 0.1328035145998001,
      "learning_rate": 3.967608951707892e-05,
      "loss": 0.0855,
      "step": 19290
    },
    {
      "epoch": 2.0666024199593105,
      "grad_norm": 0.17236542701721191,
      "learning_rate": 3.967073562479923e-05,
      "loss": 0.087,
      "step": 19300
    },
    {
      "epoch": 2.067673198415248,
      "grad_norm": 0.1679021418094635,
      "learning_rate": 3.9665381732519544e-05,
      "loss": 0.0956,
      "step": 19310
    },
    {
      "epoch": 2.0687439768711853,
      "grad_norm": 0.2808493375778198,
      "learning_rate": 3.9660027840239855e-05,
      "loss": 0.084,
      "step": 19320
    },
    {
      "epoch": 2.0698147553271227,
      "grad_norm": 0.13408705592155457,
      "learning_rate": 3.9654673947960167e-05,
      "loss": 0.0816,
      "step": 19330
    },
    {
      "epoch": 2.07088553378306,
      "grad_norm": 0.12577436864376068,
      "learning_rate": 3.9649320055680485e-05,
      "loss": 0.0903,
      "step": 19340
    },
    {
      "epoch": 2.071956312238998,
      "grad_norm": 0.1885281801223755,
      "learning_rate": 3.964396616340079e-05,
      "loss": 0.0953,
      "step": 19350
    },
    {
      "epoch": 2.0730270906949353,
      "grad_norm": 0.1561652570962906,
      "learning_rate": 3.963861227112111e-05,
      "loss": 0.1093,
      "step": 19360
    },
    {
      "epoch": 2.0740978691508727,
      "grad_norm": 0.13901013135910034,
      "learning_rate": 3.963325837884142e-05,
      "loss": 0.0908,
      "step": 19370
    },
    {
      "epoch": 2.07516864760681,
      "grad_norm": 0.3676246404647827,
      "learning_rate": 3.962790448656174e-05,
      "loss": 0.0833,
      "step": 19380
    },
    {
      "epoch": 2.0762394260627475,
      "grad_norm": 0.27916789054870605,
      "learning_rate": 3.962255059428204e-05,
      "loss": 0.0745,
      "step": 19390
    },
    {
      "epoch": 2.0773102045186853,
      "grad_norm": 0.1806521713733673,
      "learning_rate": 3.961719670200236e-05,
      "loss": 0.0841,
      "step": 19400
    },
    {
      "epoch": 2.0783809829746227,
      "grad_norm": 0.11099514365196228,
      "learning_rate": 3.961184280972267e-05,
      "loss": 0.0776,
      "step": 19410
    },
    {
      "epoch": 2.07945176143056,
      "grad_norm": 0.1507035493850708,
      "learning_rate": 3.960648891744298e-05,
      "loss": 0.0904,
      "step": 19420
    },
    {
      "epoch": 2.0805225398864975,
      "grad_norm": 0.17120526731014252,
      "learning_rate": 3.9601135025163294e-05,
      "loss": 0.0953,
      "step": 19430
    },
    {
      "epoch": 2.081593318342435,
      "grad_norm": 0.38047292828559875,
      "learning_rate": 3.9595781132883605e-05,
      "loss": 0.0873,
      "step": 19440
    },
    {
      "epoch": 2.0826640967983723,
      "grad_norm": 0.1382792443037033,
      "learning_rate": 3.9590427240603924e-05,
      "loss": 0.087,
      "step": 19450
    },
    {
      "epoch": 2.0837348752543097,
      "grad_norm": 0.20213355123996735,
      "learning_rate": 3.958507334832423e-05,
      "loss": 0.0825,
      "step": 19460
    },
    {
      "epoch": 2.0848056537102475,
      "grad_norm": 0.18179506063461304,
      "learning_rate": 3.9579719456044546e-05,
      "loss": 0.0814,
      "step": 19470
    },
    {
      "epoch": 2.085876432166185,
      "grad_norm": 0.15011627972126007,
      "learning_rate": 3.957436556376486e-05,
      "loss": 0.0782,
      "step": 19480
    },
    {
      "epoch": 2.0869472106221223,
      "grad_norm": 0.15250515937805176,
      "learning_rate": 3.9569011671485176e-05,
      "loss": 0.0844,
      "step": 19490
    },
    {
      "epoch": 2.0880179890780597,
      "grad_norm": 0.16431735455989838,
      "learning_rate": 3.956365777920548e-05,
      "loss": 0.0913,
      "step": 19500
    },
    {
      "epoch": 2.089088767533997,
      "grad_norm": 0.14611119031906128,
      "learning_rate": 3.95583038869258e-05,
      "loss": 0.0821,
      "step": 19510
    },
    {
      "epoch": 2.0901595459899345,
      "grad_norm": 0.20988255739212036,
      "learning_rate": 3.955294999464611e-05,
      "loss": 0.1011,
      "step": 19520
    },
    {
      "epoch": 2.0912303244458723,
      "grad_norm": 0.14894838631153107,
      "learning_rate": 3.954759610236642e-05,
      "loss": 0.0755,
      "step": 19530
    },
    {
      "epoch": 2.0923011029018097,
      "grad_norm": 0.22485627233982086,
      "learning_rate": 3.954224221008673e-05,
      "loss": 0.0787,
      "step": 19540
    },
    {
      "epoch": 2.093371881357747,
      "grad_norm": 0.2008165717124939,
      "learning_rate": 3.9536888317807044e-05,
      "loss": 0.0772,
      "step": 19550
    },
    {
      "epoch": 2.0944426598136845,
      "grad_norm": 0.13506543636322021,
      "learning_rate": 3.953153442552736e-05,
      "loss": 0.0932,
      "step": 19560
    },
    {
      "epoch": 2.095513438269622,
      "grad_norm": 0.2031838297843933,
      "learning_rate": 3.9526180533247674e-05,
      "loss": 0.0895,
      "step": 19570
    },
    {
      "epoch": 2.0965842167255593,
      "grad_norm": 0.13156190514564514,
      "learning_rate": 3.9520826640967985e-05,
      "loss": 0.0768,
      "step": 19580
    },
    {
      "epoch": 2.097654995181497,
      "grad_norm": 0.18986305594444275,
      "learning_rate": 3.95154727486883e-05,
      "loss": 0.086,
      "step": 19590
    },
    {
      "epoch": 2.0987257736374345,
      "grad_norm": 0.2150786817073822,
      "learning_rate": 3.9510118856408615e-05,
      "loss": 0.0907,
      "step": 19600
    },
    {
      "epoch": 2.099796552093372,
      "grad_norm": 0.16197946667671204,
      "learning_rate": 3.9504764964128926e-05,
      "loss": 0.0954,
      "step": 19610
    },
    {
      "epoch": 2.1008673305493093,
      "grad_norm": 0.22735664248466492,
      "learning_rate": 3.949941107184924e-05,
      "loss": 0.0946,
      "step": 19620
    },
    {
      "epoch": 2.1019381090052467,
      "grad_norm": 0.13918232917785645,
      "learning_rate": 3.949405717956955e-05,
      "loss": 0.0877,
      "step": 19630
    },
    {
      "epoch": 2.103008887461184,
      "grad_norm": 0.2169279009103775,
      "learning_rate": 3.948870328728986e-05,
      "loss": 0.0994,
      "step": 19640
    },
    {
      "epoch": 2.104079665917122,
      "grad_norm": 0.12369618564844131,
      "learning_rate": 3.948334939501017e-05,
      "loss": 0.0962,
      "step": 19650
    },
    {
      "epoch": 2.1051504443730593,
      "grad_norm": 0.1307409703731537,
      "learning_rate": 3.947799550273048e-05,
      "loss": 0.0684,
      "step": 19660
    },
    {
      "epoch": 2.1062212228289967,
      "grad_norm": 0.13700087368488312,
      "learning_rate": 3.94726416104508e-05,
      "loss": 0.0905,
      "step": 19670
    },
    {
      "epoch": 2.107292001284934,
      "grad_norm": 0.13461697101593018,
      "learning_rate": 3.946728771817111e-05,
      "loss": 0.0883,
      "step": 19680
    },
    {
      "epoch": 2.1083627797408715,
      "grad_norm": 0.19335505366325378,
      "learning_rate": 3.9461933825891424e-05,
      "loss": 0.0933,
      "step": 19690
    },
    {
      "epoch": 2.109433558196809,
      "grad_norm": 0.18277332186698914,
      "learning_rate": 3.9456579933611736e-05,
      "loss": 0.0844,
      "step": 19700
    },
    {
      "epoch": 2.1105043366527467,
      "grad_norm": 0.11462604999542236,
      "learning_rate": 3.9451226041332054e-05,
      "loss": 0.0974,
      "step": 19710
    },
    {
      "epoch": 2.111575115108684,
      "grad_norm": 0.12686088681221008,
      "learning_rate": 3.9445872149052365e-05,
      "loss": 0.0802,
      "step": 19720
    },
    {
      "epoch": 2.1126458935646215,
      "grad_norm": 0.2083168774843216,
      "learning_rate": 3.944051825677268e-05,
      "loss": 0.0779,
      "step": 19730
    },
    {
      "epoch": 2.113716672020559,
      "grad_norm": 0.14308075606822968,
      "learning_rate": 3.943516436449299e-05,
      "loss": 0.0743,
      "step": 19740
    },
    {
      "epoch": 2.1147874504764963,
      "grad_norm": 0.15512603521347046,
      "learning_rate": 3.94298104722133e-05,
      "loss": 0.0851,
      "step": 19750
    },
    {
      "epoch": 2.1158582289324337,
      "grad_norm": 0.12562492489814758,
      "learning_rate": 3.942445657993362e-05,
      "loss": 0.0861,
      "step": 19760
    },
    {
      "epoch": 2.1169290073883715,
      "grad_norm": 0.16728857159614563,
      "learning_rate": 3.941910268765392e-05,
      "loss": 0.0931,
      "step": 19770
    },
    {
      "epoch": 2.117999785844309,
      "grad_norm": 0.16808874905109406,
      "learning_rate": 3.941374879537424e-05,
      "loss": 0.0996,
      "step": 19780
    },
    {
      "epoch": 2.1190705643002463,
      "grad_norm": 0.20511244237422943,
      "learning_rate": 3.940839490309455e-05,
      "loss": 0.0824,
      "step": 19790
    },
    {
      "epoch": 2.1201413427561837,
      "grad_norm": 0.1539406180381775,
      "learning_rate": 3.940304101081486e-05,
      "loss": 0.0936,
      "step": 19800
    },
    {
      "epoch": 2.121212121212121,
      "grad_norm": 0.5405466556549072,
      "learning_rate": 3.9397687118535175e-05,
      "loss": 0.0874,
      "step": 19810
    },
    {
      "epoch": 2.1222828996680585,
      "grad_norm": 0.1871996968984604,
      "learning_rate": 3.939233322625549e-05,
      "loss": 0.0943,
      "step": 19820
    },
    {
      "epoch": 2.1233536781239963,
      "grad_norm": 0.25785011053085327,
      "learning_rate": 3.9386979333975804e-05,
      "loss": 0.0914,
      "step": 19830
    },
    {
      "epoch": 2.1244244565799337,
      "grad_norm": 0.11636162549257278,
      "learning_rate": 3.9381625441696116e-05,
      "loss": 0.0898,
      "step": 19840
    },
    {
      "epoch": 2.125495235035871,
      "grad_norm": 0.1255975067615509,
      "learning_rate": 3.937627154941643e-05,
      "loss": 0.09,
      "step": 19850
    },
    {
      "epoch": 2.1265660134918085,
      "grad_norm": 0.14065483212471008,
      "learning_rate": 3.937091765713674e-05,
      "loss": 0.0805,
      "step": 19860
    },
    {
      "epoch": 2.127636791947746,
      "grad_norm": 0.1156797781586647,
      "learning_rate": 3.936556376485706e-05,
      "loss": 0.084,
      "step": 19870
    },
    {
      "epoch": 2.1287075704036833,
      "grad_norm": 0.16079582273960114,
      "learning_rate": 3.936020987257736e-05,
      "loss": 0.0859,
      "step": 19880
    },
    {
      "epoch": 2.129778348859621,
      "grad_norm": 0.28022557497024536,
      "learning_rate": 3.935485598029768e-05,
      "loss": 0.1016,
      "step": 19890
    },
    {
      "epoch": 2.1308491273155585,
      "grad_norm": 0.16973069310188293,
      "learning_rate": 3.934950208801799e-05,
      "loss": 0.0859,
      "step": 19900
    },
    {
      "epoch": 2.131919905771496,
      "grad_norm": 0.1355264037847519,
      "learning_rate": 3.934414819573831e-05,
      "loss": 0.0861,
      "step": 19910
    },
    {
      "epoch": 2.1329906842274333,
      "grad_norm": 0.12364893406629562,
      "learning_rate": 3.9338794303458614e-05,
      "loss": 0.0845,
      "step": 19920
    },
    {
      "epoch": 2.1340614626833707,
      "grad_norm": 0.15253135561943054,
      "learning_rate": 3.933344041117893e-05,
      "loss": 0.0951,
      "step": 19930
    },
    {
      "epoch": 2.135132241139308,
      "grad_norm": 0.24304629862308502,
      "learning_rate": 3.932808651889924e-05,
      "loss": 0.0974,
      "step": 19940
    },
    {
      "epoch": 2.136203019595246,
      "grad_norm": 0.1089862808585167,
      "learning_rate": 3.9322732626619555e-05,
      "loss": 0.0877,
      "step": 19950
    },
    {
      "epoch": 2.1372737980511833,
      "grad_norm": 0.16664598882198334,
      "learning_rate": 3.9317378734339866e-05,
      "loss": 0.0818,
      "step": 19960
    },
    {
      "epoch": 2.1383445765071207,
      "grad_norm": 0.17817124724388123,
      "learning_rate": 3.931202484206018e-05,
      "loss": 0.097,
      "step": 19970
    },
    {
      "epoch": 2.139415354963058,
      "grad_norm": 0.20098620653152466,
      "learning_rate": 3.9306670949780496e-05,
      "loss": 0.0804,
      "step": 19980
    },
    {
      "epoch": 2.1404861334189955,
      "grad_norm": 0.1789504736661911,
      "learning_rate": 3.93013170575008e-05,
      "loss": 0.0849,
      "step": 19990
    },
    {
      "epoch": 2.141556911874933,
      "grad_norm": 0.2884942591190338,
      "learning_rate": 3.929596316522112e-05,
      "loss": 0.0877,
      "step": 20000
    },
    {
      "epoch": 2.1426276903308707,
      "grad_norm": 0.2316303700208664,
      "learning_rate": 3.929060927294143e-05,
      "loss": 0.0877,
      "step": 20010
    },
    {
      "epoch": 2.143698468786808,
      "grad_norm": 0.1424349546432495,
      "learning_rate": 3.928525538066175e-05,
      "loss": 0.0864,
      "step": 20020
    },
    {
      "epoch": 2.1447692472427455,
      "grad_norm": 0.12527602910995483,
      "learning_rate": 3.927990148838205e-05,
      "loss": 0.0898,
      "step": 20030
    },
    {
      "epoch": 2.145840025698683,
      "grad_norm": 0.15971612930297852,
      "learning_rate": 3.927454759610237e-05,
      "loss": 0.0942,
      "step": 20040
    },
    {
      "epoch": 2.1469108041546203,
      "grad_norm": 0.16043005883693695,
      "learning_rate": 3.926919370382268e-05,
      "loss": 0.0891,
      "step": 20050
    },
    {
      "epoch": 2.1479815826105577,
      "grad_norm": 0.14508268237113953,
      "learning_rate": 3.9263839811542994e-05,
      "loss": 0.0784,
      "step": 20060
    },
    {
      "epoch": 2.149052361066495,
      "grad_norm": 0.1367155760526657,
      "learning_rate": 3.9258485919263305e-05,
      "loss": 0.0882,
      "step": 20070
    },
    {
      "epoch": 2.150123139522433,
      "grad_norm": 0.17288564145565033,
      "learning_rate": 3.9253132026983616e-05,
      "loss": 0.079,
      "step": 20080
    },
    {
      "epoch": 2.1511939179783703,
      "grad_norm": 0.12195650488138199,
      "learning_rate": 3.9247778134703935e-05,
      "loss": 0.0863,
      "step": 20090
    },
    {
      "epoch": 2.1522646964343077,
      "grad_norm": 0.2592753469944,
      "learning_rate": 3.924242424242424e-05,
      "loss": 0.0897,
      "step": 20100
    },
    {
      "epoch": 2.153335474890245,
      "grad_norm": 0.12655989825725555,
      "learning_rate": 3.923707035014456e-05,
      "loss": 0.0981,
      "step": 20110
    },
    {
      "epoch": 2.1544062533461825,
      "grad_norm": 0.15955983102321625,
      "learning_rate": 3.923171645786487e-05,
      "loss": 0.0814,
      "step": 20120
    },
    {
      "epoch": 2.1554770318021204,
      "grad_norm": 0.15760719776153564,
      "learning_rate": 3.922636256558519e-05,
      "loss": 0.0835,
      "step": 20130
    },
    {
      "epoch": 2.1565478102580578,
      "grad_norm": 0.14997641742229462,
      "learning_rate": 3.922100867330549e-05,
      "loss": 0.084,
      "step": 20140
    },
    {
      "epoch": 2.157618588713995,
      "grad_norm": 0.22639121115207672,
      "learning_rate": 3.921565478102581e-05,
      "loss": 0.084,
      "step": 20150
    },
    {
      "epoch": 2.1586893671699325,
      "grad_norm": 0.14627963304519653,
      "learning_rate": 3.921030088874612e-05,
      "loss": 0.0771,
      "step": 20160
    },
    {
      "epoch": 2.15976014562587,
      "grad_norm": 0.21663078665733337,
      "learning_rate": 3.920494699646643e-05,
      "loss": 0.0899,
      "step": 20170
    },
    {
      "epoch": 2.1608309240818073,
      "grad_norm": 0.2030218243598938,
      "learning_rate": 3.9199593104186744e-05,
      "loss": 0.0903,
      "step": 20180
    },
    {
      "epoch": 2.1619017025377447,
      "grad_norm": 0.13769493997097015,
      "learning_rate": 3.9194239211907055e-05,
      "loss": 0.0764,
      "step": 20190
    },
    {
      "epoch": 2.1629724809936826,
      "grad_norm": 0.12972447276115417,
      "learning_rate": 3.9188885319627374e-05,
      "loss": 0.076,
      "step": 20200
    },
    {
      "epoch": 2.16404325944962,
      "grad_norm": 0.22992199659347534,
      "learning_rate": 3.9183531427347685e-05,
      "loss": 0.0893,
      "step": 20210
    },
    {
      "epoch": 2.1651140379055573,
      "grad_norm": 0.22658856213092804,
      "learning_rate": 3.9178177535067996e-05,
      "loss": 0.0833,
      "step": 20220
    },
    {
      "epoch": 2.1661848163614947,
      "grad_norm": 0.18300144374370575,
      "learning_rate": 3.917282364278831e-05,
      "loss": 0.0953,
      "step": 20230
    },
    {
      "epoch": 2.167255594817432,
      "grad_norm": 0.18394635617733002,
      "learning_rate": 3.9167469750508626e-05,
      "loss": 0.0885,
      "step": 20240
    },
    {
      "epoch": 2.16832637327337,
      "grad_norm": 0.17023049294948578,
      "learning_rate": 3.916211585822893e-05,
      "loss": 0.0889,
      "step": 20250
    },
    {
      "epoch": 2.1693971517293074,
      "grad_norm": 0.11131112277507782,
      "learning_rate": 3.915676196594925e-05,
      "loss": 0.0881,
      "step": 20260
    },
    {
      "epoch": 2.1704679301852448,
      "grad_norm": 0.15983416140079498,
      "learning_rate": 3.915140807366956e-05,
      "loss": 0.0787,
      "step": 20270
    },
    {
      "epoch": 2.171538708641182,
      "grad_norm": 0.17014271020889282,
      "learning_rate": 3.914605418138987e-05,
      "loss": 0.0826,
      "step": 20280
    },
    {
      "epoch": 2.1726094870971195,
      "grad_norm": 0.168564572930336,
      "learning_rate": 3.914070028911018e-05,
      "loss": 0.0792,
      "step": 20290
    },
    {
      "epoch": 2.173680265553057,
      "grad_norm": 0.17336487770080566,
      "learning_rate": 3.9135346396830494e-05,
      "loss": 0.0801,
      "step": 20300
    },
    {
      "epoch": 2.1747510440089943,
      "grad_norm": 0.26605701446533203,
      "learning_rate": 3.912999250455081e-05,
      "loss": 0.0863,
      "step": 20310
    },
    {
      "epoch": 2.175821822464932,
      "grad_norm": 0.19606205821037292,
      "learning_rate": 3.9124638612271124e-05,
      "loss": 0.0967,
      "step": 20320
    },
    {
      "epoch": 2.1768926009208696,
      "grad_norm": 0.15931342542171478,
      "learning_rate": 3.9119284719991435e-05,
      "loss": 0.0755,
      "step": 20330
    },
    {
      "epoch": 2.177963379376807,
      "grad_norm": 0.14970706403255463,
      "learning_rate": 3.911393082771175e-05,
      "loss": 0.0802,
      "step": 20340
    },
    {
      "epoch": 2.1790341578327443,
      "grad_norm": 0.1784374713897705,
      "learning_rate": 3.9108576935432065e-05,
      "loss": 0.091,
      "step": 20350
    },
    {
      "epoch": 2.1801049362886817,
      "grad_norm": 0.3417923152446747,
      "learning_rate": 3.9103223043152376e-05,
      "loss": 0.0896,
      "step": 20360
    },
    {
      "epoch": 2.181175714744619,
      "grad_norm": 0.1531199812889099,
      "learning_rate": 3.909786915087269e-05,
      "loss": 0.0741,
      "step": 20370
    },
    {
      "epoch": 2.182246493200557,
      "grad_norm": 0.1257629245519638,
      "learning_rate": 3.9092515258593e-05,
      "loss": 0.0846,
      "step": 20380
    },
    {
      "epoch": 2.1833172716564944,
      "grad_norm": 0.1892920583486557,
      "learning_rate": 3.908716136631331e-05,
      "loss": 0.0757,
      "step": 20390
    },
    {
      "epoch": 2.1843880501124318,
      "grad_norm": 0.25046491622924805,
      "learning_rate": 3.908180747403363e-05,
      "loss": 0.0863,
      "step": 20400
    },
    {
      "epoch": 2.185458828568369,
      "grad_norm": 0.18343240022659302,
      "learning_rate": 3.907698897098191e-05,
      "loss": 0.0792,
      "step": 20410
    },
    {
      "epoch": 2.1865296070243065,
      "grad_norm": 0.16471274197101593,
      "learning_rate": 3.907163507870222e-05,
      "loss": 0.0842,
      "step": 20420
    },
    {
      "epoch": 2.187600385480244,
      "grad_norm": 0.22366055846214294,
      "learning_rate": 3.906628118642253e-05,
      "loss": 0.0903,
      "step": 20430
    },
    {
      "epoch": 2.1886711639361818,
      "grad_norm": 0.1646757423877716,
      "learning_rate": 3.906092729414285e-05,
      "loss": 0.1017,
      "step": 20440
    },
    {
      "epoch": 2.189741942392119,
      "grad_norm": 0.36783793568611145,
      "learning_rate": 3.905557340186315e-05,
      "loss": 0.0965,
      "step": 20450
    },
    {
      "epoch": 2.1908127208480566,
      "grad_norm": 0.194741889834404,
      "learning_rate": 3.905021950958347e-05,
      "loss": 0.0848,
      "step": 20460
    },
    {
      "epoch": 2.191883499303994,
      "grad_norm": 0.09557951986789703,
      "learning_rate": 3.904486561730378e-05,
      "loss": 0.0825,
      "step": 20470
    },
    {
      "epoch": 2.1929542777599313,
      "grad_norm": 0.15291179716587067,
      "learning_rate": 3.90395117250241e-05,
      "loss": 0.0801,
      "step": 20480
    },
    {
      "epoch": 2.1940250562158687,
      "grad_norm": 0.1406143307685852,
      "learning_rate": 3.9034157832744405e-05,
      "loss": 0.0864,
      "step": 20490
    },
    {
      "epoch": 2.1950958346718066,
      "grad_norm": 0.13840191066265106,
      "learning_rate": 3.902880394046472e-05,
      "loss": 0.0881,
      "step": 20500
    },
    {
      "epoch": 2.196166613127744,
      "grad_norm": 0.11067034304141998,
      "learning_rate": 3.9023450048185034e-05,
      "loss": 0.0813,
      "step": 20510
    },
    {
      "epoch": 2.1972373915836814,
      "grad_norm": 0.18821024894714355,
      "learning_rate": 3.9018096155905346e-05,
      "loss": 0.0966,
      "step": 20520
    },
    {
      "epoch": 2.1983081700396188,
      "grad_norm": 0.23051908612251282,
      "learning_rate": 3.901274226362566e-05,
      "loss": 0.0899,
      "step": 20530
    },
    {
      "epoch": 2.199378948495556,
      "grad_norm": 0.4253747761249542,
      "learning_rate": 3.900738837134597e-05,
      "loss": 0.0796,
      "step": 20540
    },
    {
      "epoch": 2.2004497269514935,
      "grad_norm": 0.15504522621631622,
      "learning_rate": 3.900203447906629e-05,
      "loss": 0.0822,
      "step": 20550
    },
    {
      "epoch": 2.2015205054074314,
      "grad_norm": 0.20063818991184235,
      "learning_rate": 3.899668058678659e-05,
      "loss": 0.0874,
      "step": 20560
    },
    {
      "epoch": 2.2025912838633688,
      "grad_norm": 0.13538102805614471,
      "learning_rate": 3.899132669450691e-05,
      "loss": 0.0896,
      "step": 20570
    },
    {
      "epoch": 2.203662062319306,
      "grad_norm": 0.12018239498138428,
      "learning_rate": 3.898597280222722e-05,
      "loss": 0.0851,
      "step": 20580
    },
    {
      "epoch": 2.2047328407752436,
      "grad_norm": 0.2755727171897888,
      "learning_rate": 3.898061890994754e-05,
      "loss": 0.081,
      "step": 20590
    },
    {
      "epoch": 2.205803619231181,
      "grad_norm": 0.16963467001914978,
      "learning_rate": 3.8975265017667844e-05,
      "loss": 0.0993,
      "step": 20600
    },
    {
      "epoch": 2.2068743976871183,
      "grad_norm": 0.14149655401706696,
      "learning_rate": 3.896991112538816e-05,
      "loss": 0.078,
      "step": 20610
    },
    {
      "epoch": 2.207945176143056,
      "grad_norm": 0.3312227129936218,
      "learning_rate": 3.896455723310847e-05,
      "loss": 0.0939,
      "step": 20620
    },
    {
      "epoch": 2.2090159545989936,
      "grad_norm": 0.12037631124258041,
      "learning_rate": 3.8959203340828785e-05,
      "loss": 0.0915,
      "step": 20630
    },
    {
      "epoch": 2.210086733054931,
      "grad_norm": 0.16131769120693207,
      "learning_rate": 3.8953849448549096e-05,
      "loss": 0.0943,
      "step": 20640
    },
    {
      "epoch": 2.2111575115108684,
      "grad_norm": 0.15132123231887817,
      "learning_rate": 3.894849555626941e-05,
      "loss": 0.086,
      "step": 20650
    },
    {
      "epoch": 2.2122282899668058,
      "grad_norm": 0.1659654825925827,
      "learning_rate": 3.8943141663989726e-05,
      "loss": 0.0846,
      "step": 20660
    },
    {
      "epoch": 2.213299068422743,
      "grad_norm": 0.123711496591568,
      "learning_rate": 3.893778777171003e-05,
      "loss": 0.0756,
      "step": 20670
    },
    {
      "epoch": 2.214369846878681,
      "grad_norm": 0.250222772359848,
      "learning_rate": 3.893243387943035e-05,
      "loss": 0.0945,
      "step": 20680
    },
    {
      "epoch": 2.2154406253346184,
      "grad_norm": 0.13559870421886444,
      "learning_rate": 3.892707998715066e-05,
      "loss": 0.0858,
      "step": 20690
    },
    {
      "epoch": 2.216511403790556,
      "grad_norm": 0.15091198682785034,
      "learning_rate": 3.892172609487098e-05,
      "loss": 0.0879,
      "step": 20700
    },
    {
      "epoch": 2.217582182246493,
      "grad_norm": 0.17160451412200928,
      "learning_rate": 3.891637220259128e-05,
      "loss": 0.0876,
      "step": 20710
    },
    {
      "epoch": 2.2186529607024306,
      "grad_norm": 0.1411060392856598,
      "learning_rate": 3.89110183103116e-05,
      "loss": 0.0851,
      "step": 20720
    },
    {
      "epoch": 2.219723739158368,
      "grad_norm": 0.16956773400306702,
      "learning_rate": 3.890566441803191e-05,
      "loss": 0.0903,
      "step": 20730
    },
    {
      "epoch": 2.220794517614306,
      "grad_norm": 0.3505547046661377,
      "learning_rate": 3.8900310525752224e-05,
      "loss": 0.0836,
      "step": 20740
    },
    {
      "epoch": 2.221865296070243,
      "grad_norm": 0.16996604204177856,
      "learning_rate": 3.8894956633472535e-05,
      "loss": 0.082,
      "step": 20750
    },
    {
      "epoch": 2.2229360745261806,
      "grad_norm": 0.1909642368555069,
      "learning_rate": 3.8889602741192847e-05,
      "loss": 0.096,
      "step": 20760
    },
    {
      "epoch": 2.224006852982118,
      "grad_norm": 0.11483579874038696,
      "learning_rate": 3.8884248848913165e-05,
      "loss": 0.0843,
      "step": 20770
    },
    {
      "epoch": 2.2250776314380554,
      "grad_norm": 0.16330507397651672,
      "learning_rate": 3.8878894956633476e-05,
      "loss": 0.0874,
      "step": 20780
    },
    {
      "epoch": 2.2261484098939928,
      "grad_norm": 0.24719631671905518,
      "learning_rate": 3.887354106435379e-05,
      "loss": 0.1044,
      "step": 20790
    },
    {
      "epoch": 2.2272191883499306,
      "grad_norm": 0.13307902216911316,
      "learning_rate": 3.88681871720741e-05,
      "loss": 0.0918,
      "step": 20800
    },
    {
      "epoch": 2.228289966805868,
      "grad_norm": 0.13324278593063354,
      "learning_rate": 3.886283327979442e-05,
      "loss": 0.0738,
      "step": 20810
    },
    {
      "epoch": 2.2293607452618054,
      "grad_norm": 0.14780555665493011,
      "learning_rate": 3.885747938751472e-05,
      "loss": 0.0983,
      "step": 20820
    },
    {
      "epoch": 2.230431523717743,
      "grad_norm": 0.17093543708324432,
      "learning_rate": 3.885212549523504e-05,
      "loss": 0.0975,
      "step": 20830
    },
    {
      "epoch": 2.23150230217368,
      "grad_norm": 0.1668042242527008,
      "learning_rate": 3.884677160295535e-05,
      "loss": 0.0871,
      "step": 20840
    },
    {
      "epoch": 2.2325730806296176,
      "grad_norm": 0.12811212241649628,
      "learning_rate": 3.884141771067566e-05,
      "loss": 0.0753,
      "step": 20850
    },
    {
      "epoch": 2.2336438590855554,
      "grad_norm": 0.20044630765914917,
      "learning_rate": 3.8836063818395974e-05,
      "loss": 0.0715,
      "step": 20860
    },
    {
      "epoch": 2.234714637541493,
      "grad_norm": 0.14996953308582306,
      "learning_rate": 3.8830709926116285e-05,
      "loss": 0.0951,
      "step": 20870
    },
    {
      "epoch": 2.23578541599743,
      "grad_norm": 0.22603633999824524,
      "learning_rate": 3.8825356033836604e-05,
      "loss": 0.0911,
      "step": 20880
    },
    {
      "epoch": 2.2368561944533676,
      "grad_norm": 0.18049748241901398,
      "learning_rate": 3.8820002141556915e-05,
      "loss": 0.0776,
      "step": 20890
    },
    {
      "epoch": 2.237926972909305,
      "grad_norm": 0.16076374053955078,
      "learning_rate": 3.8814648249277226e-05,
      "loss": 0.1023,
      "step": 20900
    },
    {
      "epoch": 2.2389977513652424,
      "grad_norm": 0.15017196536064148,
      "learning_rate": 3.880929435699754e-05,
      "loss": 0.0876,
      "step": 20910
    },
    {
      "epoch": 2.2400685298211798,
      "grad_norm": 0.18841196596622467,
      "learning_rate": 3.8803940464717856e-05,
      "loss": 0.0934,
      "step": 20920
    },
    {
      "epoch": 2.2411393082771176,
      "grad_norm": 0.17989081144332886,
      "learning_rate": 3.879858657243817e-05,
      "loss": 0.0862,
      "step": 20930
    },
    {
      "epoch": 2.242210086733055,
      "grad_norm": 0.19779279828071594,
      "learning_rate": 3.879323268015848e-05,
      "loss": 0.1,
      "step": 20940
    },
    {
      "epoch": 2.2432808651889924,
      "grad_norm": 0.1327766329050064,
      "learning_rate": 3.878787878787879e-05,
      "loss": 0.0867,
      "step": 20950
    },
    {
      "epoch": 2.24435164364493,
      "grad_norm": 0.13596434891223907,
      "learning_rate": 3.87825248955991e-05,
      "loss": 0.0756,
      "step": 20960
    },
    {
      "epoch": 2.245422422100867,
      "grad_norm": 0.10415997356176376,
      "learning_rate": 3.877717100331941e-05,
      "loss": 0.0833,
      "step": 20970
    },
    {
      "epoch": 2.246493200556805,
      "grad_norm": 0.09213098883628845,
      "learning_rate": 3.8771817111039724e-05,
      "loss": 0.0862,
      "step": 20980
    },
    {
      "epoch": 2.2475639790127424,
      "grad_norm": 0.12014851719141006,
      "learning_rate": 3.876646321876004e-05,
      "loss": 0.0886,
      "step": 20990
    },
    {
      "epoch": 2.24863475746868,
      "grad_norm": 0.21319305896759033,
      "learning_rate": 3.8761109326480354e-05,
      "loss": 0.0809,
      "step": 21000
    },
    {
      "epoch": 2.249705535924617,
      "grad_norm": 0.1961725801229477,
      "learning_rate": 3.8755755434200665e-05,
      "loss": 0.0994,
      "step": 21010
    },
    {
      "epoch": 2.2507763143805546,
      "grad_norm": 0.1775781363248825,
      "learning_rate": 3.875040154192098e-05,
      "loss": 0.0844,
      "step": 21020
    },
    {
      "epoch": 2.251847092836492,
      "grad_norm": 0.14901018142700195,
      "learning_rate": 3.8745047649641295e-05,
      "loss": 0.0771,
      "step": 21030
    },
    {
      "epoch": 2.2529178712924294,
      "grad_norm": 0.1521063894033432,
      "learning_rate": 3.8739693757361606e-05,
      "loss": 0.1083,
      "step": 21040
    },
    {
      "epoch": 2.253988649748367,
      "grad_norm": 0.14648215472698212,
      "learning_rate": 3.873433986508192e-05,
      "loss": 0.082,
      "step": 21050
    },
    {
      "epoch": 2.2550594282043046,
      "grad_norm": 0.16377824544906616,
      "learning_rate": 3.872898597280223e-05,
      "loss": 0.0791,
      "step": 21060
    },
    {
      "epoch": 2.256130206660242,
      "grad_norm": 0.15246179699897766,
      "learning_rate": 3.872363208052254e-05,
      "loss": 0.0853,
      "step": 21070
    },
    {
      "epoch": 2.2572009851161794,
      "grad_norm": 0.1742583066225052,
      "learning_rate": 3.871827818824286e-05,
      "loss": 0.0872,
      "step": 21080
    },
    {
      "epoch": 2.258271763572117,
      "grad_norm": 0.09887904673814774,
      "learning_rate": 3.871292429596316e-05,
      "loss": 0.0829,
      "step": 21090
    },
    {
      "epoch": 2.2593425420280546,
      "grad_norm": 0.24266856908798218,
      "learning_rate": 3.870757040368348e-05,
      "loss": 0.0847,
      "step": 21100
    },
    {
      "epoch": 2.260413320483992,
      "grad_norm": 0.20275139808654785,
      "learning_rate": 3.870221651140379e-05,
      "loss": 0.0921,
      "step": 21110
    },
    {
      "epoch": 2.2614840989399294,
      "grad_norm": 0.14387795329093933,
      "learning_rate": 3.8696862619124104e-05,
      "loss": 0.0753,
      "step": 21120
    },
    {
      "epoch": 2.262554877395867,
      "grad_norm": 0.13473348319530487,
      "learning_rate": 3.8691508726844416e-05,
      "loss": 0.0738,
      "step": 21130
    },
    {
      "epoch": 2.263625655851804,
      "grad_norm": 0.11200641095638275,
      "learning_rate": 3.8686154834564734e-05,
      "loss": 0.0743,
      "step": 21140
    },
    {
      "epoch": 2.2646964343077416,
      "grad_norm": 0.16051755845546722,
      "learning_rate": 3.8680800942285045e-05,
      "loss": 0.0848,
      "step": 21150
    },
    {
      "epoch": 2.265767212763679,
      "grad_norm": 0.18136386573314667,
      "learning_rate": 3.867544705000536e-05,
      "loss": 0.0962,
      "step": 21160
    },
    {
      "epoch": 2.266837991219617,
      "grad_norm": 0.2227700650691986,
      "learning_rate": 3.867009315772567e-05,
      "loss": 0.0853,
      "step": 21170
    },
    {
      "epoch": 2.267908769675554,
      "grad_norm": 0.1404116451740265,
      "learning_rate": 3.866473926544598e-05,
      "loss": 0.0778,
      "step": 21180
    },
    {
      "epoch": 2.2689795481314916,
      "grad_norm": 0.18633250892162323,
      "learning_rate": 3.86593853731663e-05,
      "loss": 0.0866,
      "step": 21190
    },
    {
      "epoch": 2.270050326587429,
      "grad_norm": 0.21167081594467163,
      "learning_rate": 3.86540314808866e-05,
      "loss": 0.0957,
      "step": 21200
    },
    {
      "epoch": 2.2711211050433664,
      "grad_norm": 0.16769841313362122,
      "learning_rate": 3.864867758860692e-05,
      "loss": 0.0749,
      "step": 21210
    },
    {
      "epoch": 2.2721918834993042,
      "grad_norm": 0.12077485769987106,
      "learning_rate": 3.864332369632723e-05,
      "loss": 0.0883,
      "step": 21220
    },
    {
      "epoch": 2.2732626619552416,
      "grad_norm": 0.18072937428951263,
      "learning_rate": 3.863796980404755e-05,
      "loss": 0.0851,
      "step": 21230
    },
    {
      "epoch": 2.274333440411179,
      "grad_norm": 0.20558065176010132,
      "learning_rate": 3.8632615911767855e-05,
      "loss": 0.0837,
      "step": 21240
    },
    {
      "epoch": 2.2754042188671164,
      "grad_norm": 0.20535115897655487,
      "learning_rate": 3.862726201948817e-05,
      "loss": 0.1042,
      "step": 21250
    },
    {
      "epoch": 2.276474997323054,
      "grad_norm": 0.17142632603645325,
      "learning_rate": 3.8621908127208484e-05,
      "loss": 0.096,
      "step": 21260
    },
    {
      "epoch": 2.277545775778991,
      "grad_norm": 0.14049032330513,
      "learning_rate": 3.8616554234928796e-05,
      "loss": 0.0873,
      "step": 21270
    },
    {
      "epoch": 2.2786165542349286,
      "grad_norm": 0.1746150255203247,
      "learning_rate": 3.861120034264911e-05,
      "loss": 0.0848,
      "step": 21280
    },
    {
      "epoch": 2.2796873326908664,
      "grad_norm": 0.15182949602603912,
      "learning_rate": 3.860584645036942e-05,
      "loss": 0.093,
      "step": 21290
    },
    {
      "epoch": 2.280758111146804,
      "grad_norm": 0.17438165843486786,
      "learning_rate": 3.860049255808974e-05,
      "loss": 0.0906,
      "step": 21300
    },
    {
      "epoch": 2.281828889602741,
      "grad_norm": 0.1486150026321411,
      "learning_rate": 3.859513866581004e-05,
      "loss": 0.0856,
      "step": 21310
    },
    {
      "epoch": 2.2828996680586786,
      "grad_norm": 0.15482650697231293,
      "learning_rate": 3.858978477353036e-05,
      "loss": 0.0809,
      "step": 21320
    },
    {
      "epoch": 2.283970446514616,
      "grad_norm": 0.1198316290974617,
      "learning_rate": 3.858443088125067e-05,
      "loss": 0.0816,
      "step": 21330
    },
    {
      "epoch": 2.285041224970554,
      "grad_norm": 0.1218828335404396,
      "learning_rate": 3.857907698897099e-05,
      "loss": 0.0732,
      "step": 21340
    },
    {
      "epoch": 2.2861120034264912,
      "grad_norm": 0.16258573532104492,
      "learning_rate": 3.8573723096691294e-05,
      "loss": 0.0907,
      "step": 21350
    },
    {
      "epoch": 2.2871827818824286,
      "grad_norm": 0.1769559234380722,
      "learning_rate": 3.856836920441161e-05,
      "loss": 0.0939,
      "step": 21360
    },
    {
      "epoch": 2.288253560338366,
      "grad_norm": 0.17840954661369324,
      "learning_rate": 3.856301531213192e-05,
      "loss": 0.086,
      "step": 21370
    },
    {
      "epoch": 2.2893243387943034,
      "grad_norm": 0.22667357325553894,
      "learning_rate": 3.8557661419852235e-05,
      "loss": 0.088,
      "step": 21380
    },
    {
      "epoch": 2.290395117250241,
      "grad_norm": 0.20531515777111053,
      "learning_rate": 3.8552307527572546e-05,
      "loss": 0.071,
      "step": 21390
    },
    {
      "epoch": 2.291465895706178,
      "grad_norm": 0.1965034157037735,
      "learning_rate": 3.854695363529286e-05,
      "loss": 0.0754,
      "step": 21400
    },
    {
      "epoch": 2.292536674162116,
      "grad_norm": 0.1674482524394989,
      "learning_rate": 3.8541599743013176e-05,
      "loss": 0.087,
      "step": 21410
    },
    {
      "epoch": 2.2936074526180534,
      "grad_norm": 0.14810024201869965,
      "learning_rate": 3.853624585073349e-05,
      "loss": 0.0835,
      "step": 21420
    },
    {
      "epoch": 2.294678231073991,
      "grad_norm": 0.18230348825454712,
      "learning_rate": 3.85308919584538e-05,
      "loss": 0.0863,
      "step": 21430
    },
    {
      "epoch": 2.295749009529928,
      "grad_norm": 0.23765462636947632,
      "learning_rate": 3.852553806617411e-05,
      "loss": 0.0954,
      "step": 21440
    },
    {
      "epoch": 2.2968197879858656,
      "grad_norm": 0.13879618048667908,
      "learning_rate": 3.852018417389443e-05,
      "loss": 0.0756,
      "step": 21450
    },
    {
      "epoch": 2.297890566441803,
      "grad_norm": 0.1278606355190277,
      "learning_rate": 3.851483028161473e-05,
      "loss": 0.0823,
      "step": 21460
    },
    {
      "epoch": 2.298961344897741,
      "grad_norm": 0.1437290906906128,
      "learning_rate": 3.850947638933505e-05,
      "loss": 0.0811,
      "step": 21470
    },
    {
      "epoch": 2.3000321233536782,
      "grad_norm": 0.20242281258106232,
      "learning_rate": 3.850412249705536e-05,
      "loss": 0.078,
      "step": 21480
    },
    {
      "epoch": 2.3011029018096156,
      "grad_norm": 0.16121965646743774,
      "learning_rate": 3.8498768604775674e-05,
      "loss": 0.0817,
      "step": 21490
    },
    {
      "epoch": 2.302173680265553,
      "grad_norm": 0.1934649795293808,
      "learning_rate": 3.8493414712495985e-05,
      "loss": 0.0857,
      "step": 21500
    },
    {
      "epoch": 2.3032444587214904,
      "grad_norm": 0.14530031383037567,
      "learning_rate": 3.8488060820216296e-05,
      "loss": 0.0915,
      "step": 21510
    },
    {
      "epoch": 2.304315237177428,
      "grad_norm": 0.29077577590942383,
      "learning_rate": 3.8482706927936615e-05,
      "loss": 0.0869,
      "step": 21520
    },
    {
      "epoch": 2.3053860156333656,
      "grad_norm": 0.23884674906730652,
      "learning_rate": 3.8477353035656926e-05,
      "loss": 0.0804,
      "step": 21530
    },
    {
      "epoch": 2.306456794089303,
      "grad_norm": 0.13540734350681305,
      "learning_rate": 3.847199914337724e-05,
      "loss": 0.0908,
      "step": 21540
    },
    {
      "epoch": 2.3075275725452404,
      "grad_norm": 0.1319573074579239,
      "learning_rate": 3.846664525109755e-05,
      "loss": 0.0915,
      "step": 21550
    },
    {
      "epoch": 2.308598351001178,
      "grad_norm": 0.1677583009004593,
      "learning_rate": 3.846129135881787e-05,
      "loss": 0.0912,
      "step": 21560
    },
    {
      "epoch": 2.309669129457115,
      "grad_norm": 0.17059680819511414,
      "learning_rate": 3.845593746653818e-05,
      "loss": 0.0872,
      "step": 21570
    },
    {
      "epoch": 2.3107399079130526,
      "grad_norm": 0.2507650554180145,
      "learning_rate": 3.845058357425848e-05,
      "loss": 0.0945,
      "step": 21580
    },
    {
      "epoch": 2.3118106863689905,
      "grad_norm": 0.14857088029384613,
      "learning_rate": 3.84452296819788e-05,
      "loss": 0.0757,
      "step": 21590
    },
    {
      "epoch": 2.312881464824928,
      "grad_norm": 0.18124404549598694,
      "learning_rate": 3.843987578969911e-05,
      "loss": 0.0795,
      "step": 21600
    },
    {
      "epoch": 2.3139522432808652,
      "grad_norm": 0.21803806722164154,
      "learning_rate": 3.8434521897419424e-05,
      "loss": 0.0818,
      "step": 21610
    },
    {
      "epoch": 2.3150230217368026,
      "grad_norm": 0.17043691873550415,
      "learning_rate": 3.8429168005139735e-05,
      "loss": 0.0861,
      "step": 21620
    },
    {
      "epoch": 2.31609380019274,
      "grad_norm": 0.11269097775220871,
      "learning_rate": 3.8423814112860054e-05,
      "loss": 0.0926,
      "step": 21630
    },
    {
      "epoch": 2.3171645786486774,
      "grad_norm": 0.12282321602106094,
      "learning_rate": 3.8418460220580365e-05,
      "loss": 0.0899,
      "step": 21640
    },
    {
      "epoch": 2.318235357104615,
      "grad_norm": 0.13560625910758972,
      "learning_rate": 3.8413106328300676e-05,
      "loss": 0.0763,
      "step": 21650
    },
    {
      "epoch": 2.3193061355605527,
      "grad_norm": 0.15556037425994873,
      "learning_rate": 3.840775243602099e-05,
      "loss": 0.0783,
      "step": 21660
    },
    {
      "epoch": 2.32037691401649,
      "grad_norm": 0.16464878618717194,
      "learning_rate": 3.8402398543741306e-05,
      "loss": 0.0866,
      "step": 21670
    },
    {
      "epoch": 2.3214476924724274,
      "grad_norm": 0.1749742180109024,
      "learning_rate": 3.839704465146162e-05,
      "loss": 0.0906,
      "step": 21680
    },
    {
      "epoch": 2.322518470928365,
      "grad_norm": 0.6291439533233643,
      "learning_rate": 3.839169075918192e-05,
      "loss": 0.0881,
      "step": 21690
    },
    {
      "epoch": 2.3235892493843022,
      "grad_norm": 0.12052489072084427,
      "learning_rate": 3.838633686690224e-05,
      "loss": 0.1019,
      "step": 21700
    },
    {
      "epoch": 2.32466002784024,
      "grad_norm": 0.17347998917102814,
      "learning_rate": 3.838098297462255e-05,
      "loss": 0.0805,
      "step": 21710
    },
    {
      "epoch": 2.3257308062961775,
      "grad_norm": 0.15453247725963593,
      "learning_rate": 3.837562908234287e-05,
      "loss": 0.0847,
      "step": 21720
    },
    {
      "epoch": 2.326801584752115,
      "grad_norm": 0.12367422878742218,
      "learning_rate": 3.8370275190063174e-05,
      "loss": 0.0802,
      "step": 21730
    },
    {
      "epoch": 2.3278723632080522,
      "grad_norm": 0.16450315713882446,
      "learning_rate": 3.836492129778349e-05,
      "loss": 0.0849,
      "step": 21740
    },
    {
      "epoch": 2.3289431416639896,
      "grad_norm": 0.1419316977262497,
      "learning_rate": 3.8359567405503804e-05,
      "loss": 0.0763,
      "step": 21750
    },
    {
      "epoch": 2.330013920119927,
      "grad_norm": 0.11085200309753418,
      "learning_rate": 3.8354213513224115e-05,
      "loss": 0.0742,
      "step": 21760
    },
    {
      "epoch": 2.3310846985758644,
      "grad_norm": 0.1687587946653366,
      "learning_rate": 3.834885962094443e-05,
      "loss": 0.0944,
      "step": 21770
    },
    {
      "epoch": 2.3321554770318023,
      "grad_norm": 0.1217004582285881,
      "learning_rate": 3.834350572866474e-05,
      "loss": 0.0782,
      "step": 21780
    },
    {
      "epoch": 2.3332262554877397,
      "grad_norm": 0.1756691187620163,
      "learning_rate": 3.8338151836385056e-05,
      "loss": 0.0855,
      "step": 21790
    },
    {
      "epoch": 2.334297033943677,
      "grad_norm": 0.13534660637378693,
      "learning_rate": 3.833279794410536e-05,
      "loss": 0.0858,
      "step": 21800
    },
    {
      "epoch": 2.3353678123996144,
      "grad_norm": 0.11384740471839905,
      "learning_rate": 3.832744405182568e-05,
      "loss": 0.0751,
      "step": 21810
    },
    {
      "epoch": 2.336438590855552,
      "grad_norm": 0.12559056282043457,
      "learning_rate": 3.832209015954599e-05,
      "loss": 0.0828,
      "step": 21820
    },
    {
      "epoch": 2.3375093693114897,
      "grad_norm": 0.19141584634780884,
      "learning_rate": 3.831673626726631e-05,
      "loss": 0.0795,
      "step": 21830
    },
    {
      "epoch": 2.338580147767427,
      "grad_norm": 0.12094703316688538,
      "learning_rate": 3.831138237498661e-05,
      "loss": 0.0823,
      "step": 21840
    },
    {
      "epoch": 2.3396509262233645,
      "grad_norm": 0.1765250414609909,
      "learning_rate": 3.830602848270693e-05,
      "loss": 0.0836,
      "step": 21850
    },
    {
      "epoch": 2.340721704679302,
      "grad_norm": 0.17856431007385254,
      "learning_rate": 3.830067459042724e-05,
      "loss": 0.0771,
      "step": 21860
    },
    {
      "epoch": 2.3417924831352392,
      "grad_norm": 0.12339574098587036,
      "learning_rate": 3.8295320698147554e-05,
      "loss": 0.0891,
      "step": 21870
    },
    {
      "epoch": 2.3428632615911766,
      "grad_norm": 0.18524350225925446,
      "learning_rate": 3.8289966805867866e-05,
      "loss": 0.0958,
      "step": 21880
    },
    {
      "epoch": 2.343934040047114,
      "grad_norm": 0.146043062210083,
      "learning_rate": 3.828461291358818e-05,
      "loss": 0.0756,
      "step": 21890
    },
    {
      "epoch": 2.345004818503052,
      "grad_norm": 0.16283626854419708,
      "learning_rate": 3.8279259021308495e-05,
      "loss": 0.0808,
      "step": 21900
    },
    {
      "epoch": 2.3460755969589893,
      "grad_norm": 0.15951566398143768,
      "learning_rate": 3.82739051290288e-05,
      "loss": 0.0914,
      "step": 21910
    },
    {
      "epoch": 2.3471463754149267,
      "grad_norm": 0.13250255584716797,
      "learning_rate": 3.826855123674912e-05,
      "loss": 0.0924,
      "step": 21920
    },
    {
      "epoch": 2.348217153870864,
      "grad_norm": 0.24585865437984467,
      "learning_rate": 3.826319734446943e-05,
      "loss": 0.0804,
      "step": 21930
    },
    {
      "epoch": 2.3492879323268014,
      "grad_norm": 0.7697135806083679,
      "learning_rate": 3.825784345218975e-05,
      "loss": 0.0869,
      "step": 21940
    },
    {
      "epoch": 2.3503587107827393,
      "grad_norm": 0.14489787817001343,
      "learning_rate": 3.825248955991005e-05,
      "loss": 0.0759,
      "step": 21950
    },
    {
      "epoch": 2.3514294892386767,
      "grad_norm": 0.25648951530456543,
      "learning_rate": 3.824713566763037e-05,
      "loss": 0.0922,
      "step": 21960
    },
    {
      "epoch": 2.352500267694614,
      "grad_norm": 0.17328472435474396,
      "learning_rate": 3.824178177535068e-05,
      "loss": 0.0846,
      "step": 21970
    },
    {
      "epoch": 2.3535710461505515,
      "grad_norm": 0.19653670489788055,
      "learning_rate": 3.823642788307099e-05,
      "loss": 0.0822,
      "step": 21980
    },
    {
      "epoch": 2.354641824606489,
      "grad_norm": 0.15744240581989288,
      "learning_rate": 3.8231073990791305e-05,
      "loss": 0.0892,
      "step": 21990
    },
    {
      "epoch": 2.3557126030624262,
      "grad_norm": 0.13534973561763763,
      "learning_rate": 3.8225720098511616e-05,
      "loss": 0.1033,
      "step": 22000
    },
    {
      "epoch": 2.3567833815183636,
      "grad_norm": 0.16006158292293549,
      "learning_rate": 3.8220366206231934e-05,
      "loss": 0.0809,
      "step": 22010
    },
    {
      "epoch": 2.3578541599743015,
      "grad_norm": 0.10478699952363968,
      "learning_rate": 3.8215012313952246e-05,
      "loss": 0.0776,
      "step": 22020
    },
    {
      "epoch": 2.358924938430239,
      "grad_norm": 0.20141789317131042,
      "learning_rate": 3.820965842167256e-05,
      "loss": 0.0896,
      "step": 22030
    },
    {
      "epoch": 2.3599957168861763,
      "grad_norm": 0.11910971254110336,
      "learning_rate": 3.820430452939287e-05,
      "loss": 0.0873,
      "step": 22040
    },
    {
      "epoch": 2.3610664953421137,
      "grad_norm": 0.15330542623996735,
      "learning_rate": 3.8198950637113187e-05,
      "loss": 0.0911,
      "step": 22050
    },
    {
      "epoch": 2.362137273798051,
      "grad_norm": 0.16888442635536194,
      "learning_rate": 3.819359674483349e-05,
      "loss": 0.0752,
      "step": 22060
    },
    {
      "epoch": 2.363208052253989,
      "grad_norm": 0.16748467087745667,
      "learning_rate": 3.818824285255381e-05,
      "loss": 0.0855,
      "step": 22070
    },
    {
      "epoch": 2.3642788307099263,
      "grad_norm": 0.11466878652572632,
      "learning_rate": 3.818288896027412e-05,
      "loss": 0.0957,
      "step": 22080
    },
    {
      "epoch": 2.3653496091658637,
      "grad_norm": 0.11157985776662827,
      "learning_rate": 3.817753506799443e-05,
      "loss": 0.0767,
      "step": 22090
    },
    {
      "epoch": 2.366420387621801,
      "grad_norm": 0.2522267997264862,
      "learning_rate": 3.8172181175714744e-05,
      "loss": 0.0784,
      "step": 22100
    },
    {
      "epoch": 2.3674911660777385,
      "grad_norm": 0.22147458791732788,
      "learning_rate": 3.8166827283435055e-05,
      "loss": 0.0944,
      "step": 22110
    },
    {
      "epoch": 2.368561944533676,
      "grad_norm": 0.11766774207353592,
      "learning_rate": 3.816147339115537e-05,
      "loss": 0.0751,
      "step": 22120
    },
    {
      "epoch": 2.3696327229896132,
      "grad_norm": 0.181046724319458,
      "learning_rate": 3.8156119498875685e-05,
      "loss": 0.083,
      "step": 22130
    },
    {
      "epoch": 2.370703501445551,
      "grad_norm": 0.12365113943815231,
      "learning_rate": 3.8150765606595996e-05,
      "loss": 0.0924,
      "step": 22140
    },
    {
      "epoch": 2.3717742799014885,
      "grad_norm": 0.19081568717956543,
      "learning_rate": 3.814541171431631e-05,
      "loss": 0.0776,
      "step": 22150
    },
    {
      "epoch": 2.372845058357426,
      "grad_norm": 0.17778974771499634,
      "learning_rate": 3.8140057822036626e-05,
      "loss": 0.0808,
      "step": 22160
    },
    {
      "epoch": 2.3739158368133633,
      "grad_norm": 0.15574480593204498,
      "learning_rate": 3.813470392975694e-05,
      "loss": 0.0986,
      "step": 22170
    },
    {
      "epoch": 2.3749866152693007,
      "grad_norm": 0.3143291771411896,
      "learning_rate": 3.812935003747725e-05,
      "loss": 0.0914,
      "step": 22180
    },
    {
      "epoch": 2.3760573937252385,
      "grad_norm": 0.17871950566768646,
      "learning_rate": 3.812399614519756e-05,
      "loss": 0.0733,
      "step": 22190
    },
    {
      "epoch": 2.377128172181176,
      "grad_norm": 0.1460527926683426,
      "learning_rate": 3.811864225291787e-05,
      "loss": 0.0798,
      "step": 22200
    },
    {
      "epoch": 2.3781989506371133,
      "grad_norm": 0.20221291482448578,
      "learning_rate": 3.811328836063819e-05,
      "loss": 0.0832,
      "step": 22210
    },
    {
      "epoch": 2.3792697290930507,
      "grad_norm": 0.11677302420139313,
      "learning_rate": 3.8107934468358494e-05,
      "loss": 0.0812,
      "step": 22220
    },
    {
      "epoch": 2.380340507548988,
      "grad_norm": 0.10206834971904755,
      "learning_rate": 3.810258057607881e-05,
      "loss": 0.0682,
      "step": 22230
    },
    {
      "epoch": 2.3814112860049255,
      "grad_norm": 0.14531736075878143,
      "learning_rate": 3.8097226683799123e-05,
      "loss": 0.0924,
      "step": 22240
    },
    {
      "epoch": 2.382482064460863,
      "grad_norm": 0.12781333923339844,
      "learning_rate": 3.8091872791519435e-05,
      "loss": 0.0785,
      "step": 22250
    },
    {
      "epoch": 2.3835528429168007,
      "grad_norm": 0.10329805314540863,
      "learning_rate": 3.8086518899239746e-05,
      "loss": 0.0793,
      "step": 22260
    },
    {
      "epoch": 2.384623621372738,
      "grad_norm": 0.2771971821784973,
      "learning_rate": 3.8081165006960064e-05,
      "loss": 0.0919,
      "step": 22270
    },
    {
      "epoch": 2.3856943998286755,
      "grad_norm": 0.11347811669111252,
      "learning_rate": 3.8075811114680376e-05,
      "loss": 0.0869,
      "step": 22280
    },
    {
      "epoch": 2.386765178284613,
      "grad_norm": 0.18226785957813263,
      "learning_rate": 3.807045722240069e-05,
      "loss": 0.0748,
      "step": 22290
    },
    {
      "epoch": 2.3878359567405503,
      "grad_norm": 0.1665545552968979,
      "learning_rate": 3.8065103330121e-05,
      "loss": 0.0724,
      "step": 22300
    },
    {
      "epoch": 2.3889067351964877,
      "grad_norm": 0.10935547202825546,
      "learning_rate": 3.805974943784131e-05,
      "loss": 0.0842,
      "step": 22310
    },
    {
      "epoch": 2.3899775136524255,
      "grad_norm": 0.23744846880435944,
      "learning_rate": 3.805439554556163e-05,
      "loss": 0.0774,
      "step": 22320
    },
    {
      "epoch": 2.391048292108363,
      "grad_norm": 0.16648943722248077,
      "learning_rate": 3.804904165328193e-05,
      "loss": 0.0673,
      "step": 22330
    },
    {
      "epoch": 2.3921190705643003,
      "grad_norm": 0.14289875328540802,
      "learning_rate": 3.804368776100225e-05,
      "loss": 0.0754,
      "step": 22340
    },
    {
      "epoch": 2.3931898490202377,
      "grad_norm": 0.13713106513023376,
      "learning_rate": 3.803833386872256e-05,
      "loss": 0.0798,
      "step": 22350
    },
    {
      "epoch": 2.394260627476175,
      "grad_norm": 0.13405901193618774,
      "learning_rate": 3.803297997644288e-05,
      "loss": 0.0873,
      "step": 22360
    },
    {
      "epoch": 2.3953314059321125,
      "grad_norm": 0.1362561136484146,
      "learning_rate": 3.8027626084163185e-05,
      "loss": 0.0847,
      "step": 22370
    },
    {
      "epoch": 2.3964021843880503,
      "grad_norm": 0.37911245226860046,
      "learning_rate": 3.8022272191883503e-05,
      "loss": 0.0892,
      "step": 22380
    },
    {
      "epoch": 2.3974729628439877,
      "grad_norm": 0.3741621673107147,
      "learning_rate": 3.8016918299603815e-05,
      "loss": 0.0766,
      "step": 22390
    },
    {
      "epoch": 2.398543741299925,
      "grad_norm": 0.19580742716789246,
      "learning_rate": 3.8011564407324126e-05,
      "loss": 0.0878,
      "step": 22400
    },
    {
      "epoch": 2.3996145197558625,
      "grad_norm": 0.16242334246635437,
      "learning_rate": 3.800621051504444e-05,
      "loss": 0.0849,
      "step": 22410
    },
    {
      "epoch": 2.4006852982118,
      "grad_norm": 0.83415687084198,
      "learning_rate": 3.800085662276475e-05,
      "loss": 0.0802,
      "step": 22420
    },
    {
      "epoch": 2.4017560766677373,
      "grad_norm": 0.07991968095302582,
      "learning_rate": 3.799550273048507e-05,
      "loss": 0.0775,
      "step": 22430
    },
    {
      "epoch": 2.402826855123675,
      "grad_norm": 0.14135956764221191,
      "learning_rate": 3.799014883820537e-05,
      "loss": 0.0825,
      "step": 22440
    },
    {
      "epoch": 2.4038976335796125,
      "grad_norm": 0.15048442780971527,
      "learning_rate": 3.798479494592569e-05,
      "loss": 0.0855,
      "step": 22450
    },
    {
      "epoch": 2.40496841203555,
      "grad_norm": 0.14086876809597015,
      "learning_rate": 3.797997644287397e-05,
      "loss": 0.075,
      "step": 22460
    },
    {
      "epoch": 2.4060391904914873,
      "grad_norm": 0.17309258878231049,
      "learning_rate": 3.7974622550594286e-05,
      "loss": 0.0842,
      "step": 22470
    },
    {
      "epoch": 2.4071099689474247,
      "grad_norm": 0.17072075605392456,
      "learning_rate": 3.796926865831459e-05,
      "loss": 0.0881,
      "step": 22480
    },
    {
      "epoch": 2.408180747403362,
      "grad_norm": 0.18017464876174927,
      "learning_rate": 3.796391476603491e-05,
      "loss": 0.0739,
      "step": 22490
    },
    {
      "epoch": 2.4092515258592995,
      "grad_norm": 0.18657489120960236,
      "learning_rate": 3.795856087375522e-05,
      "loss": 0.0945,
      "step": 22500
    },
    {
      "epoch": 2.4103223043152373,
      "grad_norm": 0.1530120074748993,
      "learning_rate": 3.795320698147554e-05,
      "loss": 0.098,
      "step": 22510
    },
    {
      "epoch": 2.4113930827711747,
      "grad_norm": 0.17829036712646484,
      "learning_rate": 3.7947853089195843e-05,
      "loss": 0.0761,
      "step": 22520
    },
    {
      "epoch": 2.412463861227112,
      "grad_norm": 0.14918947219848633,
      "learning_rate": 3.794249919691616e-05,
      "loss": 0.0832,
      "step": 22530
    },
    {
      "epoch": 2.4135346396830495,
      "grad_norm": 0.1969890296459198,
      "learning_rate": 3.793714530463647e-05,
      "loss": 0.0829,
      "step": 22540
    },
    {
      "epoch": 2.414605418138987,
      "grad_norm": 0.12742145359516144,
      "learning_rate": 3.7931791412356784e-05,
      "loss": 0.0774,
      "step": 22550
    },
    {
      "epoch": 2.4156761965949247,
      "grad_norm": 0.18098242580890656,
      "learning_rate": 3.7926437520077096e-05,
      "loss": 0.0787,
      "step": 22560
    },
    {
      "epoch": 2.416746975050862,
      "grad_norm": 0.12286247313022614,
      "learning_rate": 3.792108362779741e-05,
      "loss": 0.0854,
      "step": 22570
    },
    {
      "epoch": 2.4178177535067995,
      "grad_norm": 0.19296833872795105,
      "learning_rate": 3.7915729735517725e-05,
      "loss": 0.0773,
      "step": 22580
    },
    {
      "epoch": 2.418888531962737,
      "grad_norm": 0.1252841204404831,
      "learning_rate": 3.791037584323804e-05,
      "loss": 0.0801,
      "step": 22590
    },
    {
      "epoch": 2.4199593104186743,
      "grad_norm": 0.17962384223937988,
      "learning_rate": 3.790502195095835e-05,
      "loss": 0.0869,
      "step": 22600
    },
    {
      "epoch": 2.4210300888746117,
      "grad_norm": 0.2080824226140976,
      "learning_rate": 3.789966805867866e-05,
      "loss": 0.0859,
      "step": 22610
    },
    {
      "epoch": 2.422100867330549,
      "grad_norm": 0.2510203719139099,
      "learning_rate": 3.789431416639898e-05,
      "loss": 0.0792,
      "step": 22620
    },
    {
      "epoch": 2.423171645786487,
      "grad_norm": 0.12254408746957779,
      "learning_rate": 3.788896027411928e-05,
      "loss": 0.0851,
      "step": 22630
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 0.1521289050579071,
      "learning_rate": 3.78836063818396e-05,
      "loss": 0.0893,
      "step": 22640
    },
    {
      "epoch": 2.4253132026983617,
      "grad_norm": 0.12562690675258636,
      "learning_rate": 3.787825248955991e-05,
      "loss": 0.0916,
      "step": 22650
    },
    {
      "epoch": 2.426383981154299,
      "grad_norm": 0.11130980402231216,
      "learning_rate": 3.787289859728022e-05,
      "loss": 0.0839,
      "step": 22660
    },
    {
      "epoch": 2.4274547596102365,
      "grad_norm": 0.14374417066574097,
      "learning_rate": 3.7867544705000535e-05,
      "loss": 0.0853,
      "step": 22670
    },
    {
      "epoch": 2.4285255380661743,
      "grad_norm": 0.24099254608154297,
      "learning_rate": 3.7862190812720846e-05,
      "loss": 0.0784,
      "step": 22680
    },
    {
      "epoch": 2.4295963165221117,
      "grad_norm": 0.17602914571762085,
      "learning_rate": 3.7856836920441164e-05,
      "loss": 0.0805,
      "step": 22690
    },
    {
      "epoch": 2.430667094978049,
      "grad_norm": 0.14259320497512817,
      "learning_rate": 3.7851483028161476e-05,
      "loss": 0.0765,
      "step": 22700
    },
    {
      "epoch": 2.4317378734339865,
      "grad_norm": 0.09476660937070847,
      "learning_rate": 3.784612913588179e-05,
      "loss": 0.0855,
      "step": 22710
    },
    {
      "epoch": 2.432808651889924,
      "grad_norm": 0.305738627910614,
      "learning_rate": 3.78407752436021e-05,
      "loss": 0.0846,
      "step": 22720
    },
    {
      "epoch": 2.4338794303458613,
      "grad_norm": 0.15865175426006317,
      "learning_rate": 3.783542135132242e-05,
      "loss": 0.0816,
      "step": 22730
    },
    {
      "epoch": 2.4349502088017987,
      "grad_norm": 0.1834995150566101,
      "learning_rate": 3.783006745904273e-05,
      "loss": 0.0852,
      "step": 22740
    },
    {
      "epoch": 2.4360209872577365,
      "grad_norm": 0.16105319559574127,
      "learning_rate": 3.782471356676304e-05,
      "loss": 0.0952,
      "step": 22750
    },
    {
      "epoch": 2.437091765713674,
      "grad_norm": 0.11549971997737885,
      "learning_rate": 3.781935967448335e-05,
      "loss": 0.0719,
      "step": 22760
    },
    {
      "epoch": 2.4381625441696113,
      "grad_norm": 0.49991893768310547,
      "learning_rate": 3.781400578220366e-05,
      "loss": 0.0792,
      "step": 22770
    },
    {
      "epoch": 2.4392333226255487,
      "grad_norm": 0.17104597389698029,
      "learning_rate": 3.7808651889923974e-05,
      "loss": 0.0663,
      "step": 22780
    },
    {
      "epoch": 2.440304101081486,
      "grad_norm": 0.11347382515668869,
      "learning_rate": 3.7803297997644285e-05,
      "loss": 0.0921,
      "step": 22790
    },
    {
      "epoch": 2.441374879537424,
      "grad_norm": 0.17823472619056702,
      "learning_rate": 3.77979441053646e-05,
      "loss": 0.085,
      "step": 22800
    },
    {
      "epoch": 2.4424456579933613,
      "grad_norm": 0.16517166793346405,
      "learning_rate": 3.7792590213084915e-05,
      "loss": 0.0811,
      "step": 22810
    },
    {
      "epoch": 2.4435164364492987,
      "grad_norm": 0.12870196998119354,
      "learning_rate": 3.7787236320805226e-05,
      "loss": 0.0783,
      "step": 22820
    },
    {
      "epoch": 2.444587214905236,
      "grad_norm": 0.1328953504562378,
      "learning_rate": 3.778188242852554e-05,
      "loss": 0.0944,
      "step": 22830
    },
    {
      "epoch": 2.4456579933611735,
      "grad_norm": 0.1334657520055771,
      "learning_rate": 3.7776528536245856e-05,
      "loss": 0.0731,
      "step": 22840
    },
    {
      "epoch": 2.446728771817111,
      "grad_norm": 0.14168933033943176,
      "learning_rate": 3.777117464396617e-05,
      "loss": 0.0742,
      "step": 22850
    },
    {
      "epoch": 2.4477995502730483,
      "grad_norm": 0.15373201668262482,
      "learning_rate": 3.776582075168648e-05,
      "loss": 0.0806,
      "step": 22860
    },
    {
      "epoch": 2.448870328728986,
      "grad_norm": 0.16828332841396332,
      "learning_rate": 3.776046685940679e-05,
      "loss": 0.078,
      "step": 22870
    },
    {
      "epoch": 2.4499411071849235,
      "grad_norm": 0.15451619029045105,
      "learning_rate": 3.77551129671271e-05,
      "loss": 0.0906,
      "step": 22880
    },
    {
      "epoch": 2.451011885640861,
      "grad_norm": 0.3003424108028412,
      "learning_rate": 3.774975907484742e-05,
      "loss": 0.0873,
      "step": 22890
    },
    {
      "epoch": 2.4520826640967983,
      "grad_norm": 0.13359816372394562,
      "learning_rate": 3.7744405182567724e-05,
      "loss": 0.0828,
      "step": 22900
    },
    {
      "epoch": 2.4531534425527357,
      "grad_norm": 0.1340685784816742,
      "learning_rate": 3.773905129028804e-05,
      "loss": 0.0932,
      "step": 22910
    },
    {
      "epoch": 2.4542242210086735,
      "grad_norm": 0.22723472118377686,
      "learning_rate": 3.7733697398008354e-05,
      "loss": 0.0764,
      "step": 22920
    },
    {
      "epoch": 2.455294999464611,
      "grad_norm": 0.14209365844726562,
      "learning_rate": 3.7728343505728665e-05,
      "loss": 0.0847,
      "step": 22930
    },
    {
      "epoch": 2.4563657779205483,
      "grad_norm": 0.09788326919078827,
      "learning_rate": 3.7722989613448976e-05,
      "loss": 0.0764,
      "step": 22940
    },
    {
      "epoch": 2.4574365563764857,
      "grad_norm": 0.18639416992664337,
      "learning_rate": 3.7717635721169295e-05,
      "loss": 0.0872,
      "step": 22950
    },
    {
      "epoch": 2.458507334832423,
      "grad_norm": 0.1784892976284027,
      "learning_rate": 3.7712281828889606e-05,
      "loss": 0.0782,
      "step": 22960
    },
    {
      "epoch": 2.4595781132883605,
      "grad_norm": 0.4366171061992645,
      "learning_rate": 3.770692793660992e-05,
      "loss": 0.0749,
      "step": 22970
    },
    {
      "epoch": 2.460648891744298,
      "grad_norm": 0.13265040516853333,
      "learning_rate": 3.770157404433023e-05,
      "loss": 0.0834,
      "step": 22980
    },
    {
      "epoch": 2.4617196702002357,
      "grad_norm": 0.21123751997947693,
      "learning_rate": 3.769622015205054e-05,
      "loss": 0.086,
      "step": 22990
    },
    {
      "epoch": 2.462790448656173,
      "grad_norm": 0.16840285062789917,
      "learning_rate": 3.769086625977086e-05,
      "loss": 0.0765,
      "step": 23000
    },
    {
      "epoch": 2.4638612271121105,
      "grad_norm": 0.15789763629436493,
      "learning_rate": 3.768551236749116e-05,
      "loss": 0.0986,
      "step": 23010
    },
    {
      "epoch": 2.464932005568048,
      "grad_norm": 0.17301756143569946,
      "learning_rate": 3.768015847521148e-05,
      "loss": 0.0799,
      "step": 23020
    },
    {
      "epoch": 2.4660027840239853,
      "grad_norm": 0.7535862326622009,
      "learning_rate": 3.767480458293179e-05,
      "loss": 0.09,
      "step": 23030
    },
    {
      "epoch": 2.4670735624799227,
      "grad_norm": 0.14833182096481323,
      "learning_rate": 3.766945069065211e-05,
      "loss": 0.0811,
      "step": 23040
    },
    {
      "epoch": 2.4681443409358605,
      "grad_norm": 0.22735099494457245,
      "learning_rate": 3.7664096798372415e-05,
      "loss": 0.0851,
      "step": 23050
    },
    {
      "epoch": 2.469215119391798,
      "grad_norm": 0.22902071475982666,
      "learning_rate": 3.7658742906092734e-05,
      "loss": 0.0928,
      "step": 23060
    },
    {
      "epoch": 2.4702858978477353,
      "grad_norm": 0.12464374303817749,
      "learning_rate": 3.7653389013813045e-05,
      "loss": 0.0774,
      "step": 23070
    },
    {
      "epoch": 2.4713566763036727,
      "grad_norm": 0.10084612667560577,
      "learning_rate": 3.7648035121533356e-05,
      "loss": 0.0764,
      "step": 23080
    },
    {
      "epoch": 2.47242745475961,
      "grad_norm": 0.15123894810676575,
      "learning_rate": 3.764268122925367e-05,
      "loss": 0.0769,
      "step": 23090
    },
    {
      "epoch": 2.4734982332155475,
      "grad_norm": 0.15841680765151978,
      "learning_rate": 3.763732733697398e-05,
      "loss": 0.09,
      "step": 23100
    },
    {
      "epoch": 2.4745690116714854,
      "grad_norm": 0.08574719727039337,
      "learning_rate": 3.76319734446943e-05,
      "loss": 0.0708,
      "step": 23110
    },
    {
      "epoch": 2.4756397901274227,
      "grad_norm": 0.10984313488006592,
      "learning_rate": 3.76266195524146e-05,
      "loss": 0.0702,
      "step": 23120
    },
    {
      "epoch": 2.47671056858336,
      "grad_norm": 0.18391361832618713,
      "learning_rate": 3.762126566013492e-05,
      "loss": 0.0795,
      "step": 23130
    },
    {
      "epoch": 2.4777813470392975,
      "grad_norm": 0.1876128613948822,
      "learning_rate": 3.761591176785523e-05,
      "loss": 0.0872,
      "step": 23140
    },
    {
      "epoch": 2.478852125495235,
      "grad_norm": 0.13713572919368744,
      "learning_rate": 3.761055787557555e-05,
      "loss": 0.0866,
      "step": 23150
    },
    {
      "epoch": 2.4799229039511723,
      "grad_norm": 0.1504703313112259,
      "learning_rate": 3.7605203983295854e-05,
      "loss": 0.088,
      "step": 23160
    },
    {
      "epoch": 2.48099368240711,
      "grad_norm": 0.2201068103313446,
      "learning_rate": 3.759985009101617e-05,
      "loss": 0.0904,
      "step": 23170
    },
    {
      "epoch": 2.4820644608630476,
      "grad_norm": 0.11537348479032516,
      "learning_rate": 3.7594496198736484e-05,
      "loss": 0.0824,
      "step": 23180
    },
    {
      "epoch": 2.483135239318985,
      "grad_norm": 0.17245283722877502,
      "learning_rate": 3.7589142306456795e-05,
      "loss": 0.0768,
      "step": 23190
    },
    {
      "epoch": 2.4842060177749223,
      "grad_norm": 0.23088344931602478,
      "learning_rate": 3.758378841417711e-05,
      "loss": 0.0858,
      "step": 23200
    },
    {
      "epoch": 2.4852767962308597,
      "grad_norm": 0.23621182143688202,
      "learning_rate": 3.757843452189742e-05,
      "loss": 0.083,
      "step": 23210
    },
    {
      "epoch": 2.486347574686797,
      "grad_norm": 0.12945830821990967,
      "learning_rate": 3.7573080629617736e-05,
      "loss": 0.0829,
      "step": 23220
    },
    {
      "epoch": 2.487418353142735,
      "grad_norm": 0.1648329645395279,
      "learning_rate": 3.756772673733805e-05,
      "loss": 0.0713,
      "step": 23230
    },
    {
      "epoch": 2.4884891315986724,
      "grad_norm": 0.34957069158554077,
      "learning_rate": 3.756237284505836e-05,
      "loss": 0.0857,
      "step": 23240
    },
    {
      "epoch": 2.4895599100546097,
      "grad_norm": 0.21398282051086426,
      "learning_rate": 3.755701895277867e-05,
      "loss": 0.0809,
      "step": 23250
    },
    {
      "epoch": 2.490630688510547,
      "grad_norm": 0.21594947576522827,
      "learning_rate": 3.755166506049899e-05,
      "loss": 0.0831,
      "step": 23260
    },
    {
      "epoch": 2.4917014669664845,
      "grad_norm": 0.11977727711200714,
      "learning_rate": 3.754631116821929e-05,
      "loss": 0.0844,
      "step": 23270
    },
    {
      "epoch": 2.492772245422422,
      "grad_norm": 0.14467595517635345,
      "learning_rate": 3.754095727593961e-05,
      "loss": 0.0856,
      "step": 23280
    },
    {
      "epoch": 2.4938430238783598,
      "grad_norm": 0.1355370581150055,
      "learning_rate": 3.753560338365992e-05,
      "loss": 0.085,
      "step": 23290
    },
    {
      "epoch": 2.494913802334297,
      "grad_norm": 0.16594453155994415,
      "learning_rate": 3.7530249491380234e-05,
      "loss": 0.0947,
      "step": 23300
    },
    {
      "epoch": 2.4959845807902346,
      "grad_norm": 0.21390748023986816,
      "learning_rate": 3.7524895599100546e-05,
      "loss": 0.0871,
      "step": 23310
    },
    {
      "epoch": 2.497055359246172,
      "grad_norm": 0.14218804240226746,
      "learning_rate": 3.751954170682086e-05,
      "loss": 0.0801,
      "step": 23320
    },
    {
      "epoch": 2.4981261377021093,
      "grad_norm": 0.22428420186042786,
      "learning_rate": 3.7514187814541175e-05,
      "loss": 0.089,
      "step": 23330
    },
    {
      "epoch": 2.4991969161580467,
      "grad_norm": 0.15394550561904907,
      "learning_rate": 3.750883392226149e-05,
      "loss": 0.0764,
      "step": 23340
    },
    {
      "epoch": 2.500267694613984,
      "grad_norm": 0.13500355184078217,
      "learning_rate": 3.75034800299818e-05,
      "loss": 0.0985,
      "step": 23350
    },
    {
      "epoch": 2.501338473069922,
      "grad_norm": 0.18265284597873688,
      "learning_rate": 3.749812613770211e-05,
      "loss": 0.0855,
      "step": 23360
    },
    {
      "epoch": 2.5024092515258594,
      "grad_norm": 0.18028514087200165,
      "learning_rate": 3.749277224542243e-05,
      "loss": 0.0806,
      "step": 23370
    },
    {
      "epoch": 2.5034800299817968,
      "grad_norm": 0.17944808304309845,
      "learning_rate": 3.748741835314274e-05,
      "loss": 0.0817,
      "step": 23380
    },
    {
      "epoch": 2.504550808437734,
      "grad_norm": 0.13855071365833282,
      "learning_rate": 3.748206446086305e-05,
      "loss": 0.0809,
      "step": 23390
    },
    {
      "epoch": 2.5056215868936715,
      "grad_norm": 0.1193612739443779,
      "learning_rate": 3.747671056858336e-05,
      "loss": 0.0918,
      "step": 23400
    },
    {
      "epoch": 2.5066923653496094,
      "grad_norm": 0.26153847575187683,
      "learning_rate": 3.747135667630367e-05,
      "loss": 0.0978,
      "step": 23410
    },
    {
      "epoch": 2.5077631438055468,
      "grad_norm": 0.1575871706008911,
      "learning_rate": 3.7466002784023985e-05,
      "loss": 0.0804,
      "step": 23420
    },
    {
      "epoch": 2.508833922261484,
      "grad_norm": 0.14374160766601562,
      "learning_rate": 3.7460648891744296e-05,
      "loss": 0.0941,
      "step": 23430
    },
    {
      "epoch": 2.5099047007174216,
      "grad_norm": 0.1704685539007187,
      "learning_rate": 3.7455294999464614e-05,
      "loss": 0.0872,
      "step": 23440
    },
    {
      "epoch": 2.510975479173359,
      "grad_norm": 0.22362454235553741,
      "learning_rate": 3.7449941107184926e-05,
      "loss": 0.0889,
      "step": 23450
    },
    {
      "epoch": 2.5120462576292963,
      "grad_norm": 0.14394766092300415,
      "learning_rate": 3.744458721490524e-05,
      "loss": 0.0789,
      "step": 23460
    },
    {
      "epoch": 2.5131170360852337,
      "grad_norm": 0.24226512014865875,
      "learning_rate": 3.743923332262555e-05,
      "loss": 0.0975,
      "step": 23470
    },
    {
      "epoch": 2.5141878145411716,
      "grad_norm": 0.13970345258712769,
      "learning_rate": 3.7433879430345867e-05,
      "loss": 0.0822,
      "step": 23480
    },
    {
      "epoch": 2.515258592997109,
      "grad_norm": 0.16246487200260162,
      "learning_rate": 3.742852553806618e-05,
      "loss": 0.0765,
      "step": 23490
    },
    {
      "epoch": 2.5163293714530464,
      "grad_norm": 0.1615755259990692,
      "learning_rate": 3.742317164578649e-05,
      "loss": 0.082,
      "step": 23500
    },
    {
      "epoch": 2.5174001499089838,
      "grad_norm": 0.12767226994037628,
      "learning_rate": 3.74178177535068e-05,
      "loss": 0.0788,
      "step": 23510
    },
    {
      "epoch": 2.518470928364921,
      "grad_norm": 0.1534457802772522,
      "learning_rate": 3.741246386122711e-05,
      "loss": 0.0756,
      "step": 23520
    },
    {
      "epoch": 2.519541706820859,
      "grad_norm": 0.15809445083141327,
      "learning_rate": 3.740710996894743e-05,
      "loss": 0.0708,
      "step": 23530
    },
    {
      "epoch": 2.5206124852767964,
      "grad_norm": 0.1619747132062912,
      "learning_rate": 3.7401756076667735e-05,
      "loss": 0.075,
      "step": 23540
    },
    {
      "epoch": 2.5216832637327338,
      "grad_norm": 0.14017115533351898,
      "learning_rate": 3.739640218438805e-05,
      "loss": 0.0814,
      "step": 23550
    },
    {
      "epoch": 2.522754042188671,
      "grad_norm": 0.13632605969905853,
      "learning_rate": 3.7391048292108365e-05,
      "loss": 0.0782,
      "step": 23560
    },
    {
      "epoch": 2.5238248206446086,
      "grad_norm": 0.14919833838939667,
      "learning_rate": 3.7385694399828676e-05,
      "loss": 0.0874,
      "step": 23570
    },
    {
      "epoch": 2.524895599100546,
      "grad_norm": 0.15923552215099335,
      "learning_rate": 3.738034050754899e-05,
      "loss": 0.0892,
      "step": 23580
    },
    {
      "epoch": 2.5259663775564833,
      "grad_norm": 0.10472726821899414,
      "learning_rate": 3.7374986615269306e-05,
      "loss": 0.0867,
      "step": 23590
    },
    {
      "epoch": 2.527037156012421,
      "grad_norm": 0.2226715236902237,
      "learning_rate": 3.736963272298962e-05,
      "loss": 0.0764,
      "step": 23600
    },
    {
      "epoch": 2.5281079344683586,
      "grad_norm": 0.14489378035068512,
      "learning_rate": 3.736427883070993e-05,
      "loss": 0.0912,
      "step": 23610
    },
    {
      "epoch": 2.529178712924296,
      "grad_norm": 0.12741206586360931,
      "learning_rate": 3.735892493843024e-05,
      "loss": 0.0862,
      "step": 23620
    },
    {
      "epoch": 2.5302494913802334,
      "grad_norm": 0.13945412635803223,
      "learning_rate": 3.735357104615055e-05,
      "loss": 0.0768,
      "step": 23630
    },
    {
      "epoch": 2.5313202698361708,
      "grad_norm": 0.10757006704807281,
      "learning_rate": 3.734821715387087e-05,
      "loss": 0.0781,
      "step": 23640
    },
    {
      "epoch": 2.5323910482921086,
      "grad_norm": 0.23079660534858704,
      "learning_rate": 3.7342863261591174e-05,
      "loss": 0.0787,
      "step": 23650
    },
    {
      "epoch": 2.533461826748046,
      "grad_norm": 0.4407086968421936,
      "learning_rate": 3.733750936931149e-05,
      "loss": 0.0764,
      "step": 23660
    },
    {
      "epoch": 2.5345326052039834,
      "grad_norm": 0.197610542178154,
      "learning_rate": 3.7332155477031803e-05,
      "loss": 0.0903,
      "step": 23670
    },
    {
      "epoch": 2.5356033836599208,
      "grad_norm": 0.0944308489561081,
      "learning_rate": 3.732680158475212e-05,
      "loss": 0.0767,
      "step": 23680
    },
    {
      "epoch": 2.536674162115858,
      "grad_norm": 0.14910049736499786,
      "learning_rate": 3.7321447692472426e-05,
      "loss": 0.0849,
      "step": 23690
    },
    {
      "epoch": 2.5377449405717956,
      "grad_norm": 0.1708361804485321,
      "learning_rate": 3.7316093800192744e-05,
      "loss": 0.0857,
      "step": 23700
    },
    {
      "epoch": 2.538815719027733,
      "grad_norm": 0.11265214532613754,
      "learning_rate": 3.7310739907913056e-05,
      "loss": 0.0874,
      "step": 23710
    },
    {
      "epoch": 2.539886497483671,
      "grad_norm": 0.11462506651878357,
      "learning_rate": 3.730538601563337e-05,
      "loss": 0.0812,
      "step": 23720
    },
    {
      "epoch": 2.540957275939608,
      "grad_norm": 0.18527071177959442,
      "learning_rate": 3.730003212335368e-05,
      "loss": 0.0824,
      "step": 23730
    },
    {
      "epoch": 2.5420280543955456,
      "grad_norm": 0.15174123644828796,
      "learning_rate": 3.729467823107399e-05,
      "loss": 0.0789,
      "step": 23740
    },
    {
      "epoch": 2.543098832851483,
      "grad_norm": 0.09224212169647217,
      "learning_rate": 3.728932433879431e-05,
      "loss": 0.0819,
      "step": 23750
    },
    {
      "epoch": 2.5441696113074204,
      "grad_norm": 0.12990765273571014,
      "learning_rate": 3.728397044651461e-05,
      "loss": 0.0769,
      "step": 23760
    },
    {
      "epoch": 2.545240389763358,
      "grad_norm": 0.15919822454452515,
      "learning_rate": 3.727861655423493e-05,
      "loss": 0.0738,
      "step": 23770
    },
    {
      "epoch": 2.5463111682192956,
      "grad_norm": 0.14225324988365173,
      "learning_rate": 3.727326266195524e-05,
      "loss": 0.0785,
      "step": 23780
    },
    {
      "epoch": 2.547381946675233,
      "grad_norm": 0.13135626912117004,
      "learning_rate": 3.726790876967556e-05,
      "loss": 0.0811,
      "step": 23790
    },
    {
      "epoch": 2.5484527251311704,
      "grad_norm": 0.1596541553735733,
      "learning_rate": 3.7262554877395865e-05,
      "loss": 0.0724,
      "step": 23800
    },
    {
      "epoch": 2.5495235035871078,
      "grad_norm": 0.17550067603588104,
      "learning_rate": 3.7257200985116183e-05,
      "loss": 0.0795,
      "step": 23810
    },
    {
      "epoch": 2.550594282043045,
      "grad_norm": 0.1573912799358368,
      "learning_rate": 3.7251847092836495e-05,
      "loss": 0.0828,
      "step": 23820
    },
    {
      "epoch": 2.5516650604989826,
      "grad_norm": 0.11227934062480927,
      "learning_rate": 3.7246493200556806e-05,
      "loss": 0.0768,
      "step": 23830
    },
    {
      "epoch": 2.55273583895492,
      "grad_norm": 0.16780053079128265,
      "learning_rate": 3.724113930827712e-05,
      "loss": 0.0876,
      "step": 23840
    },
    {
      "epoch": 2.553806617410858,
      "grad_norm": 0.17345976829528809,
      "learning_rate": 3.723578541599743e-05,
      "loss": 0.0792,
      "step": 23850
    },
    {
      "epoch": 2.554877395866795,
      "grad_norm": 0.13419120013713837,
      "learning_rate": 3.723043152371775e-05,
      "loss": 0.0868,
      "step": 23860
    },
    {
      "epoch": 2.5559481743227326,
      "grad_norm": 0.16877493262290955,
      "learning_rate": 3.722507763143805e-05,
      "loss": 0.0879,
      "step": 23870
    },
    {
      "epoch": 2.55701895277867,
      "grad_norm": 0.16696685552597046,
      "learning_rate": 3.721972373915837e-05,
      "loss": 0.0878,
      "step": 23880
    },
    {
      "epoch": 2.558089731234608,
      "grad_norm": 0.13464777171611786,
      "learning_rate": 3.721436984687868e-05,
      "loss": 0.0775,
      "step": 23890
    },
    {
      "epoch": 2.559160509690545,
      "grad_norm": 0.26139765977859497,
      "learning_rate": 3.7209015954599e-05,
      "loss": 0.0761,
      "step": 23900
    },
    {
      "epoch": 2.5602312881464826,
      "grad_norm": 0.18257470428943634,
      "learning_rate": 3.7203662062319304e-05,
      "loss": 0.0815,
      "step": 23910
    },
    {
      "epoch": 2.56130206660242,
      "grad_norm": 0.14408086240291595,
      "learning_rate": 3.719830817003962e-05,
      "loss": 0.0797,
      "step": 23920
    },
    {
      "epoch": 2.5623728450583574,
      "grad_norm": 0.28287050127983093,
      "learning_rate": 3.7192954277759934e-05,
      "loss": 0.0951,
      "step": 23930
    },
    {
      "epoch": 2.563443623514295,
      "grad_norm": 0.1676073968410492,
      "learning_rate": 3.7187600385480245e-05,
      "loss": 0.0823,
      "step": 23940
    },
    {
      "epoch": 2.564514401970232,
      "grad_norm": 0.11978072673082352,
      "learning_rate": 3.7182246493200557e-05,
      "loss": 0.0766,
      "step": 23950
    },
    {
      "epoch": 2.5655851804261696,
      "grad_norm": 0.14160682260990143,
      "learning_rate": 3.717689260092087e-05,
      "loss": 0.0824,
      "step": 23960
    },
    {
      "epoch": 2.5666559588821074,
      "grad_norm": 0.1034594252705574,
      "learning_rate": 3.7171538708641186e-05,
      "loss": 0.0684,
      "step": 23970
    },
    {
      "epoch": 2.567726737338045,
      "grad_norm": 0.14312273263931274,
      "learning_rate": 3.71661848163615e-05,
      "loss": 0.0882,
      "step": 23980
    },
    {
      "epoch": 2.568797515793982,
      "grad_norm": 0.11719106882810593,
      "learning_rate": 3.716083092408181e-05,
      "loss": 0.0724,
      "step": 23990
    },
    {
      "epoch": 2.5698682942499196,
      "grad_norm": 0.1425025463104248,
      "learning_rate": 3.715547703180212e-05,
      "loss": 0.0793,
      "step": 24000
    },
    {
      "epoch": 2.5709390727058574,
      "grad_norm": 0.1449146866798401,
      "learning_rate": 3.715012313952244e-05,
      "loss": 0.0707,
      "step": 24010
    },
    {
      "epoch": 2.572009851161795,
      "grad_norm": 0.2259974479675293,
      "learning_rate": 3.714476924724275e-05,
      "loss": 0.0862,
      "step": 24020
    },
    {
      "epoch": 2.573080629617732,
      "grad_norm": 0.13175459206104279,
      "learning_rate": 3.713941535496306e-05,
      "loss": 0.0925,
      "step": 24030
    },
    {
      "epoch": 2.5741514080736696,
      "grad_norm": 0.12198979407548904,
      "learning_rate": 3.713406146268337e-05,
      "loss": 0.0715,
      "step": 24040
    },
    {
      "epoch": 2.575222186529607,
      "grad_norm": 0.1392923891544342,
      "learning_rate": 3.7128707570403684e-05,
      "loss": 0.0883,
      "step": 24050
    },
    {
      "epoch": 2.5762929649855444,
      "grad_norm": 0.22651483118534088,
      "learning_rate": 3.7123353678123996e-05,
      "loss": 0.0853,
      "step": 24060
    },
    {
      "epoch": 2.577363743441482,
      "grad_norm": 0.20072178542613983,
      "learning_rate": 3.711799978584431e-05,
      "loss": 0.0727,
      "step": 24070
    },
    {
      "epoch": 2.578434521897419,
      "grad_norm": 0.21729829907417297,
      "learning_rate": 3.7112645893564625e-05,
      "loss": 0.0926,
      "step": 24080
    },
    {
      "epoch": 2.579505300353357,
      "grad_norm": 0.1922793984413147,
      "learning_rate": 3.7107292001284937e-05,
      "loss": 0.076,
      "step": 24090
    },
    {
      "epoch": 2.5805760788092944,
      "grad_norm": 0.1840776652097702,
      "learning_rate": 3.710193810900525e-05,
      "loss": 0.0836,
      "step": 24100
    },
    {
      "epoch": 2.581646857265232,
      "grad_norm": 0.14976048469543457,
      "learning_rate": 3.709658421672556e-05,
      "loss": 0.0888,
      "step": 24110
    },
    {
      "epoch": 2.582717635721169,
      "grad_norm": 0.15787163376808167,
      "learning_rate": 3.709123032444588e-05,
      "loss": 0.0812,
      "step": 24120
    },
    {
      "epoch": 2.583788414177107,
      "grad_norm": 0.14908753335475922,
      "learning_rate": 3.708587643216619e-05,
      "loss": 0.0837,
      "step": 24130
    },
    {
      "epoch": 2.5848591926330444,
      "grad_norm": 0.1392820179462433,
      "learning_rate": 3.70805225398865e-05,
      "loss": 0.0773,
      "step": 24140
    },
    {
      "epoch": 2.585929971088982,
      "grad_norm": 0.1721990406513214,
      "learning_rate": 3.707516864760681e-05,
      "loss": 0.0723,
      "step": 24150
    },
    {
      "epoch": 2.587000749544919,
      "grad_norm": 0.14457976818084717,
      "learning_rate": 3.706981475532712e-05,
      "loss": 0.0821,
      "step": 24160
    },
    {
      "epoch": 2.5880715280008566,
      "grad_norm": 0.1397007703781128,
      "learning_rate": 3.706446086304744e-05,
      "loss": 0.0787,
      "step": 24170
    },
    {
      "epoch": 2.589142306456794,
      "grad_norm": 0.2808859348297119,
      "learning_rate": 3.7059106970767746e-05,
      "loss": 0.0858,
      "step": 24180
    },
    {
      "epoch": 2.5902130849127314,
      "grad_norm": 0.15780732035636902,
      "learning_rate": 3.7053753078488064e-05,
      "loss": 0.0822,
      "step": 24190
    },
    {
      "epoch": 2.591283863368669,
      "grad_norm": 0.2007717788219452,
      "learning_rate": 3.7048399186208375e-05,
      "loss": 0.0731,
      "step": 24200
    },
    {
      "epoch": 2.5923546418246066,
      "grad_norm": 0.10147229582071304,
      "learning_rate": 3.704304529392869e-05,
      "loss": 0.0709,
      "step": 24210
    },
    {
      "epoch": 2.593425420280544,
      "grad_norm": 0.20510028302669525,
      "learning_rate": 3.7037691401649e-05,
      "loss": 0.0737,
      "step": 24220
    },
    {
      "epoch": 2.5944961987364814,
      "grad_norm": 0.09324447810649872,
      "learning_rate": 3.7032337509369316e-05,
      "loss": 0.076,
      "step": 24230
    },
    {
      "epoch": 2.595566977192419,
      "grad_norm": 0.15665046870708466,
      "learning_rate": 3.702698361708963e-05,
      "loss": 0.0958,
      "step": 24240
    },
    {
      "epoch": 2.596637755648356,
      "grad_norm": 0.14797136187553406,
      "learning_rate": 3.702162972480994e-05,
      "loss": 0.0772,
      "step": 24250
    },
    {
      "epoch": 2.597708534104294,
      "grad_norm": 0.1233200803399086,
      "learning_rate": 3.701627583253025e-05,
      "loss": 0.093,
      "step": 24260
    },
    {
      "epoch": 2.5987793125602314,
      "grad_norm": 0.1165347471833229,
      "learning_rate": 3.701092194025056e-05,
      "loss": 0.0805,
      "step": 24270
    },
    {
      "epoch": 2.599850091016169,
      "grad_norm": 0.19144722819328308,
      "learning_rate": 3.700556804797088e-05,
      "loss": 0.0817,
      "step": 24280
    },
    {
      "epoch": 2.600920869472106,
      "grad_norm": 0.14706124365329742,
      "learning_rate": 3.7000214155691185e-05,
      "loss": 0.0814,
      "step": 24290
    },
    {
      "epoch": 2.6019916479280436,
      "grad_norm": 0.24916529655456543,
      "learning_rate": 3.69948602634115e-05,
      "loss": 0.081,
      "step": 24300
    },
    {
      "epoch": 2.603062426383981,
      "grad_norm": 0.0942525789141655,
      "learning_rate": 3.6989506371131814e-05,
      "loss": 0.0748,
      "step": 24310
    },
    {
      "epoch": 2.6041332048399184,
      "grad_norm": 0.10923051834106445,
      "learning_rate": 3.698415247885213e-05,
      "loss": 0.0779,
      "step": 24320
    },
    {
      "epoch": 2.6052039832958562,
      "grad_norm": 0.15727019309997559,
      "learning_rate": 3.697879858657244e-05,
      "loss": 0.0833,
      "step": 24330
    },
    {
      "epoch": 2.6062747617517936,
      "grad_norm": 0.22350415587425232,
      "learning_rate": 3.6973444694292755e-05,
      "loss": 0.0843,
      "step": 24340
    },
    {
      "epoch": 2.607345540207731,
      "grad_norm": 0.2003387063741684,
      "learning_rate": 3.696809080201307e-05,
      "loss": 0.0834,
      "step": 24350
    },
    {
      "epoch": 2.6084163186636684,
      "grad_norm": 0.20378297567367554,
      "learning_rate": 3.696273690973338e-05,
      "loss": 0.0731,
      "step": 24360
    },
    {
      "epoch": 2.609487097119606,
      "grad_norm": 0.18058805167675018,
      "learning_rate": 3.695738301745369e-05,
      "loss": 0.0869,
      "step": 24370
    },
    {
      "epoch": 2.6105578755755436,
      "grad_norm": 0.14724045991897583,
      "learning_rate": 3.6952029125174e-05,
      "loss": 0.0864,
      "step": 24380
    },
    {
      "epoch": 2.611628654031481,
      "grad_norm": 0.11995726823806763,
      "learning_rate": 3.694667523289432e-05,
      "loss": 0.0796,
      "step": 24390
    },
    {
      "epoch": 2.6126994324874184,
      "grad_norm": 0.1659328043460846,
      "learning_rate": 3.6941321340614624e-05,
      "loss": 0.081,
      "step": 24400
    },
    {
      "epoch": 2.613770210943356,
      "grad_norm": 0.1297457069158554,
      "learning_rate": 3.693596744833494e-05,
      "loss": 0.0698,
      "step": 24410
    },
    {
      "epoch": 2.614840989399293,
      "grad_norm": 0.09454528242349625,
      "learning_rate": 3.693061355605525e-05,
      "loss": 0.0724,
      "step": 24420
    },
    {
      "epoch": 2.6159117678552306,
      "grad_norm": 0.14099299907684326,
      "learning_rate": 3.692525966377557e-05,
      "loss": 0.0725,
      "step": 24430
    },
    {
      "epoch": 2.616982546311168,
      "grad_norm": 0.13181784749031067,
      "learning_rate": 3.6919905771495876e-05,
      "loss": 0.0787,
      "step": 24440
    },
    {
      "epoch": 2.618053324767106,
      "grad_norm": 0.14076578617095947,
      "learning_rate": 3.6914551879216194e-05,
      "loss": 0.0791,
      "step": 24450
    },
    {
      "epoch": 2.6191241032230432,
      "grad_norm": 0.2088748812675476,
      "learning_rate": 3.6909197986936506e-05,
      "loss": 0.0874,
      "step": 24460
    },
    {
      "epoch": 2.6201948816789806,
      "grad_norm": 0.08666393905878067,
      "learning_rate": 3.690384409465682e-05,
      "loss": 0.0818,
      "step": 24470
    },
    {
      "epoch": 2.621265660134918,
      "grad_norm": 0.23104263842105865,
      "learning_rate": 3.689849020237713e-05,
      "loss": 0.0771,
      "step": 24480
    },
    {
      "epoch": 2.6223364385908554,
      "grad_norm": 0.08531491458415985,
      "learning_rate": 3.689313631009744e-05,
      "loss": 0.0733,
      "step": 24490
    },
    {
      "epoch": 2.6234072170467932,
      "grad_norm": 0.23531906306743622,
      "learning_rate": 3.688778241781776e-05,
      "loss": 0.1031,
      "step": 24500
    },
    {
      "epoch": 2.6244779955027306,
      "grad_norm": 0.16391821205615997,
      "learning_rate": 3.6882963914766036e-05,
      "loss": 0.0769,
      "step": 24510
    },
    {
      "epoch": 2.625548773958668,
      "grad_norm": 0.1617615967988968,
      "learning_rate": 3.687761002248635e-05,
      "loss": 0.0722,
      "step": 24520
    },
    {
      "epoch": 2.6266195524146054,
      "grad_norm": 0.19256015121936798,
      "learning_rate": 3.687225613020666e-05,
      "loss": 0.0895,
      "step": 24530
    },
    {
      "epoch": 2.627690330870543,
      "grad_norm": 0.1758498102426529,
      "learning_rate": 3.686690223792698e-05,
      "loss": 0.0835,
      "step": 24540
    },
    {
      "epoch": 2.62876110932648,
      "grad_norm": 0.1326134353876114,
      "learning_rate": 3.686154834564729e-05,
      "loss": 0.0889,
      "step": 24550
    },
    {
      "epoch": 2.6298318877824176,
      "grad_norm": 0.10368553549051285,
      "learning_rate": 3.68561944533676e-05,
      "loss": 0.0716,
      "step": 24560
    },
    {
      "epoch": 2.6309026662383554,
      "grad_norm": 0.2648978531360626,
      "learning_rate": 3.685084056108791e-05,
      "loss": 0.0832,
      "step": 24570
    },
    {
      "epoch": 2.631973444694293,
      "grad_norm": 0.1350640207529068,
      "learning_rate": 3.684548666880823e-05,
      "loss": 0.0792,
      "step": 24580
    },
    {
      "epoch": 2.6330442231502302,
      "grad_norm": 0.2066340446472168,
      "learning_rate": 3.6840132776528534e-05,
      "loss": 0.0719,
      "step": 24590
    },
    {
      "epoch": 2.6341150016061676,
      "grad_norm": 0.21493598818778992,
      "learning_rate": 3.683477888424885e-05,
      "loss": 0.0725,
      "step": 24600
    },
    {
      "epoch": 2.635185780062105,
      "grad_norm": 0.24332904815673828,
      "learning_rate": 3.6829424991969164e-05,
      "loss": 0.0867,
      "step": 24610
    },
    {
      "epoch": 2.636256558518043,
      "grad_norm": 0.15719516575336456,
      "learning_rate": 3.6824071099689475e-05,
      "loss": 0.0767,
      "step": 24620
    },
    {
      "epoch": 2.6373273369739803,
      "grad_norm": 0.17504911124706268,
      "learning_rate": 3.681871720740979e-05,
      "loss": 0.0717,
      "step": 24630
    },
    {
      "epoch": 2.6383981154299176,
      "grad_norm": 0.2078699916601181,
      "learning_rate": 3.68133633151301e-05,
      "loss": 0.0914,
      "step": 24640
    },
    {
      "epoch": 2.639468893885855,
      "grad_norm": 0.0920291393995285,
      "learning_rate": 3.6808009422850416e-05,
      "loss": 0.0699,
      "step": 24650
    },
    {
      "epoch": 2.6405396723417924,
      "grad_norm": 0.13401341438293457,
      "learning_rate": 3.680265553057073e-05,
      "loss": 0.0775,
      "step": 24660
    },
    {
      "epoch": 2.64161045079773,
      "grad_norm": 0.1619197428226471,
      "learning_rate": 3.679730163829104e-05,
      "loss": 0.0703,
      "step": 24670
    },
    {
      "epoch": 2.642681229253667,
      "grad_norm": 0.1352071613073349,
      "learning_rate": 3.679194774601135e-05,
      "loss": 0.089,
      "step": 24680
    },
    {
      "epoch": 2.6437520077096046,
      "grad_norm": 0.14967040717601776,
      "learning_rate": 3.678659385373167e-05,
      "loss": 0.0854,
      "step": 24690
    },
    {
      "epoch": 2.6448227861655424,
      "grad_norm": 0.12059444934129715,
      "learning_rate": 3.678123996145198e-05,
      "loss": 0.0892,
      "step": 24700
    },
    {
      "epoch": 2.64589356462148,
      "grad_norm": 0.10630282014608383,
      "learning_rate": 3.677588606917229e-05,
      "loss": 0.0769,
      "step": 24710
    },
    {
      "epoch": 2.6469643430774172,
      "grad_norm": 0.11284372210502625,
      "learning_rate": 3.67705321768926e-05,
      "loss": 0.0768,
      "step": 24720
    },
    {
      "epoch": 2.6480351215333546,
      "grad_norm": 0.14549358189105988,
      "learning_rate": 3.6765178284612914e-05,
      "loss": 0.0793,
      "step": 24730
    },
    {
      "epoch": 2.6491058999892925,
      "grad_norm": 0.14707179367542267,
      "learning_rate": 3.6759824392333226e-05,
      "loss": 0.0825,
      "step": 24740
    },
    {
      "epoch": 2.65017667844523,
      "grad_norm": 0.14734399318695068,
      "learning_rate": 3.675447050005354e-05,
      "loss": 0.0769,
      "step": 24750
    },
    {
      "epoch": 2.6512474569011673,
      "grad_norm": 0.26557788252830505,
      "learning_rate": 3.6749116607773855e-05,
      "loss": 0.0883,
      "step": 24760
    },
    {
      "epoch": 2.6523182353571046,
      "grad_norm": 0.1482929140329361,
      "learning_rate": 3.674376271549417e-05,
      "loss": 0.0807,
      "step": 24770
    },
    {
      "epoch": 2.653389013813042,
      "grad_norm": 0.1923515647649765,
      "learning_rate": 3.673840882321448e-05,
      "loss": 0.0802,
      "step": 24780
    },
    {
      "epoch": 2.6544597922689794,
      "grad_norm": 0.1429823935031891,
      "learning_rate": 3.673305493093479e-05,
      "loss": 0.0795,
      "step": 24790
    },
    {
      "epoch": 2.655530570724917,
      "grad_norm": 0.12749436497688293,
      "learning_rate": 3.672770103865511e-05,
      "loss": 0.0817,
      "step": 24800
    },
    {
      "epoch": 2.656601349180854,
      "grad_norm": 0.3865939974784851,
      "learning_rate": 3.672234714637542e-05,
      "loss": 0.071,
      "step": 24810
    },
    {
      "epoch": 2.657672127636792,
      "grad_norm": 0.13392794132232666,
      "learning_rate": 3.671699325409573e-05,
      "loss": 0.0818,
      "step": 24820
    },
    {
      "epoch": 2.6587429060927295,
      "grad_norm": 0.20559431612491608,
      "learning_rate": 3.671163936181604e-05,
      "loss": 0.0845,
      "step": 24830
    },
    {
      "epoch": 2.659813684548667,
      "grad_norm": 0.12653909623622894,
      "learning_rate": 3.670628546953635e-05,
      "loss": 0.0882,
      "step": 24840
    },
    {
      "epoch": 2.6608844630046042,
      "grad_norm": 0.14630769193172455,
      "learning_rate": 3.670093157725667e-05,
      "loss": 0.076,
      "step": 24850
    },
    {
      "epoch": 2.661955241460542,
      "grad_norm": 0.26923680305480957,
      "learning_rate": 3.6695577684976976e-05,
      "loss": 0.0845,
      "step": 24860
    },
    {
      "epoch": 2.6630260199164795,
      "grad_norm": 0.16690656542778015,
      "learning_rate": 3.6690223792697294e-05,
      "loss": 0.1063,
      "step": 24870
    },
    {
      "epoch": 2.664096798372417,
      "grad_norm": 0.1257530152797699,
      "learning_rate": 3.6684869900417606e-05,
      "loss": 0.0709,
      "step": 24880
    },
    {
      "epoch": 2.6651675768283543,
      "grad_norm": 0.14687129855155945,
      "learning_rate": 3.6679516008137924e-05,
      "loss": 0.0766,
      "step": 24890
    },
    {
      "epoch": 2.6662383552842917,
      "grad_norm": 0.14900727570056915,
      "learning_rate": 3.667416211585823e-05,
      "loss": 0.0734,
      "step": 24900
    },
    {
      "epoch": 2.667309133740229,
      "grad_norm": 0.14482635259628296,
      "learning_rate": 3.6668808223578547e-05,
      "loss": 0.1,
      "step": 24910
    },
    {
      "epoch": 2.6683799121961664,
      "grad_norm": 0.20353184640407562,
      "learning_rate": 3.666345433129886e-05,
      "loss": 0.0937,
      "step": 24920
    },
    {
      "epoch": 2.669450690652104,
      "grad_norm": 0.18700821697711945,
      "learning_rate": 3.665810043901917e-05,
      "loss": 0.0818,
      "step": 24930
    },
    {
      "epoch": 2.6705214691080417,
      "grad_norm": 0.19478876888751984,
      "learning_rate": 3.665274654673948e-05,
      "loss": 0.0894,
      "step": 24940
    },
    {
      "epoch": 2.671592247563979,
      "grad_norm": 0.15555627644062042,
      "learning_rate": 3.664739265445979e-05,
      "loss": 0.0871,
      "step": 24950
    },
    {
      "epoch": 2.6726630260199165,
      "grad_norm": 0.17944130301475525,
      "learning_rate": 3.664203876218011e-05,
      "loss": 0.0768,
      "step": 24960
    },
    {
      "epoch": 2.673733804475854,
      "grad_norm": 0.17243501543998718,
      "learning_rate": 3.6636684869900415e-05,
      "loss": 0.0897,
      "step": 24970
    },
    {
      "epoch": 2.6748045829317917,
      "grad_norm": 0.1237562969326973,
      "learning_rate": 3.663133097762073e-05,
      "loss": 0.09,
      "step": 24980
    },
    {
      "epoch": 2.675875361387729,
      "grad_norm": 0.13605310022830963,
      "learning_rate": 3.6625977085341045e-05,
      "loss": 0.0855,
      "step": 24990
    },
    {
      "epoch": 2.6769461398436665,
      "grad_norm": 0.15080450475215912,
      "learning_rate": 3.662062319306136e-05,
      "loss": 0.0897,
      "step": 25000
    },
    {
      "epoch": 2.678016918299604,
      "grad_norm": 0.18744659423828125,
      "learning_rate": 3.661526930078167e-05,
      "loss": 0.0692,
      "step": 25010
    },
    {
      "epoch": 2.6790876967555413,
      "grad_norm": 0.15873876214027405,
      "learning_rate": 3.6609915408501986e-05,
      "loss": 0.0756,
      "step": 25020
    },
    {
      "epoch": 2.6801584752114787,
      "grad_norm": 0.1073678508400917,
      "learning_rate": 3.66045615162223e-05,
      "loss": 0.0703,
      "step": 25030
    },
    {
      "epoch": 2.681229253667416,
      "grad_norm": 0.11134453862905502,
      "learning_rate": 3.659920762394261e-05,
      "loss": 0.0761,
      "step": 25040
    },
    {
      "epoch": 2.6823000321233534,
      "grad_norm": 0.1441093385219574,
      "learning_rate": 3.659385373166292e-05,
      "loss": 0.0795,
      "step": 25050
    },
    {
      "epoch": 2.6833708105792913,
      "grad_norm": 0.16041305661201477,
      "learning_rate": 3.658849983938323e-05,
      "loss": 0.0712,
      "step": 25060
    },
    {
      "epoch": 2.6844415890352287,
      "grad_norm": 0.27244633436203003,
      "learning_rate": 3.658314594710355e-05,
      "loss": 0.0852,
      "step": 25070
    },
    {
      "epoch": 2.685512367491166,
      "grad_norm": 0.14360027015209198,
      "learning_rate": 3.6577792054823854e-05,
      "loss": 0.0758,
      "step": 25080
    },
    {
      "epoch": 2.6865831459471035,
      "grad_norm": 0.1497483253479004,
      "learning_rate": 3.657243816254417e-05,
      "loss": 0.0841,
      "step": 25090
    },
    {
      "epoch": 2.687653924403041,
      "grad_norm": 0.18275435268878937,
      "learning_rate": 3.6567084270264484e-05,
      "loss": 0.0914,
      "step": 25100
    },
    {
      "epoch": 2.6887247028589787,
      "grad_norm": 0.4872017800807953,
      "learning_rate": 3.65617303779848e-05,
      "loss": 0.0909,
      "step": 25110
    },
    {
      "epoch": 2.689795481314916,
      "grad_norm": 0.22672556340694427,
      "learning_rate": 3.6556376485705106e-05,
      "loss": 0.0856,
      "step": 25120
    },
    {
      "epoch": 2.6908662597708535,
      "grad_norm": 0.08806465566158295,
      "learning_rate": 3.6551022593425424e-05,
      "loss": 0.0786,
      "step": 25130
    },
    {
      "epoch": 2.691937038226791,
      "grad_norm": 0.17356282472610474,
      "learning_rate": 3.6545668701145736e-05,
      "loss": 0.0867,
      "step": 25140
    },
    {
      "epoch": 2.6930078166827283,
      "grad_norm": 0.15416604280471802,
      "learning_rate": 3.654031480886605e-05,
      "loss": 0.0953,
      "step": 25150
    },
    {
      "epoch": 2.6940785951386657,
      "grad_norm": 0.12692151963710785,
      "learning_rate": 3.653496091658636e-05,
      "loss": 0.0746,
      "step": 25160
    },
    {
      "epoch": 2.695149373594603,
      "grad_norm": 0.1417068988084793,
      "learning_rate": 3.652960702430667e-05,
      "loss": 0.0697,
      "step": 25170
    },
    {
      "epoch": 2.696220152050541,
      "grad_norm": 0.10065597295761108,
      "learning_rate": 3.652425313202699e-05,
      "loss": 0.0589,
      "step": 25180
    },
    {
      "epoch": 2.6972909305064783,
      "grad_norm": 0.1518499255180359,
      "learning_rate": 3.65188992397473e-05,
      "loss": 0.075,
      "step": 25190
    },
    {
      "epoch": 2.6983617089624157,
      "grad_norm": 0.17160063982009888,
      "learning_rate": 3.651354534746761e-05,
      "loss": 0.0814,
      "step": 25200
    },
    {
      "epoch": 2.699432487418353,
      "grad_norm": 0.16139398515224457,
      "learning_rate": 3.650819145518792e-05,
      "loss": 0.0786,
      "step": 25210
    },
    {
      "epoch": 2.7005032658742905,
      "grad_norm": 0.1668744534254074,
      "learning_rate": 3.650283756290824e-05,
      "loss": 0.0766,
      "step": 25220
    },
    {
      "epoch": 2.7015740443302283,
      "grad_norm": 0.19103631377220154,
      "learning_rate": 3.6497483670628545e-05,
      "loss": 0.0816,
      "step": 25230
    },
    {
      "epoch": 2.7026448227861657,
      "grad_norm": 0.1415441930294037,
      "learning_rate": 3.6492129778348863e-05,
      "loss": 0.0859,
      "step": 25240
    },
    {
      "epoch": 2.703715601242103,
      "grad_norm": 0.2122296541929245,
      "learning_rate": 3.6486775886069175e-05,
      "loss": 0.102,
      "step": 25250
    },
    {
      "epoch": 2.7047863796980405,
      "grad_norm": 0.17918165028095245,
      "learning_rate": 3.6481421993789486e-05,
      "loss": 0.0794,
      "step": 25260
    },
    {
      "epoch": 2.705857158153978,
      "grad_norm": 0.20569534599781036,
      "learning_rate": 3.64760681015098e-05,
      "loss": 0.0837,
      "step": 25270
    },
    {
      "epoch": 2.7069279366099153,
      "grad_norm": 0.18503513932228088,
      "learning_rate": 3.647071420923011e-05,
      "loss": 0.0912,
      "step": 25280
    },
    {
      "epoch": 2.7079987150658527,
      "grad_norm": 0.1912209391593933,
      "learning_rate": 3.646536031695043e-05,
      "loss": 0.0777,
      "step": 25290
    },
    {
      "epoch": 2.7090694935217905,
      "grad_norm": 0.17992649972438812,
      "learning_rate": 3.646000642467074e-05,
      "loss": 0.0733,
      "step": 25300
    },
    {
      "epoch": 2.710140271977728,
      "grad_norm": 0.1978006511926651,
      "learning_rate": 3.645465253239105e-05,
      "loss": 0.0834,
      "step": 25310
    },
    {
      "epoch": 2.7112110504336653,
      "grad_norm": 0.1255033165216446,
      "learning_rate": 3.644929864011136e-05,
      "loss": 0.0824,
      "step": 25320
    },
    {
      "epoch": 2.7122818288896027,
      "grad_norm": 0.18764638900756836,
      "learning_rate": 3.644394474783168e-05,
      "loss": 0.0854,
      "step": 25330
    },
    {
      "epoch": 2.71335260734554,
      "grad_norm": 0.11586697399616241,
      "learning_rate": 3.643859085555199e-05,
      "loss": 0.0667,
      "step": 25340
    },
    {
      "epoch": 2.714423385801478,
      "grad_norm": 0.19693902134895325,
      "learning_rate": 3.64332369632723e-05,
      "loss": 0.0749,
      "step": 25350
    },
    {
      "epoch": 2.7154941642574153,
      "grad_norm": 0.6914357542991638,
      "learning_rate": 3.6427883070992614e-05,
      "loss": 0.078,
      "step": 25360
    },
    {
      "epoch": 2.7165649427133527,
      "grad_norm": 0.3816109597682953,
      "learning_rate": 3.6422529178712925e-05,
      "loss": 0.0828,
      "step": 25370
    },
    {
      "epoch": 2.71763572116929,
      "grad_norm": 0.5754252076148987,
      "learning_rate": 3.6417175286433237e-05,
      "loss": 0.092,
      "step": 25380
    },
    {
      "epoch": 2.7187064996252275,
      "grad_norm": 0.12848961353302002,
      "learning_rate": 3.641182139415355e-05,
      "loss": 0.0769,
      "step": 25390
    },
    {
      "epoch": 2.719777278081165,
      "grad_norm": 0.1576664298772812,
      "learning_rate": 3.6406467501873866e-05,
      "loss": 0.0813,
      "step": 25400
    },
    {
      "epoch": 2.7208480565371023,
      "grad_norm": 0.11843641847372055,
      "learning_rate": 3.640111360959418e-05,
      "loss": 0.0877,
      "step": 25410
    },
    {
      "epoch": 2.72191883499304,
      "grad_norm": 0.1789957880973816,
      "learning_rate": 3.639575971731449e-05,
      "loss": 0.0751,
      "step": 25420
    },
    {
      "epoch": 2.7229896134489775,
      "grad_norm": 0.23277829587459564,
      "learning_rate": 3.63904058250348e-05,
      "loss": 0.0813,
      "step": 25430
    },
    {
      "epoch": 2.724060391904915,
      "grad_norm": 0.14820238947868347,
      "learning_rate": 3.638505193275512e-05,
      "loss": 0.0818,
      "step": 25440
    },
    {
      "epoch": 2.7251311703608523,
      "grad_norm": 0.11377064883708954,
      "learning_rate": 3.637969804047543e-05,
      "loss": 0.0723,
      "step": 25450
    },
    {
      "epoch": 2.7262019488167897,
      "grad_norm": 0.163460373878479,
      "learning_rate": 3.637434414819574e-05,
      "loss": 0.0833,
      "step": 25460
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.1621139496564865,
      "learning_rate": 3.636899025591605e-05,
      "loss": 0.0859,
      "step": 25470
    },
    {
      "epoch": 2.728343505728665,
      "grad_norm": 0.1351972371339798,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.0845,
      "step": 25480
    },
    {
      "epoch": 2.7294142841846023,
      "grad_norm": 0.15460501611232758,
      "learning_rate": 3.635828247135668e-05,
      "loss": 0.0829,
      "step": 25490
    },
    {
      "epoch": 2.7304850626405397,
      "grad_norm": 0.17199206352233887,
      "learning_rate": 3.635292857907699e-05,
      "loss": 0.0849,
      "step": 25500
    },
    {
      "epoch": 2.731555841096477,
      "grad_norm": 0.18816129863262177,
      "learning_rate": 3.6347574686797305e-05,
      "loss": 0.0796,
      "step": 25510
    },
    {
      "epoch": 2.7326266195524145,
      "grad_norm": 0.12627869844436646,
      "learning_rate": 3.6342220794517617e-05,
      "loss": 0.0681,
      "step": 25520
    },
    {
      "epoch": 2.733697398008352,
      "grad_norm": 0.10746940225362778,
      "learning_rate": 3.633686690223793e-05,
      "loss": 0.072,
      "step": 25530
    },
    {
      "epoch": 2.7347681764642893,
      "grad_norm": 0.14471794664859772,
      "learning_rate": 3.633151300995824e-05,
      "loss": 0.0632,
      "step": 25540
    },
    {
      "epoch": 2.735838954920227,
      "grad_norm": 0.14943256974220276,
      "learning_rate": 3.632615911767856e-05,
      "loss": 0.0779,
      "step": 25550
    },
    {
      "epoch": 2.7369097333761645,
      "grad_norm": 0.14094005525112152,
      "learning_rate": 3.632080522539887e-05,
      "loss": 0.086,
      "step": 25560
    },
    {
      "epoch": 2.737980511832102,
      "grad_norm": 0.18217608332633972,
      "learning_rate": 3.631545133311918e-05,
      "loss": 0.0914,
      "step": 25570
    },
    {
      "epoch": 2.7390512902880393,
      "grad_norm": 0.1565115749835968,
      "learning_rate": 3.631009744083949e-05,
      "loss": 0.0766,
      "step": 25580
    },
    {
      "epoch": 2.740122068743977,
      "grad_norm": 0.11194763332605362,
      "learning_rate": 3.63047435485598e-05,
      "loss": 0.0728,
      "step": 25590
    },
    {
      "epoch": 2.7411928471999145,
      "grad_norm": 0.18139636516571045,
      "learning_rate": 3.629938965628012e-05,
      "loss": 0.0781,
      "step": 25600
    },
    {
      "epoch": 2.742263625655852,
      "grad_norm": 0.1531788408756256,
      "learning_rate": 3.6294035764000426e-05,
      "loss": 0.0926,
      "step": 25610
    },
    {
      "epoch": 2.7433344041117893,
      "grad_norm": 0.12803907692432404,
      "learning_rate": 3.6288681871720744e-05,
      "loss": 0.0802,
      "step": 25620
    },
    {
      "epoch": 2.7444051825677267,
      "grad_norm": 0.20803575217723846,
      "learning_rate": 3.6283327979441055e-05,
      "loss": 0.0808,
      "step": 25630
    },
    {
      "epoch": 2.745475961023664,
      "grad_norm": 0.2268092781305313,
      "learning_rate": 3.6277974087161374e-05,
      "loss": 0.0847,
      "step": 25640
    },
    {
      "epoch": 2.7465467394796015,
      "grad_norm": 0.19161786139011383,
      "learning_rate": 3.627262019488168e-05,
      "loss": 0.0894,
      "step": 25650
    },
    {
      "epoch": 2.747617517935539,
      "grad_norm": 0.17226599156856537,
      "learning_rate": 3.6267266302601996e-05,
      "loss": 0.0786,
      "step": 25660
    },
    {
      "epoch": 2.7486882963914767,
      "grad_norm": 0.2258300483226776,
      "learning_rate": 3.626191241032231e-05,
      "loss": 0.0836,
      "step": 25670
    },
    {
      "epoch": 2.749759074847414,
      "grad_norm": 0.1571151167154312,
      "learning_rate": 3.625655851804262e-05,
      "loss": 0.0785,
      "step": 25680
    },
    {
      "epoch": 2.7508298533033515,
      "grad_norm": 0.13298745453357697,
      "learning_rate": 3.625120462576293e-05,
      "loss": 0.0769,
      "step": 25690
    },
    {
      "epoch": 2.751900631759289,
      "grad_norm": 0.14859886467456818,
      "learning_rate": 3.624585073348324e-05,
      "loss": 0.0729,
      "step": 25700
    },
    {
      "epoch": 2.7529714102152267,
      "grad_norm": 0.20598368346691132,
      "learning_rate": 3.624049684120356e-05,
      "loss": 0.0777,
      "step": 25710
    },
    {
      "epoch": 2.754042188671164,
      "grad_norm": 0.1572476327419281,
      "learning_rate": 3.6235142948923865e-05,
      "loss": 0.0658,
      "step": 25720
    },
    {
      "epoch": 2.7551129671271015,
      "grad_norm": 0.10382331907749176,
      "learning_rate": 3.622978905664418e-05,
      "loss": 0.0771,
      "step": 25730
    },
    {
      "epoch": 2.756183745583039,
      "grad_norm": 0.13717298209667206,
      "learning_rate": 3.6224435164364494e-05,
      "loss": 0.0783,
      "step": 25740
    },
    {
      "epoch": 2.7572545240389763,
      "grad_norm": 0.20138217508792877,
      "learning_rate": 3.621908127208481e-05,
      "loss": 0.0754,
      "step": 25750
    },
    {
      "epoch": 2.7583253024949137,
      "grad_norm": 0.1794804185628891,
      "learning_rate": 3.621372737980512e-05,
      "loss": 0.082,
      "step": 25760
    },
    {
      "epoch": 2.759396080950851,
      "grad_norm": 0.25764188170433044,
      "learning_rate": 3.6208373487525435e-05,
      "loss": 0.0755,
      "step": 25770
    },
    {
      "epoch": 2.7604668594067885,
      "grad_norm": 0.1432906836271286,
      "learning_rate": 3.620301959524575e-05,
      "loss": 0.0836,
      "step": 25780
    },
    {
      "epoch": 2.7615376378627263,
      "grad_norm": 0.16738685965538025,
      "learning_rate": 3.619766570296606e-05,
      "loss": 0.0863,
      "step": 25790
    },
    {
      "epoch": 2.7626084163186637,
      "grad_norm": 0.15268221497535706,
      "learning_rate": 3.619231181068637e-05,
      "loss": 0.0734,
      "step": 25800
    },
    {
      "epoch": 2.763679194774601,
      "grad_norm": 0.1868823766708374,
      "learning_rate": 3.618695791840668e-05,
      "loss": 0.0742,
      "step": 25810
    },
    {
      "epoch": 2.7647499732305385,
      "grad_norm": 0.21556423604488373,
      "learning_rate": 3.6181604026127e-05,
      "loss": 0.0857,
      "step": 25820
    },
    {
      "epoch": 2.7658207516864763,
      "grad_norm": 0.1379268914461136,
      "learning_rate": 3.617625013384731e-05,
      "loss": 0.0852,
      "step": 25830
    },
    {
      "epoch": 2.7668915301424137,
      "grad_norm": 0.18720106780529022,
      "learning_rate": 3.617089624156762e-05,
      "loss": 0.0679,
      "step": 25840
    },
    {
      "epoch": 2.767962308598351,
      "grad_norm": 0.14571349322795868,
      "learning_rate": 3.616554234928793e-05,
      "loss": 0.0741,
      "step": 25850
    },
    {
      "epoch": 2.7690330870542885,
      "grad_norm": 0.15661247074604034,
      "learning_rate": 3.616018845700825e-05,
      "loss": 0.0805,
      "step": 25860
    },
    {
      "epoch": 2.770103865510226,
      "grad_norm": 0.15788812935352325,
      "learning_rate": 3.6154834564728556e-05,
      "loss": 0.0851,
      "step": 25870
    },
    {
      "epoch": 2.7711746439661633,
      "grad_norm": 0.14871665835380554,
      "learning_rate": 3.6149480672448874e-05,
      "loss": 0.0685,
      "step": 25880
    },
    {
      "epoch": 2.7722454224221007,
      "grad_norm": 0.18742302060127258,
      "learning_rate": 3.6144126780169186e-05,
      "loss": 0.0784,
      "step": 25890
    },
    {
      "epoch": 2.773316200878038,
      "grad_norm": 0.1679682582616806,
      "learning_rate": 3.61387728878895e-05,
      "loss": 0.0865,
      "step": 25900
    },
    {
      "epoch": 2.774386979333976,
      "grad_norm": 0.18981708586215973,
      "learning_rate": 3.613341899560981e-05,
      "loss": 0.0851,
      "step": 25910
    },
    {
      "epoch": 2.7754577577899133,
      "grad_norm": 0.13407346606254578,
      "learning_rate": 3.612806510333012e-05,
      "loss": 0.0809,
      "step": 25920
    },
    {
      "epoch": 2.7765285362458507,
      "grad_norm": 0.20680725574493408,
      "learning_rate": 3.612271121105044e-05,
      "loss": 0.0714,
      "step": 25930
    },
    {
      "epoch": 2.777599314701788,
      "grad_norm": 0.17991729080677032,
      "learning_rate": 3.611735731877075e-05,
      "loss": 0.0864,
      "step": 25940
    },
    {
      "epoch": 2.7786700931577255,
      "grad_norm": 0.17623499035835266,
      "learning_rate": 3.611200342649106e-05,
      "loss": 0.0814,
      "step": 25950
    },
    {
      "epoch": 2.7797408716136633,
      "grad_norm": 0.10278496891260147,
      "learning_rate": 3.610664953421137e-05,
      "loss": 0.0864,
      "step": 25960
    },
    {
      "epoch": 2.7808116500696007,
      "grad_norm": 0.13933172821998596,
      "learning_rate": 3.610129564193169e-05,
      "loss": 0.0871,
      "step": 25970
    },
    {
      "epoch": 2.781882428525538,
      "grad_norm": 0.12751293182373047,
      "learning_rate": 3.6095941749652e-05,
      "loss": 0.0779,
      "step": 25980
    },
    {
      "epoch": 2.7829532069814755,
      "grad_norm": 0.14552482962608337,
      "learning_rate": 3.609058785737231e-05,
      "loss": 0.0857,
      "step": 25990
    },
    {
      "epoch": 2.784023985437413,
      "grad_norm": 0.1905379742383957,
      "learning_rate": 3.6085233965092625e-05,
      "loss": 0.0806,
      "step": 26000
    },
    {
      "epoch": 2.7850947638933503,
      "grad_norm": 0.2242826223373413,
      "learning_rate": 3.6079880072812936e-05,
      "loss": 0.0758,
      "step": 26010
    },
    {
      "epoch": 2.7861655423492877,
      "grad_norm": 0.12394114583730698,
      "learning_rate": 3.607452618053325e-05,
      "loss": 0.083,
      "step": 26020
    },
    {
      "epoch": 2.7872363208052255,
      "grad_norm": 0.17121079564094543,
      "learning_rate": 3.606917228825356e-05,
      "loss": 0.0756,
      "step": 26030
    },
    {
      "epoch": 2.788307099261163,
      "grad_norm": 0.14452481269836426,
      "learning_rate": 3.606381839597388e-05,
      "loss": 0.0762,
      "step": 26040
    },
    {
      "epoch": 2.7893778777171003,
      "grad_norm": 0.19563499093055725,
      "learning_rate": 3.605846450369419e-05,
      "loss": 0.0887,
      "step": 26050
    },
    {
      "epoch": 2.7904486561730377,
      "grad_norm": 0.1632477343082428,
      "learning_rate": 3.60531106114145e-05,
      "loss": 0.0819,
      "step": 26060
    },
    {
      "epoch": 2.791519434628975,
      "grad_norm": 0.19156192243099213,
      "learning_rate": 3.604775671913481e-05,
      "loss": 0.085,
      "step": 26070
    },
    {
      "epoch": 2.792590213084913,
      "grad_norm": 0.11905020475387573,
      "learning_rate": 3.604240282685513e-05,
      "loss": 0.0726,
      "step": 26080
    },
    {
      "epoch": 2.7936609915408503,
      "grad_norm": 0.15983441472053528,
      "learning_rate": 3.603704893457544e-05,
      "loss": 0.0796,
      "step": 26090
    },
    {
      "epoch": 2.7947317699967877,
      "grad_norm": 0.18202488124370575,
      "learning_rate": 3.6031695042295745e-05,
      "loss": 0.0854,
      "step": 26100
    },
    {
      "epoch": 2.795802548452725,
      "grad_norm": 0.11802425980567932,
      "learning_rate": 3.6026341150016064e-05,
      "loss": 0.0787,
      "step": 26110
    },
    {
      "epoch": 2.7968733269086625,
      "grad_norm": 0.1816788762807846,
      "learning_rate": 3.6020987257736375e-05,
      "loss": 0.0873,
      "step": 26120
    },
    {
      "epoch": 2.7979441053646,
      "grad_norm": 0.10586941987276077,
      "learning_rate": 3.601563336545669e-05,
      "loss": 0.072,
      "step": 26130
    },
    {
      "epoch": 2.7990148838205373,
      "grad_norm": 0.1382475346326828,
      "learning_rate": 3.6010279473177e-05,
      "loss": 0.0733,
      "step": 26140
    },
    {
      "epoch": 2.800085662276475,
      "grad_norm": 0.15313829481601715,
      "learning_rate": 3.6004925580897316e-05,
      "loss": 0.0807,
      "step": 26150
    },
    {
      "epoch": 2.8011564407324125,
      "grad_norm": 0.13421976566314697,
      "learning_rate": 3.599957168861763e-05,
      "loss": 0.0778,
      "step": 26160
    },
    {
      "epoch": 2.80222721918835,
      "grad_norm": 0.24497337639331818,
      "learning_rate": 3.599421779633794e-05,
      "loss": 0.0824,
      "step": 26170
    },
    {
      "epoch": 2.8032979976442873,
      "grad_norm": 0.17163729667663574,
      "learning_rate": 3.598886390405825e-05,
      "loss": 0.0901,
      "step": 26180
    },
    {
      "epoch": 2.8043687761002247,
      "grad_norm": 0.15190349519252777,
      "learning_rate": 3.598351001177857e-05,
      "loss": 0.0843,
      "step": 26190
    },
    {
      "epoch": 2.8054395545561626,
      "grad_norm": 0.17761161923408508,
      "learning_rate": 3.597815611949888e-05,
      "loss": 0.0776,
      "step": 26200
    },
    {
      "epoch": 2.8065103330121,
      "grad_norm": 0.15817949175834656,
      "learning_rate": 3.5972802227219184e-05,
      "loss": 0.0807,
      "step": 26210
    },
    {
      "epoch": 2.8075811114680373,
      "grad_norm": 0.15128719806671143,
      "learning_rate": 3.59674483349395e-05,
      "loss": 0.0795,
      "step": 26220
    },
    {
      "epoch": 2.8086518899239747,
      "grad_norm": 0.18330149352550507,
      "learning_rate": 3.5962094442659814e-05,
      "loss": 0.0866,
      "step": 26230
    },
    {
      "epoch": 2.809722668379912,
      "grad_norm": 0.1250794231891632,
      "learning_rate": 3.595674055038013e-05,
      "loss": 0.0684,
      "step": 26240
    },
    {
      "epoch": 2.8107934468358495,
      "grad_norm": 0.16272753477096558,
      "learning_rate": 3.595138665810044e-05,
      "loss": 0.09,
      "step": 26250
    },
    {
      "epoch": 2.811864225291787,
      "grad_norm": 0.14920851588249207,
      "learning_rate": 3.5946032765820755e-05,
      "loss": 0.0914,
      "step": 26260
    },
    {
      "epoch": 2.8129350037477248,
      "grad_norm": 0.19348235428333282,
      "learning_rate": 3.5940678873541066e-05,
      "loss": 0.0776,
      "step": 26270
    },
    {
      "epoch": 2.814005782203662,
      "grad_norm": 0.09372203052043915,
      "learning_rate": 3.5935324981261385e-05,
      "loss": 0.0846,
      "step": 26280
    },
    {
      "epoch": 2.8150765606595995,
      "grad_norm": 0.21077960729599,
      "learning_rate": 3.592997108898169e-05,
      "loss": 0.0898,
      "step": 26290
    },
    {
      "epoch": 2.816147339115537,
      "grad_norm": 0.17511172592639923,
      "learning_rate": 3.5924617196702e-05,
      "loss": 0.0722,
      "step": 26300
    },
    {
      "epoch": 2.8172181175714743,
      "grad_norm": 0.1280592978000641,
      "learning_rate": 3.591926330442232e-05,
      "loss": 0.0809,
      "step": 26310
    },
    {
      "epoch": 2.818288896027412,
      "grad_norm": 0.30011290311813354,
      "learning_rate": 3.5913909412142623e-05,
      "loss": 0.0725,
      "step": 26320
    },
    {
      "epoch": 2.8193596744833496,
      "grad_norm": 0.19480425119400024,
      "learning_rate": 3.590855551986294e-05,
      "loss": 0.0969,
      "step": 26330
    },
    {
      "epoch": 2.820430452939287,
      "grad_norm": 0.16431382298469543,
      "learning_rate": 3.590320162758325e-05,
      "loss": 0.0797,
      "step": 26340
    },
    {
      "epoch": 2.8215012313952244,
      "grad_norm": 0.16569238901138306,
      "learning_rate": 3.589784773530357e-05,
      "loss": 0.0903,
      "step": 26350
    },
    {
      "epoch": 2.8225720098511617,
      "grad_norm": 0.1407802700996399,
      "learning_rate": 3.5892493843023876e-05,
      "loss": 0.0803,
      "step": 26360
    },
    {
      "epoch": 2.823642788307099,
      "grad_norm": 0.22091513872146606,
      "learning_rate": 3.5887139950744194e-05,
      "loss": 0.0773,
      "step": 26370
    },
    {
      "epoch": 2.8247135667630365,
      "grad_norm": 0.177127867937088,
      "learning_rate": 3.5881786058464505e-05,
      "loss": 0.0657,
      "step": 26380
    },
    {
      "epoch": 2.825784345218974,
      "grad_norm": 0.2054305523633957,
      "learning_rate": 3.5876432166184824e-05,
      "loss": 0.0824,
      "step": 26390
    },
    {
      "epoch": 2.8268551236749118,
      "grad_norm": 0.09183292090892792,
      "learning_rate": 3.587107827390513e-05,
      "loss": 0.0682,
      "step": 26400
    },
    {
      "epoch": 2.827925902130849,
      "grad_norm": 0.10629057139158249,
      "learning_rate": 3.586572438162544e-05,
      "loss": 0.0817,
      "step": 26410
    },
    {
      "epoch": 2.8289966805867865,
      "grad_norm": 0.17238891124725342,
      "learning_rate": 3.586037048934576e-05,
      "loss": 0.0772,
      "step": 26420
    },
    {
      "epoch": 2.830067459042724,
      "grad_norm": 0.15108099579811096,
      "learning_rate": 3.585501659706607e-05,
      "loss": 0.077,
      "step": 26430
    },
    {
      "epoch": 2.831138237498662,
      "grad_norm": 0.2671651542186737,
      "learning_rate": 3.584966270478638e-05,
      "loss": 0.0893,
      "step": 26440
    },
    {
      "epoch": 2.832209015954599,
      "grad_norm": 0.18011876940727234,
      "learning_rate": 3.584430881250669e-05,
      "loss": 0.0881,
      "step": 26450
    },
    {
      "epoch": 2.8332797944105366,
      "grad_norm": 0.2638612985610962,
      "learning_rate": 3.583895492022701e-05,
      "loss": 0.063,
      "step": 26460
    },
    {
      "epoch": 2.834350572866474,
      "grad_norm": 0.11397238075733185,
      "learning_rate": 3.5833601027947315e-05,
      "loss": 0.0844,
      "step": 26470
    },
    {
      "epoch": 2.8354213513224114,
      "grad_norm": 0.12034548074007034,
      "learning_rate": 3.582824713566763e-05,
      "loss": 0.0692,
      "step": 26480
    },
    {
      "epoch": 2.8364921297783487,
      "grad_norm": 0.1594919115304947,
      "learning_rate": 3.5822893243387944e-05,
      "loss": 0.0853,
      "step": 26490
    },
    {
      "epoch": 2.837562908234286,
      "grad_norm": 0.19228367507457733,
      "learning_rate": 3.5817539351108256e-05,
      "loss": 0.0773,
      "step": 26500
    },
    {
      "epoch": 2.8386336866902235,
      "grad_norm": 0.10679112374782562,
      "learning_rate": 3.581218545882857e-05,
      "loss": 0.0839,
      "step": 26510
    },
    {
      "epoch": 2.8397044651461614,
      "grad_norm": 0.09568050503730774,
      "learning_rate": 3.580736695577685e-05,
      "loss": 0.0763,
      "step": 26520
    },
    {
      "epoch": 2.8407752436020988,
      "grad_norm": 0.09812483191490173,
      "learning_rate": 3.5802013063497164e-05,
      "loss": 0.072,
      "step": 26530
    },
    {
      "epoch": 2.841846022058036,
      "grad_norm": 0.12247729301452637,
      "learning_rate": 3.5796659171217475e-05,
      "loss": 0.0823,
      "step": 26540
    },
    {
      "epoch": 2.8429168005139736,
      "grad_norm": 0.19511936604976654,
      "learning_rate": 3.5791305278937786e-05,
      "loss": 0.0814,
      "step": 26550
    },
    {
      "epoch": 2.8439875789699114,
      "grad_norm": 0.14201080799102783,
      "learning_rate": 3.57859513866581e-05,
      "loss": 0.0756,
      "step": 26560
    },
    {
      "epoch": 2.845058357425849,
      "grad_norm": 0.15274368226528168,
      "learning_rate": 3.5780597494378416e-05,
      "loss": 0.0851,
      "step": 26570
    },
    {
      "epoch": 2.846129135881786,
      "grad_norm": 0.1099308654665947,
      "learning_rate": 3.577524360209873e-05,
      "loss": 0.0737,
      "step": 26580
    },
    {
      "epoch": 2.8471999143377236,
      "grad_norm": 0.13351242244243622,
      "learning_rate": 3.576988970981904e-05,
      "loss": 0.079,
      "step": 26590
    },
    {
      "epoch": 2.848270692793661,
      "grad_norm": 0.1637074500322342,
      "learning_rate": 3.576453581753935e-05,
      "loss": 0.0733,
      "step": 26600
    },
    {
      "epoch": 2.8493414712495984,
      "grad_norm": 0.16343480348587036,
      "learning_rate": 3.575918192525967e-05,
      "loss": 0.0787,
      "step": 26610
    },
    {
      "epoch": 2.8504122497055357,
      "grad_norm": 0.12163271009922028,
      "learning_rate": 3.575382803297998e-05,
      "loss": 0.0876,
      "step": 26620
    },
    {
      "epoch": 2.851483028161473,
      "grad_norm": 0.15951085090637207,
      "learning_rate": 3.574847414070029e-05,
      "loss": 0.0785,
      "step": 26630
    },
    {
      "epoch": 2.852553806617411,
      "grad_norm": 0.18671958148479462,
      "learning_rate": 3.57431202484206e-05,
      "loss": 0.0741,
      "step": 26640
    },
    {
      "epoch": 2.8536245850733484,
      "grad_norm": 0.174342542886734,
      "learning_rate": 3.5737766356140914e-05,
      "loss": 0.0791,
      "step": 26650
    },
    {
      "epoch": 2.8546953635292858,
      "grad_norm": 0.1340894103050232,
      "learning_rate": 3.573241246386123e-05,
      "loss": 0.0876,
      "step": 26660
    },
    {
      "epoch": 2.855766141985223,
      "grad_norm": 0.12539760768413544,
      "learning_rate": 3.572705857158154e-05,
      "loss": 0.0828,
      "step": 26670
    },
    {
      "epoch": 2.856836920441161,
      "grad_norm": 0.1706584244966507,
      "learning_rate": 3.5721704679301855e-05,
      "loss": 0.0844,
      "step": 26680
    },
    {
      "epoch": 2.8579076988970984,
      "grad_norm": 0.13569483160972595,
      "learning_rate": 3.5716350787022166e-05,
      "loss": 0.0719,
      "step": 26690
    },
    {
      "epoch": 2.858978477353036,
      "grad_norm": 0.12576404213905334,
      "learning_rate": 3.5710996894742484e-05,
      "loss": 0.0732,
      "step": 26700
    },
    {
      "epoch": 2.860049255808973,
      "grad_norm": 0.1674899160861969,
      "learning_rate": 3.570564300246279e-05,
      "loss": 0.0798,
      "step": 26710
    },
    {
      "epoch": 2.8611200342649106,
      "grad_norm": 0.16045820713043213,
      "learning_rate": 3.570028911018311e-05,
      "loss": 0.0769,
      "step": 26720
    },
    {
      "epoch": 2.862190812720848,
      "grad_norm": 0.1514507681131363,
      "learning_rate": 3.569493521790342e-05,
      "loss": 0.0753,
      "step": 26730
    },
    {
      "epoch": 2.8632615911767854,
      "grad_norm": 0.14532354474067688,
      "learning_rate": 3.568958132562373e-05,
      "loss": 0.0821,
      "step": 26740
    },
    {
      "epoch": 2.8643323696327228,
      "grad_norm": 0.2796590030193329,
      "learning_rate": 3.568422743334404e-05,
      "loss": 0.095,
      "step": 26750
    },
    {
      "epoch": 2.8654031480886606,
      "grad_norm": 0.18897797167301178,
      "learning_rate": 3.567887354106435e-05,
      "loss": 0.0855,
      "step": 26760
    },
    {
      "epoch": 2.866473926544598,
      "grad_norm": 0.12855969369411469,
      "learning_rate": 3.567351964878467e-05,
      "loss": 0.0696,
      "step": 26770
    },
    {
      "epoch": 2.8675447050005354,
      "grad_norm": 0.20717012882232666,
      "learning_rate": 3.5668165756504976e-05,
      "loss": 0.0825,
      "step": 26780
    },
    {
      "epoch": 2.8686154834564728,
      "grad_norm": 0.12198694050312042,
      "learning_rate": 3.5662811864225294e-05,
      "loss": 0.0753,
      "step": 26790
    },
    {
      "epoch": 2.86968626191241,
      "grad_norm": 0.10676438361406326,
      "learning_rate": 3.5657457971945605e-05,
      "loss": 0.0703,
      "step": 26800
    },
    {
      "epoch": 2.870757040368348,
      "grad_norm": 0.14253029227256775,
      "learning_rate": 3.565210407966592e-05,
      "loss": 0.077,
      "step": 26810
    },
    {
      "epoch": 2.8718278188242854,
      "grad_norm": 0.27630147337913513,
      "learning_rate": 3.564675018738623e-05,
      "loss": 0.0759,
      "step": 26820
    },
    {
      "epoch": 2.872898597280223,
      "grad_norm": 0.16188861429691315,
      "learning_rate": 3.5641396295106546e-05,
      "loss": 0.0748,
      "step": 26830
    },
    {
      "epoch": 2.87396937573616,
      "grad_norm": 0.15010260045528412,
      "learning_rate": 3.563604240282686e-05,
      "loss": 0.0894,
      "step": 26840
    },
    {
      "epoch": 2.8750401541920976,
      "grad_norm": 0.19285447895526886,
      "learning_rate": 3.563068851054717e-05,
      "loss": 0.0824,
      "step": 26850
    },
    {
      "epoch": 2.876110932648035,
      "grad_norm": 0.16850416362285614,
      "learning_rate": 3.562533461826748e-05,
      "loss": 0.0784,
      "step": 26860
    },
    {
      "epoch": 2.8771817111039724,
      "grad_norm": 0.18447764217853546,
      "learning_rate": 3.561998072598779e-05,
      "loss": 0.0874,
      "step": 26870
    },
    {
      "epoch": 2.87825248955991,
      "grad_norm": 0.11547879129648209,
      "learning_rate": 3.561462683370811e-05,
      "loss": 0.0865,
      "step": 26880
    },
    {
      "epoch": 2.8793232680158476,
      "grad_norm": 0.12857192754745483,
      "learning_rate": 3.5609272941428415e-05,
      "loss": 0.0755,
      "step": 26890
    },
    {
      "epoch": 2.880394046471785,
      "grad_norm": 0.17611780762672424,
      "learning_rate": 3.560391904914873e-05,
      "loss": 0.0797,
      "step": 26900
    },
    {
      "epoch": 2.8814648249277224,
      "grad_norm": 0.19896268844604492,
      "learning_rate": 3.5598565156869044e-05,
      "loss": 0.0788,
      "step": 26910
    },
    {
      "epoch": 2.8825356033836598,
      "grad_norm": 0.13855305314064026,
      "learning_rate": 3.559321126458936e-05,
      "loss": 0.0711,
      "step": 26920
    },
    {
      "epoch": 2.8836063818395976,
      "grad_norm": 0.13466478884220123,
      "learning_rate": 3.558785737230967e-05,
      "loss": 0.0683,
      "step": 26930
    },
    {
      "epoch": 2.884677160295535,
      "grad_norm": 0.16953621804714203,
      "learning_rate": 3.5582503480029985e-05,
      "loss": 0.0878,
      "step": 26940
    },
    {
      "epoch": 2.8857479387514724,
      "grad_norm": 0.1561984270811081,
      "learning_rate": 3.5577149587750297e-05,
      "loss": 0.0839,
      "step": 26950
    },
    {
      "epoch": 2.88681871720741,
      "grad_norm": 0.12764900922775269,
      "learning_rate": 3.557179569547061e-05,
      "loss": 0.0848,
      "step": 26960
    },
    {
      "epoch": 2.887889495663347,
      "grad_norm": 0.14822128415107727,
      "learning_rate": 3.556644180319092e-05,
      "loss": 0.0795,
      "step": 26970
    },
    {
      "epoch": 2.8889602741192846,
      "grad_norm": 0.10346762090921402,
      "learning_rate": 3.556108791091123e-05,
      "loss": 0.0791,
      "step": 26980
    },
    {
      "epoch": 2.890031052575222,
      "grad_norm": 0.20707806944847107,
      "learning_rate": 3.555573401863155e-05,
      "loss": 0.0761,
      "step": 26990
    },
    {
      "epoch": 2.89110183103116,
      "grad_norm": 0.19642199575901031,
      "learning_rate": 3.555038012635186e-05,
      "loss": 0.0735,
      "step": 27000
    },
    {
      "epoch": 2.892172609487097,
      "grad_norm": 0.18878501653671265,
      "learning_rate": 3.554502623407217e-05,
      "loss": 0.0744,
      "step": 27010
    },
    {
      "epoch": 2.8932433879430346,
      "grad_norm": 0.20925134420394897,
      "learning_rate": 3.553967234179248e-05,
      "loss": 0.0703,
      "step": 27020
    },
    {
      "epoch": 2.894314166398972,
      "grad_norm": 0.1188938170671463,
      "learning_rate": 3.55343184495128e-05,
      "loss": 0.0673,
      "step": 27030
    },
    {
      "epoch": 2.8953849448549094,
      "grad_norm": 0.15835720300674438,
      "learning_rate": 3.5528964557233106e-05,
      "loss": 0.0725,
      "step": 27040
    },
    {
      "epoch": 2.896455723310847,
      "grad_norm": 0.17985470592975616,
      "learning_rate": 3.5523610664953424e-05,
      "loss": 0.0873,
      "step": 27050
    },
    {
      "epoch": 2.8975265017667846,
      "grad_norm": 0.12419051676988602,
      "learning_rate": 3.5518256772673735e-05,
      "loss": 0.0952,
      "step": 27060
    },
    {
      "epoch": 2.898597280222722,
      "grad_norm": 0.14637544751167297,
      "learning_rate": 3.551290288039405e-05,
      "loss": 0.0827,
      "step": 27070
    },
    {
      "epoch": 2.8996680586786594,
      "grad_norm": 0.12742967903614044,
      "learning_rate": 3.550754898811436e-05,
      "loss": 0.0747,
      "step": 27080
    },
    {
      "epoch": 2.900738837134597,
      "grad_norm": 0.5125876665115356,
      "learning_rate": 3.550219509583467e-05,
      "loss": 0.0632,
      "step": 27090
    },
    {
      "epoch": 2.901809615590534,
      "grad_norm": 0.433088481426239,
      "learning_rate": 3.549684120355499e-05,
      "loss": 0.0645,
      "step": 27100
    },
    {
      "epoch": 2.9028803940464716,
      "grad_norm": 0.20778852701187134,
      "learning_rate": 3.54914873112753e-05,
      "loss": 0.0918,
      "step": 27110
    },
    {
      "epoch": 2.9039511725024094,
      "grad_norm": 0.24057306349277496,
      "learning_rate": 3.548613341899561e-05,
      "loss": 0.0907,
      "step": 27120
    },
    {
      "epoch": 2.905021950958347,
      "grad_norm": 0.14701762795448303,
      "learning_rate": 3.548077952671592e-05,
      "loss": 0.0781,
      "step": 27130
    },
    {
      "epoch": 2.906092729414284,
      "grad_norm": 0.13110610842704773,
      "learning_rate": 3.547542563443624e-05,
      "loss": 0.0789,
      "step": 27140
    },
    {
      "epoch": 2.9071635078702216,
      "grad_norm": 0.12918786704540253,
      "learning_rate": 3.547007174215655e-05,
      "loss": 0.074,
      "step": 27150
    },
    {
      "epoch": 2.908234286326159,
      "grad_norm": 0.2838245928287506,
      "learning_rate": 3.546471784987686e-05,
      "loss": 0.0829,
      "step": 27160
    },
    {
      "epoch": 2.909305064782097,
      "grad_norm": 0.1397733837366104,
      "learning_rate": 3.5459363957597174e-05,
      "loss": 0.0769,
      "step": 27170
    },
    {
      "epoch": 2.910375843238034,
      "grad_norm": 0.18324996531009674,
      "learning_rate": 3.5454010065317486e-05,
      "loss": 0.0696,
      "step": 27180
    },
    {
      "epoch": 2.9114466216939716,
      "grad_norm": 0.11737871915102005,
      "learning_rate": 3.54486561730378e-05,
      "loss": 0.0836,
      "step": 27190
    },
    {
      "epoch": 2.912517400149909,
      "grad_norm": 0.15125131607055664,
      "learning_rate": 3.544330228075811e-05,
      "loss": 0.0807,
      "step": 27200
    },
    {
      "epoch": 2.9135881786058464,
      "grad_norm": 0.1740129590034485,
      "learning_rate": 3.543794838847843e-05,
      "loss": 0.0796,
      "step": 27210
    },
    {
      "epoch": 2.914658957061784,
      "grad_norm": 0.15954874455928802,
      "learning_rate": 3.543259449619874e-05,
      "loss": 0.0739,
      "step": 27220
    },
    {
      "epoch": 2.915729735517721,
      "grad_norm": 0.17023837566375732,
      "learning_rate": 3.542724060391905e-05,
      "loss": 0.075,
      "step": 27230
    },
    {
      "epoch": 2.9168005139736586,
      "grad_norm": 0.15365901589393616,
      "learning_rate": 3.542188671163936e-05,
      "loss": 0.075,
      "step": 27240
    },
    {
      "epoch": 2.9178712924295964,
      "grad_norm": 0.1509326994419098,
      "learning_rate": 3.541653281935968e-05,
      "loss": 0.0795,
      "step": 27250
    },
    {
      "epoch": 2.918942070885534,
      "grad_norm": 0.1732279658317566,
      "learning_rate": 3.541117892707999e-05,
      "loss": 0.0827,
      "step": 27260
    },
    {
      "epoch": 2.920012849341471,
      "grad_norm": 0.2156870812177658,
      "learning_rate": 3.54058250348003e-05,
      "loss": 0.0766,
      "step": 27270
    },
    {
      "epoch": 2.9210836277974086,
      "grad_norm": 0.18358080089092255,
      "learning_rate": 3.5400471142520613e-05,
      "loss": 0.0765,
      "step": 27280
    },
    {
      "epoch": 2.9221544062533464,
      "grad_norm": 0.1785043179988861,
      "learning_rate": 3.5395117250240925e-05,
      "loss": 0.0725,
      "step": 27290
    },
    {
      "epoch": 2.923225184709284,
      "grad_norm": 0.1617070883512497,
      "learning_rate": 3.538976335796124e-05,
      "loss": 0.0847,
      "step": 27300
    },
    {
      "epoch": 2.9242959631652212,
      "grad_norm": 0.1468694657087326,
      "learning_rate": 3.538440946568155e-05,
      "loss": 0.0972,
      "step": 27310
    },
    {
      "epoch": 2.9253667416211586,
      "grad_norm": 0.16230300068855286,
      "learning_rate": 3.5379055573401866e-05,
      "loss": 0.0923,
      "step": 27320
    },
    {
      "epoch": 2.926437520077096,
      "grad_norm": 0.11530076712369919,
      "learning_rate": 3.537370168112218e-05,
      "loss": 0.0772,
      "step": 27330
    },
    {
      "epoch": 2.9275082985330334,
      "grad_norm": 0.13161469995975494,
      "learning_rate": 3.536834778884249e-05,
      "loss": 0.0733,
      "step": 27340
    },
    {
      "epoch": 2.928579076988971,
      "grad_norm": 0.13376076519489288,
      "learning_rate": 3.53629938965628e-05,
      "loss": 0.0675,
      "step": 27350
    },
    {
      "epoch": 2.929649855444908,
      "grad_norm": 0.1253705471754074,
      "learning_rate": 3.535764000428312e-05,
      "loss": 0.0837,
      "step": 27360
    },
    {
      "epoch": 2.930720633900846,
      "grad_norm": 0.15529422461986542,
      "learning_rate": 3.535228611200343e-05,
      "loss": 0.0887,
      "step": 27370
    },
    {
      "epoch": 2.9317914123567834,
      "grad_norm": 0.17329847812652588,
      "learning_rate": 3.534693221972374e-05,
      "loss": 0.0667,
      "step": 27380
    },
    {
      "epoch": 2.932862190812721,
      "grad_norm": 0.1652718186378479,
      "learning_rate": 3.534157832744405e-05,
      "loss": 0.076,
      "step": 27390
    },
    {
      "epoch": 2.933932969268658,
      "grad_norm": 0.12389859557151794,
      "learning_rate": 3.5336224435164364e-05,
      "loss": 0.0776,
      "step": 27400
    },
    {
      "epoch": 2.935003747724596,
      "grad_norm": 0.12663860619068146,
      "learning_rate": 3.533087054288468e-05,
      "loss": 0.0788,
      "step": 27410
    },
    {
      "epoch": 2.9360745261805334,
      "grad_norm": 0.14965786039829254,
      "learning_rate": 3.5325516650604987e-05,
      "loss": 0.0819,
      "step": 27420
    },
    {
      "epoch": 2.937145304636471,
      "grad_norm": 0.15296010673046112,
      "learning_rate": 3.5320162758325305e-05,
      "loss": 0.0682,
      "step": 27430
    },
    {
      "epoch": 2.9382160830924082,
      "grad_norm": 0.17092281579971313,
      "learning_rate": 3.5314808866045616e-05,
      "loss": 0.0854,
      "step": 27440
    },
    {
      "epoch": 2.9392868615483456,
      "grad_norm": 0.12415657192468643,
      "learning_rate": 3.5309454973765934e-05,
      "loss": 0.0843,
      "step": 27450
    },
    {
      "epoch": 2.940357640004283,
      "grad_norm": 0.11728794127702713,
      "learning_rate": 3.530410108148624e-05,
      "loss": 0.0756,
      "step": 27460
    },
    {
      "epoch": 2.9414284184602204,
      "grad_norm": 0.14463365077972412,
      "learning_rate": 3.529874718920656e-05,
      "loss": 0.0699,
      "step": 27470
    },
    {
      "epoch": 2.942499196916158,
      "grad_norm": 0.15372931957244873,
      "learning_rate": 3.529339329692687e-05,
      "loss": 0.0702,
      "step": 27480
    },
    {
      "epoch": 2.9435699753720956,
      "grad_norm": 0.16132564842700958,
      "learning_rate": 3.528803940464718e-05,
      "loss": 0.0701,
      "step": 27490
    },
    {
      "epoch": 2.944640753828033,
      "grad_norm": 0.1954566091299057,
      "learning_rate": 3.528268551236749e-05,
      "loss": 0.0776,
      "step": 27500
    },
    {
      "epoch": 2.9457115322839704,
      "grad_norm": 0.14096641540527344,
      "learning_rate": 3.52773316200878e-05,
      "loss": 0.0752,
      "step": 27510
    },
    {
      "epoch": 2.946782310739908,
      "grad_norm": 0.13467822968959808,
      "learning_rate": 3.527197772780812e-05,
      "loss": 0.0714,
      "step": 27520
    },
    {
      "epoch": 2.9478530891958457,
      "grad_norm": 0.15036724507808685,
      "learning_rate": 3.5266623835528426e-05,
      "loss": 0.0807,
      "step": 27530
    },
    {
      "epoch": 2.948923867651783,
      "grad_norm": 0.11386111378669739,
      "learning_rate": 3.5261269943248744e-05,
      "loss": 0.07,
      "step": 27540
    },
    {
      "epoch": 2.9499946461077204,
      "grad_norm": 0.19832034409046173,
      "learning_rate": 3.5255916050969055e-05,
      "loss": 0.082,
      "step": 27550
    },
    {
      "epoch": 2.951065424563658,
      "grad_norm": 0.11151590198278427,
      "learning_rate": 3.525056215868937e-05,
      "loss": 0.0864,
      "step": 27560
    },
    {
      "epoch": 2.9521362030195952,
      "grad_norm": 0.13833914697170258,
      "learning_rate": 3.524520826640968e-05,
      "loss": 0.0682,
      "step": 27570
    },
    {
      "epoch": 2.9532069814755326,
      "grad_norm": 0.6384192109107971,
      "learning_rate": 3.5239854374129996e-05,
      "loss": 0.0945,
      "step": 27580
    },
    {
      "epoch": 2.95427775993147,
      "grad_norm": 0.14248746633529663,
      "learning_rate": 3.523450048185031e-05,
      "loss": 0.0617,
      "step": 27590
    },
    {
      "epoch": 2.9553485383874074,
      "grad_norm": 0.5861347317695618,
      "learning_rate": 3.522914658957062e-05,
      "loss": 0.1075,
      "step": 27600
    },
    {
      "epoch": 2.9564193168433452,
      "grad_norm": 0.2838256061077118,
      "learning_rate": 3.522379269729093e-05,
      "loss": 0.089,
      "step": 27610
    },
    {
      "epoch": 2.9574900952992826,
      "grad_norm": 0.22151146829128265,
      "learning_rate": 3.521843880501124e-05,
      "loss": 0.0815,
      "step": 27620
    },
    {
      "epoch": 2.95856087375522,
      "grad_norm": 0.14410395920276642,
      "learning_rate": 3.521308491273156e-05,
      "loss": 0.0809,
      "step": 27630
    },
    {
      "epoch": 2.9596316522111574,
      "grad_norm": 0.1700935661792755,
      "learning_rate": 3.520773102045187e-05,
      "loss": 0.0833,
      "step": 27640
    },
    {
      "epoch": 2.960702430667095,
      "grad_norm": 0.1151510626077652,
      "learning_rate": 3.520237712817218e-05,
      "loss": 0.0663,
      "step": 27650
    },
    {
      "epoch": 2.9617732091230327,
      "grad_norm": 0.11863238364458084,
      "learning_rate": 3.5197023235892494e-05,
      "loss": 0.0751,
      "step": 27660
    },
    {
      "epoch": 2.96284398757897,
      "grad_norm": 0.18137390911579132,
      "learning_rate": 3.519166934361281e-05,
      "loss": 0.086,
      "step": 27670
    },
    {
      "epoch": 2.9639147660349074,
      "grad_norm": 0.1304965615272522,
      "learning_rate": 3.518631545133312e-05,
      "loss": 0.0943,
      "step": 27680
    },
    {
      "epoch": 2.964985544490845,
      "grad_norm": 0.24043144285678864,
      "learning_rate": 3.5180961559053435e-05,
      "loss": 0.0831,
      "step": 27690
    },
    {
      "epoch": 2.9660563229467822,
      "grad_norm": 0.10483048111200333,
      "learning_rate": 3.5175607666773746e-05,
      "loss": 0.0782,
      "step": 27700
    },
    {
      "epoch": 2.9671271014027196,
      "grad_norm": 0.12600895762443542,
      "learning_rate": 3.517025377449406e-05,
      "loss": 0.0839,
      "step": 27710
    },
    {
      "epoch": 2.968197879858657,
      "grad_norm": 0.18002143502235413,
      "learning_rate": 3.516489988221437e-05,
      "loss": 0.0864,
      "step": 27720
    },
    {
      "epoch": 2.969268658314595,
      "grad_norm": 0.21359595656394958,
      "learning_rate": 3.515954598993468e-05,
      "loss": 0.0716,
      "step": 27730
    },
    {
      "epoch": 2.9703394367705322,
      "grad_norm": 0.25948163866996765,
      "learning_rate": 3.5154192097655e-05,
      "loss": 0.0734,
      "step": 27740
    },
    {
      "epoch": 2.9714102152264696,
      "grad_norm": 0.21119967103004456,
      "learning_rate": 3.514883820537531e-05,
      "loss": 0.0771,
      "step": 27750
    },
    {
      "epoch": 2.972480993682407,
      "grad_norm": 0.25759392976760864,
      "learning_rate": 3.514348431309562e-05,
      "loss": 0.073,
      "step": 27760
    },
    {
      "epoch": 2.9735517721383444,
      "grad_norm": 0.11477343738079071,
      "learning_rate": 3.513813042081593e-05,
      "loss": 0.0744,
      "step": 27770
    },
    {
      "epoch": 2.9746225505942823,
      "grad_norm": 0.16255129873752594,
      "learning_rate": 3.513277652853625e-05,
      "loss": 0.0959,
      "step": 27780
    },
    {
      "epoch": 2.9756933290502197,
      "grad_norm": 0.1737433671951294,
      "learning_rate": 3.512742263625656e-05,
      "loss": 0.0644,
      "step": 27790
    },
    {
      "epoch": 2.976764107506157,
      "grad_norm": 0.13005581498146057,
      "learning_rate": 3.5122068743976874e-05,
      "loss": 0.0757,
      "step": 27800
    },
    {
      "epoch": 2.9778348859620944,
      "grad_norm": 0.14443914592266083,
      "learning_rate": 3.5116714851697185e-05,
      "loss": 0.0767,
      "step": 27810
    },
    {
      "epoch": 2.978905664418032,
      "grad_norm": 0.23988617956638336,
      "learning_rate": 3.51113609594175e-05,
      "loss": 0.074,
      "step": 27820
    },
    {
      "epoch": 2.9799764428739692,
      "grad_norm": 0.1994789093732834,
      "learning_rate": 3.510600706713781e-05,
      "loss": 0.0927,
      "step": 27830
    },
    {
      "epoch": 2.9810472213299066,
      "grad_norm": 0.17559994757175446,
      "learning_rate": 3.510065317485812e-05,
      "loss": 0.0784,
      "step": 27840
    },
    {
      "epoch": 2.9821179997858445,
      "grad_norm": 0.16165730357170105,
      "learning_rate": 3.509529928257844e-05,
      "loss": 0.0862,
      "step": 27850
    },
    {
      "epoch": 2.983188778241782,
      "grad_norm": 0.13158081471920013,
      "learning_rate": 3.508994539029875e-05,
      "loss": 0.0729,
      "step": 27860
    },
    {
      "epoch": 2.9842595566977193,
      "grad_norm": 0.15242896974086761,
      "learning_rate": 3.508459149801906e-05,
      "loss": 0.0674,
      "step": 27870
    },
    {
      "epoch": 2.9853303351536566,
      "grad_norm": 1.2406550645828247,
      "learning_rate": 3.507923760573937e-05,
      "loss": 0.0866,
      "step": 27880
    },
    {
      "epoch": 2.986401113609594,
      "grad_norm": 0.1621844619512558,
      "learning_rate": 3.507388371345969e-05,
      "loss": 0.0736,
      "step": 27890
    },
    {
      "epoch": 2.987471892065532,
      "grad_norm": 0.10821931809186935,
      "learning_rate": 3.506852982118e-05,
      "loss": 0.0772,
      "step": 27900
    },
    {
      "epoch": 2.9885426705214693,
      "grad_norm": 0.23456405103206635,
      "learning_rate": 3.506317592890031e-05,
      "loss": 0.0842,
      "step": 27910
    },
    {
      "epoch": 2.9896134489774067,
      "grad_norm": 0.19281770288944244,
      "learning_rate": 3.5057822036620624e-05,
      "loss": 0.0715,
      "step": 27920
    },
    {
      "epoch": 2.990684227433344,
      "grad_norm": 0.2331349104642868,
      "learning_rate": 3.5052468144340936e-05,
      "loss": 0.0791,
      "step": 27930
    },
    {
      "epoch": 2.9917550058892814,
      "grad_norm": 0.14660049974918365,
      "learning_rate": 3.5047114252061254e-05,
      "loss": 0.0741,
      "step": 27940
    },
    {
      "epoch": 2.992825784345219,
      "grad_norm": 0.11699369549751282,
      "learning_rate": 3.504176035978156e-05,
      "loss": 0.0724,
      "step": 27950
    },
    {
      "epoch": 2.9938965628011562,
      "grad_norm": 0.18387462198734283,
      "learning_rate": 3.503640646750188e-05,
      "loss": 0.0931,
      "step": 27960
    },
    {
      "epoch": 2.994967341257094,
      "grad_norm": 0.17591789364814758,
      "learning_rate": 3.503105257522219e-05,
      "loss": 0.0739,
      "step": 27970
    },
    {
      "epoch": 2.9960381197130315,
      "grad_norm": 0.17129556834697723,
      "learning_rate": 3.50256986829425e-05,
      "loss": 0.0851,
      "step": 27980
    },
    {
      "epoch": 2.997108898168969,
      "grad_norm": 0.2111012190580368,
      "learning_rate": 3.502034479066281e-05,
      "loss": 0.0741,
      "step": 27990
    },
    {
      "epoch": 2.9981796766249063,
      "grad_norm": 0.14288277924060822,
      "learning_rate": 3.501499089838313e-05,
      "loss": 0.0832,
      "step": 28000
    },
    {
      "epoch": 2.9992504550808436,
      "grad_norm": 0.10326450318098068,
      "learning_rate": 3.500963700610344e-05,
      "loss": 0.0744,
      "step": 28010
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.061574388295412064,
      "eval_runtime": 140.0239,
      "eval_samples_per_second": 59.29,
      "eval_steps_per_second": 7.413,
      "step": 28017
    }
  ],
  "logging_steps": 10,
  "max_steps": 93390,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.033497001472819e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
